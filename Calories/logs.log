2023-10-21 17:01:27,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-21 17:01:27,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-21 17:01:27,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-21 17:01:27,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-22 21:40:44,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-22 21:40:44,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-22 21:40:44,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-22 21:40:44,720:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-22 22:25:20,169:INFO:PyCaret RegressionExperiment
2023-10-22 22:25:20,169:INFO:Logging name: reg-default-name
2023-10-22 22:25:20,169:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-22 22:25:20,169:INFO:version 3.1.0
2023-10-22 22:25:20,169:INFO:Initializing setup()
2023-10-22 22:25:20,169:INFO:self.USI: 73f6
2023-10-22 22:25:20,169:INFO:self._variable_keys: {'idx', 'n_jobs_param', 'fold_shuffle_param', 'y', 'fold_groups_param', 'seed', '_available_plots', 'data', 'exp_id', 'gpu_n_jobs_param', 'pipeline', '_ml_usecase', 'X_train', 'X_test', 'y_test', 'logging_param', 'html_param', 'transform_target_param', 'X', 'log_plots_param', 'y_train', 'memory', 'gpu_param', 'exp_name_log', 'fold_generator', 'USI', 'target_param'}
2023-10-22 22:25:20,169:INFO:Checking environment
2023-10-22 22:25:20,169:INFO:python_version: 3.10.6
2023-10-22 22:25:20,169:INFO:python_build: ('main', 'Mar 10 2023 10:55:28')
2023-10-22 22:25:20,169:INFO:machine: x86_64
2023-10-22 22:25:20,169:INFO:platform: Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.35
2023-10-22 22:25:20,169:INFO:Memory: svmem(total=16562769920, available=15403966464, percent=7.0, used=877932544, free=15109943296, active=310501376, inactive=719134720, buffers=156672000, cached=418222080, shared=2355200, slab=120074240)
2023-10-22 22:25:20,170:INFO:Physical Core: 12
2023-10-22 22:25:20,171:INFO:Logical Core: 24
2023-10-22 22:25:20,171:INFO:Checking libraries
2023-10-22 22:25:20,171:INFO:System:
2023-10-22 22:25:20,171:INFO:    python: 3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0]
2023-10-22 22:25:20,171:INFO:executable: /usr/bin/python3
2023-10-22 22:25:20,171:INFO:   machine: Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.35
2023-10-22 22:25:20,171:INFO:PyCaret required dependencies:
2023-10-22 22:25:20,451:INFO:                 pip: 22.0.2
2023-10-22 22:25:20,451:INFO:          setuptools: 59.6.0
2023-10-22 22:25:20,451:INFO:             pycaret: 3.1.0
2023-10-22 22:25:20,451:INFO:             IPython: 8.5.0
2023-10-22 22:25:20,451:INFO:          ipywidgets: 7.7.2
2023-10-22 22:25:20,451:INFO:                tqdm: 4.64.1
2023-10-22 22:25:20,451:INFO:               numpy: 1.23.4
2023-10-22 22:25:20,451:INFO:              pandas: 1.4.2
2023-10-22 22:25:20,451:INFO:              jinja2: 3.1.2
2023-10-22 22:25:20,451:INFO:               scipy: 1.10.1
2023-10-22 22:25:20,451:INFO:              joblib: 1.3.2
2023-10-22 22:25:20,451:INFO:             sklearn: 1.1.2
2023-10-22 22:25:20,451:INFO:                pyod: 1.1.0
2023-10-22 22:25:20,451:INFO:            imblearn: 0.9.1
2023-10-22 22:25:20,451:INFO:   category_encoders: 2.6.2
2023-10-22 22:25:20,451:INFO:            lightgbm: 4.1.0
2023-10-22 22:25:20,451:INFO:               numba: 0.58.1
2023-10-22 22:25:20,451:INFO:            requests: 2.28.1
2023-10-22 22:25:20,451:INFO:          matplotlib: 3.5.3
2023-10-22 22:25:20,451:INFO:          scikitplot: 0.3.7
2023-10-22 22:25:20,451:INFO:         yellowbrick: 1.5
2023-10-22 22:25:20,451:INFO:              plotly: 5.9.0
2023-10-22 22:25:20,451:INFO:    plotly-resampler: Not installed
2023-10-22 22:25:20,451:INFO:             kaleido: 0.2.1
2023-10-22 22:25:20,451:INFO:           schemdraw: 0.15
2023-10-22 22:25:20,451:INFO:         statsmodels: 0.13.2
2023-10-22 22:25:20,451:INFO:              sktime: 0.21.1
2023-10-22 22:25:20,451:INFO:               tbats: 1.1.3
2023-10-22 22:25:20,451:INFO:            pmdarima: 2.0.1
2023-10-22 22:25:20,451:INFO:              psutil: 5.9.3
2023-10-22 22:25:20,451:INFO:          markupsafe: 2.1.1
2023-10-22 22:25:20,451:INFO:             pickle5: Not installed
2023-10-22 22:25:20,451:INFO:         cloudpickle: 2.2.0
2023-10-22 22:25:20,451:INFO:         deprecation: 2.1.0
2023-10-22 22:25:20,451:INFO:              xxhash: 3.4.1
2023-10-22 22:25:20,451:INFO:           wurlitzer: 3.0.3
2023-10-22 22:25:20,451:INFO:PyCaret optional dependencies:
2023-10-22 22:25:20,475:INFO:                shap: Not installed
2023-10-22 22:25:20,475:INFO:           interpret: Not installed
2023-10-22 22:25:20,475:INFO:                umap: Not installed
2023-10-22 22:25:20,475:INFO:     ydata_profiling: Not installed
2023-10-22 22:25:20,475:INFO:  explainerdashboard: Not installed
2023-10-22 22:25:20,475:INFO:             autoviz: Not installed
2023-10-22 22:25:20,475:INFO:           fairlearn: Not installed
2023-10-22 22:25:20,475:INFO:          deepchecks: Not installed
2023-10-22 22:25:20,475:INFO:             xgboost: 1.6.2
2023-10-22 22:25:20,475:INFO:            catboost: Not installed
2023-10-22 22:25:20,475:INFO:              kmodes: Not installed
2023-10-22 22:25:20,475:INFO:             mlxtend: Not installed
2023-10-22 22:25:20,475:INFO:       statsforecast: Not installed
2023-10-22 22:25:20,475:INFO:        tune_sklearn: Not installed
2023-10-22 22:25:20,475:INFO:                 ray: Not installed
2023-10-22 22:25:20,475:INFO:            hyperopt: Not installed
2023-10-22 22:25:20,475:INFO:              optuna: Not installed
2023-10-22 22:25:20,475:INFO:               skopt: Not installed
2023-10-22 22:25:20,475:INFO:              mlflow: Not installed
2023-10-22 22:25:20,475:INFO:              gradio: Not installed
2023-10-22 22:25:20,475:INFO:             fastapi: Not installed
2023-10-22 22:25:20,475:INFO:             uvicorn: Not installed
2023-10-22 22:25:20,475:INFO:              m2cgen: Not installed
2023-10-22 22:25:20,475:INFO:           evidently: Not installed
2023-10-22 22:25:20,475:INFO:               fugue: Not installed
2023-10-22 22:25:20,475:INFO:           streamlit: 1.11.1
2023-10-22 22:25:20,475:INFO:             prophet: Not installed
2023-10-22 22:25:20,475:INFO:None
2023-10-22 22:25:20,475:INFO:Set up data.
2023-10-22 22:25:20,481:INFO:Set up folding strategy.
2023-10-22 22:25:20,481:INFO:Set up train/test split.
2023-10-22 22:25:20,485:INFO:Set up index.
2023-10-22 22:25:20,485:INFO:Assigning column types.
2023-10-22 22:25:20,486:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-22 22:25:20,487:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,489:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,491:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,544:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:20,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:20,545:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,547:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,550:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,600:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,601:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:20,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:20,603:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-22 22:25:20,605:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,607:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,635:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,661:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,662:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:20,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:20,665:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,667:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,696:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,715:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,715:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:20,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:20,717:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-22 22:25:20,721:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,769:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,769:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:20,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:20,775:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,802:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,823:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,823:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:20,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:20,825:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-22 22:25:20,859:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,880:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:20,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:20,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,935:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,935:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:20,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:20,937:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-22 22:25:20,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-22 22:25:20,989:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:20,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:21,024:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-22 22:25:21,044:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:21,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:21,045:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-22 22:25:21,098:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:21,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:21,152:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:21,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:21,169:INFO:Preparing preprocessing pipeline...
2023-10-22 22:25:21,169:INFO:Set up simple imputation.
2023-10-22 22:25:21,172:INFO:Set up encoding of categorical features.
2023-10-22 22:25:21,173:INFO:Set up column name cleaning.
2023-10-22 22:25:21,210:INFO:Finished creating preprocessing pipeline.
2023-10-22 22:25:21,215:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Sleep', 'Activity Duration',
                                             'TSS', 'Weight', 'Steps',
                                             'Cals_burnt', 'Protein',
                                             'Sensation'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Activity Type'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Activity Type'],
                                    transformer=OneHotEncoder(cols=['Activity '
                                                                    'Type'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-22 22:25:21,215:INFO:Creating final display dataframe.
2023-10-22 22:25:21,307:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              Cals
2                   Target type        Regression
3           Original data shape        (1014, 10)
4        Transformed data shape        (1014, 21)
5   Transformed train set shape         (709, 21)
6    Transformed test set shape         (305, 21)
7              Numeric features                 8
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              73f6
2023-10-22 22:25:21,379:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:21,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:21,439:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-22 22:25:21,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-22 22:25:21,441:INFO:setup() successfully completed in 1.27s...............
2023-10-22 22:25:35,362:INFO:Initializing compare_models()
2023-10-22 22:25:35,363:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-22 22:25:35,363:INFO:Checking exceptions
2023-10-22 22:25:35,365:INFO:Preparing display monitor
2023-10-22 22:25:35,397:INFO:Initializing Linear Regression
2023-10-22 22:25:35,397:INFO:Total runtime is 2.924601236979167e-06 minutes
2023-10-22 22:25:35,402:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:35,402:INFO:Initializing create_model()
2023-10-22 22:25:35,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:35,402:INFO:Checking exceptions
2023-10-22 22:25:35,402:INFO:Importing libraries
2023-10-22 22:25:35,402:INFO:Copying training dataset
2023-10-22 22:25:35,406:INFO:Defining folds
2023-10-22 22:25:35,406:INFO:Declaring metric variables
2023-10-22 22:25:35,409:INFO:Importing untrained model
2023-10-22 22:25:35,411:INFO:Linear Regression Imported successfully
2023-10-22 22:25:35,415:INFO:Starting cross validation
2023-10-22 22:25:35,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:37,253:INFO:Calculating mean and std
2023-10-22 22:25:37,255:INFO:Creating metrics dataframe
2023-10-22 22:25:37,261:INFO:Uploading results into container
2023-10-22 22:25:37,261:INFO:Uploading model into container now
2023-10-22 22:25:37,262:INFO:_master_model_container: 1
2023-10-22 22:25:37,262:INFO:_display_container: 2
2023-10-22 22:25:37,263:INFO:LinearRegression(n_jobs=-1)
2023-10-22 22:25:37,263:INFO:create_model() successfully completed......................................
2023-10-22 22:25:37,385:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:37,385:INFO:Creating metrics dataframe
2023-10-22 22:25:37,392:INFO:Initializing Lasso Regression
2023-10-22 22:25:37,392:INFO:Total runtime is 0.03325135707855224 minutes
2023-10-22 22:25:37,395:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:37,395:INFO:Initializing create_model()
2023-10-22 22:25:37,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:37,395:INFO:Checking exceptions
2023-10-22 22:25:37,395:INFO:Importing libraries
2023-10-22 22:25:37,396:INFO:Copying training dataset
2023-10-22 22:25:37,400:INFO:Defining folds
2023-10-22 22:25:37,401:INFO:Declaring metric variables
2023-10-22 22:25:37,404:INFO:Importing untrained model
2023-10-22 22:25:37,408:INFO:Lasso Regression Imported successfully
2023-10-22 22:25:37,412:INFO:Starting cross validation
2023-10-22 22:25:37,413:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:38,856:INFO:Calculating mean and std
2023-10-22 22:25:38,857:INFO:Creating metrics dataframe
2023-10-22 22:25:38,860:INFO:Uploading results into container
2023-10-22 22:25:38,860:INFO:Uploading model into container now
2023-10-22 22:25:38,860:INFO:_master_model_container: 2
2023-10-22 22:25:38,860:INFO:_display_container: 2
2023-10-22 22:25:38,861:INFO:Lasso(random_state=42)
2023-10-22 22:25:38,861:INFO:create_model() successfully completed......................................
2023-10-22 22:25:38,948:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:38,949:INFO:Creating metrics dataframe
2023-10-22 22:25:38,956:INFO:Initializing Ridge Regression
2023-10-22 22:25:38,956:INFO:Total runtime is 0.05930939118067423 minutes
2023-10-22 22:25:38,958:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:38,959:INFO:Initializing create_model()
2023-10-22 22:25:38,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:38,959:INFO:Checking exceptions
2023-10-22 22:25:38,959:INFO:Importing libraries
2023-10-22 22:25:38,959:INFO:Copying training dataset
2023-10-22 22:25:38,962:INFO:Defining folds
2023-10-22 22:25:38,962:INFO:Declaring metric variables
2023-10-22 22:25:38,965:INFO:Importing untrained model
2023-10-22 22:25:38,971:INFO:Ridge Regression Imported successfully
2023-10-22 22:25:38,975:INFO:Starting cross validation
2023-10-22 22:25:38,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:40,018:INFO:Calculating mean and std
2023-10-22 22:25:40,019:INFO:Creating metrics dataframe
2023-10-22 22:25:40,023:INFO:Uploading results into container
2023-10-22 22:25:40,023:INFO:Uploading model into container now
2023-10-22 22:25:40,024:INFO:_master_model_container: 3
2023-10-22 22:25:40,024:INFO:_display_container: 2
2023-10-22 22:25:40,024:INFO:Ridge(random_state=42)
2023-10-22 22:25:40,024:INFO:create_model() successfully completed......................................
2023-10-22 22:25:40,121:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:40,122:INFO:Creating metrics dataframe
2023-10-22 22:25:40,129:INFO:Initializing Elastic Net
2023-10-22 22:25:40,130:INFO:Total runtime is 0.07887618939081828 minutes
2023-10-22 22:25:40,132:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:40,133:INFO:Initializing create_model()
2023-10-22 22:25:40,133:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:40,133:INFO:Checking exceptions
2023-10-22 22:25:40,133:INFO:Importing libraries
2023-10-22 22:25:40,133:INFO:Copying training dataset
2023-10-22 22:25:40,137:INFO:Defining folds
2023-10-22 22:25:40,137:INFO:Declaring metric variables
2023-10-22 22:25:40,140:INFO:Importing untrained model
2023-10-22 22:25:40,142:INFO:Elastic Net Imported successfully
2023-10-22 22:25:40,146:INFO:Starting cross validation
2023-10-22 22:25:40,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:40,255:INFO:Calculating mean and std
2023-10-22 22:25:40,256:INFO:Creating metrics dataframe
2023-10-22 22:25:40,259:INFO:Uploading results into container
2023-10-22 22:25:40,259:INFO:Uploading model into container now
2023-10-22 22:25:40,259:INFO:_master_model_container: 4
2023-10-22 22:25:40,259:INFO:_display_container: 2
2023-10-22 22:25:40,259:INFO:ElasticNet(random_state=42)
2023-10-22 22:25:40,259:INFO:create_model() successfully completed......................................
2023-10-22 22:25:40,345:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:40,345:INFO:Creating metrics dataframe
2023-10-22 22:25:40,351:INFO:Initializing Least Angle Regression
2023-10-22 22:25:40,351:INFO:Total runtime is 0.08256147702534994 minutes
2023-10-22 22:25:40,354:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:40,354:INFO:Initializing create_model()
2023-10-22 22:25:40,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:40,354:INFO:Checking exceptions
2023-10-22 22:25:40,354:INFO:Importing libraries
2023-10-22 22:25:40,354:INFO:Copying training dataset
2023-10-22 22:25:40,358:INFO:Defining folds
2023-10-22 22:25:40,359:INFO:Declaring metric variables
2023-10-22 22:25:40,362:INFO:Importing untrained model
2023-10-22 22:25:40,364:INFO:Least Angle Regression Imported successfully
2023-10-22 22:25:40,370:INFO:Starting cross validation
2023-10-22 22:25:40,371:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:40,407:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,413:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,414:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,428:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,437:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,441:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,443:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,445:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,447:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,456:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.517e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:25:40,456:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.566e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:25:40,456:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.847e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:25:40,456:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.982e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:25:40,456:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.150e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:25:40,457:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,463:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.537e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:25:40,463:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.698e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:25:40,463:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.937e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:25:40,464:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.691e+01, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:25:40,464:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.411e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:25:40,483:INFO:Calculating mean and std
2023-10-22 22:25:40,484:INFO:Creating metrics dataframe
2023-10-22 22:25:40,487:INFO:Uploading results into container
2023-10-22 22:25:40,487:INFO:Uploading model into container now
2023-10-22 22:25:40,487:INFO:_master_model_container: 5
2023-10-22 22:25:40,487:INFO:_display_container: 2
2023-10-22 22:25:40,487:INFO:Lars(random_state=42)
2023-10-22 22:25:40,487:INFO:create_model() successfully completed......................................
2023-10-22 22:25:40,571:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:40,572:INFO:Creating metrics dataframe
2023-10-22 22:25:40,579:INFO:Initializing Lasso Least Angle Regression
2023-10-22 22:25:40,579:INFO:Total runtime is 0.08635574579238892 minutes
2023-10-22 22:25:40,581:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:40,581:INFO:Initializing create_model()
2023-10-22 22:25:40,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:40,581:INFO:Checking exceptions
2023-10-22 22:25:40,581:INFO:Importing libraries
2023-10-22 22:25:40,581:INFO:Copying training dataset
2023-10-22 22:25:40,584:INFO:Defining folds
2023-10-22 22:25:40,584:INFO:Declaring metric variables
2023-10-22 22:25:40,588:INFO:Importing untrained model
2023-10-22 22:25:40,591:INFO:Lasso Least Angle Regression Imported successfully
2023-10-22 22:25:40,596:INFO:Starting cross validation
2023-10-22 22:25:40,597:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:40,627:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:25:40,634:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:25:40,668:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:25:40,668:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:25:40,671:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:25:40,674:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:25:40,676:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:25:40,677:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:25:40,678:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:25:40,683:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:25:40,703:INFO:Calculating mean and std
2023-10-22 22:25:40,704:INFO:Creating metrics dataframe
2023-10-22 22:25:40,707:INFO:Uploading results into container
2023-10-22 22:25:40,707:INFO:Uploading model into container now
2023-10-22 22:25:40,707:INFO:_master_model_container: 6
2023-10-22 22:25:40,707:INFO:_display_container: 2
2023-10-22 22:25:40,708:INFO:LassoLars(random_state=42)
2023-10-22 22:25:40,708:INFO:create_model() successfully completed......................................
2023-10-22 22:25:40,795:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:40,795:INFO:Creating metrics dataframe
2023-10-22 22:25:40,803:INFO:Initializing Orthogonal Matching Pursuit
2023-10-22 22:25:40,804:INFO:Total runtime is 0.09010815223058065 minutes
2023-10-22 22:25:40,807:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:40,807:INFO:Initializing create_model()
2023-10-22 22:25:40,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:40,807:INFO:Checking exceptions
2023-10-22 22:25:40,807:INFO:Importing libraries
2023-10-22 22:25:40,807:INFO:Copying training dataset
2023-10-22 22:25:40,812:INFO:Defining folds
2023-10-22 22:25:40,812:INFO:Declaring metric variables
2023-10-22 22:25:40,815:INFO:Importing untrained model
2023-10-22 22:25:40,818:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-22 22:25:40,822:INFO:Starting cross validation
2023-10-22 22:25:40,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:40,851:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,860:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,865:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,895:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,899:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,900:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,901:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,901:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,903:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,906:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:25:40,934:INFO:Calculating mean and std
2023-10-22 22:25:40,935:INFO:Creating metrics dataframe
2023-10-22 22:25:40,937:INFO:Uploading results into container
2023-10-22 22:25:40,938:INFO:Uploading model into container now
2023-10-22 22:25:40,938:INFO:_master_model_container: 7
2023-10-22 22:25:40,938:INFO:_display_container: 2
2023-10-22 22:25:40,938:INFO:OrthogonalMatchingPursuit()
2023-10-22 22:25:40,938:INFO:create_model() successfully completed......................................
2023-10-22 22:25:41,025:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:41,025:INFO:Creating metrics dataframe
2023-10-22 22:25:41,034:INFO:Initializing Bayesian Ridge
2023-10-22 22:25:41,035:INFO:Total runtime is 0.0939559817314148 minutes
2023-10-22 22:25:41,037:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:41,038:INFO:Initializing create_model()
2023-10-22 22:25:41,038:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:41,038:INFO:Checking exceptions
2023-10-22 22:25:41,038:INFO:Importing libraries
2023-10-22 22:25:41,038:INFO:Copying training dataset
2023-10-22 22:25:41,041:INFO:Defining folds
2023-10-22 22:25:41,041:INFO:Declaring metric variables
2023-10-22 22:25:41,045:INFO:Importing untrained model
2023-10-22 22:25:41,048:INFO:Bayesian Ridge Imported successfully
2023-10-22 22:25:41,054:INFO:Starting cross validation
2023-10-22 22:25:41,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:41,167:INFO:Calculating mean and std
2023-10-22 22:25:41,168:INFO:Creating metrics dataframe
2023-10-22 22:25:41,170:INFO:Uploading results into container
2023-10-22 22:25:41,171:INFO:Uploading model into container now
2023-10-22 22:25:41,171:INFO:_master_model_container: 8
2023-10-22 22:25:41,171:INFO:_display_container: 2
2023-10-22 22:25:41,171:INFO:BayesianRidge()
2023-10-22 22:25:41,171:INFO:create_model() successfully completed......................................
2023-10-22 22:25:41,259:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:41,260:INFO:Creating metrics dataframe
2023-10-22 22:25:41,267:INFO:Initializing Passive Aggressive Regressor
2023-10-22 22:25:41,267:INFO:Total runtime is 0.09782555103302003 minutes
2023-10-22 22:25:41,269:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:41,269:INFO:Initializing create_model()
2023-10-22 22:25:41,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:41,269:INFO:Checking exceptions
2023-10-22 22:25:41,269:INFO:Importing libraries
2023-10-22 22:25:41,270:INFO:Copying training dataset
2023-10-22 22:25:41,273:INFO:Defining folds
2023-10-22 22:25:41,273:INFO:Declaring metric variables
2023-10-22 22:25:41,275:INFO:Importing untrained model
2023-10-22 22:25:41,278:INFO:Passive Aggressive Regressor Imported successfully
2023-10-22 22:25:41,281:INFO:Starting cross validation
2023-10-22 22:25:41,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:41,383:INFO:Calculating mean and std
2023-10-22 22:25:41,384:INFO:Creating metrics dataframe
2023-10-22 22:25:41,386:INFO:Uploading results into container
2023-10-22 22:25:41,386:INFO:Uploading model into container now
2023-10-22 22:25:41,387:INFO:_master_model_container: 9
2023-10-22 22:25:41,387:INFO:_display_container: 2
2023-10-22 22:25:41,387:INFO:PassiveAggressiveRegressor(random_state=42)
2023-10-22 22:25:41,387:INFO:create_model() successfully completed......................................
2023-10-22 22:25:41,470:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:41,470:INFO:Creating metrics dataframe
2023-10-22 22:25:41,478:INFO:Initializing Huber Regressor
2023-10-22 22:25:41,478:INFO:Total runtime is 0.10134182771046957 minutes
2023-10-22 22:25:41,480:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:41,480:INFO:Initializing create_model()
2023-10-22 22:25:41,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:41,480:INFO:Checking exceptions
2023-10-22 22:25:41,480:INFO:Importing libraries
2023-10-22 22:25:41,480:INFO:Copying training dataset
2023-10-22 22:25:41,482:INFO:Defining folds
2023-10-22 22:25:41,483:INFO:Declaring metric variables
2023-10-22 22:25:41,485:INFO:Importing untrained model
2023-10-22 22:25:41,487:INFO:Huber Regressor Imported successfully
2023-10-22 22:25:41,491:INFO:Starting cross validation
2023-10-22 22:25:41,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:41,557:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:25:41,558:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:25:41,559:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:25:41,573:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:25:41,589:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:25:41,592:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:25:41,594:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:25:41,596:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:25:41,598:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:25:41,602:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:25:41,614:INFO:Calculating mean and std
2023-10-22 22:25:41,614:INFO:Creating metrics dataframe
2023-10-22 22:25:41,616:INFO:Uploading results into container
2023-10-22 22:25:41,616:INFO:Uploading model into container now
2023-10-22 22:25:41,617:INFO:_master_model_container: 10
2023-10-22 22:25:41,617:INFO:_display_container: 2
2023-10-22 22:25:41,617:INFO:HuberRegressor()
2023-10-22 22:25:41,617:INFO:create_model() successfully completed......................................
2023-10-22 22:25:41,701:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:41,701:INFO:Creating metrics dataframe
2023-10-22 22:25:41,707:INFO:Initializing K Neighbors Regressor
2023-10-22 22:25:41,707:INFO:Total runtime is 0.10516930023829142 minutes
2023-10-22 22:25:41,709:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:41,710:INFO:Initializing create_model()
2023-10-22 22:25:41,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:41,710:INFO:Checking exceptions
2023-10-22 22:25:41,710:INFO:Importing libraries
2023-10-22 22:25:41,710:INFO:Copying training dataset
2023-10-22 22:25:41,713:INFO:Defining folds
2023-10-22 22:25:41,713:INFO:Declaring metric variables
2023-10-22 22:25:41,715:INFO:Importing untrained model
2023-10-22 22:25:41,717:INFO:K Neighbors Regressor Imported successfully
2023-10-22 22:25:41,721:INFO:Starting cross validation
2023-10-22 22:25:41,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:41,854:INFO:Calculating mean and std
2023-10-22 22:25:41,855:INFO:Creating metrics dataframe
2023-10-22 22:25:41,857:INFO:Uploading results into container
2023-10-22 22:25:41,857:INFO:Uploading model into container now
2023-10-22 22:25:41,858:INFO:_master_model_container: 11
2023-10-22 22:25:41,858:INFO:_display_container: 2
2023-10-22 22:25:41,858:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-22 22:25:41,858:INFO:create_model() successfully completed......................................
2023-10-22 22:25:41,947:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:41,947:INFO:Creating metrics dataframe
2023-10-22 22:25:41,955:INFO:Initializing Decision Tree Regressor
2023-10-22 22:25:41,955:INFO:Total runtime is 0.10929452180862427 minutes
2023-10-22 22:25:41,957:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:41,957:INFO:Initializing create_model()
2023-10-22 22:25:41,957:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:41,958:INFO:Checking exceptions
2023-10-22 22:25:41,958:INFO:Importing libraries
2023-10-22 22:25:41,958:INFO:Copying training dataset
2023-10-22 22:25:41,961:INFO:Defining folds
2023-10-22 22:25:41,961:INFO:Declaring metric variables
2023-10-22 22:25:41,964:INFO:Importing untrained model
2023-10-22 22:25:41,967:INFO:Decision Tree Regressor Imported successfully
2023-10-22 22:25:41,971:INFO:Starting cross validation
2023-10-22 22:25:41,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:42,107:INFO:Calculating mean and std
2023-10-22 22:25:42,108:INFO:Creating metrics dataframe
2023-10-22 22:25:42,111:INFO:Uploading results into container
2023-10-22 22:25:42,111:INFO:Uploading model into container now
2023-10-22 22:25:42,112:INFO:_master_model_container: 12
2023-10-22 22:25:42,112:INFO:_display_container: 2
2023-10-22 22:25:42,112:INFO:DecisionTreeRegressor(random_state=42)
2023-10-22 22:25:42,112:INFO:create_model() successfully completed......................................
2023-10-22 22:25:42,211:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:42,211:INFO:Creating metrics dataframe
2023-10-22 22:25:42,219:INFO:Initializing Random Forest Regressor
2023-10-22 22:25:42,219:INFO:Total runtime is 0.11370153427124023 minutes
2023-10-22 22:25:42,222:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:42,222:INFO:Initializing create_model()
2023-10-22 22:25:42,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:42,222:INFO:Checking exceptions
2023-10-22 22:25:42,222:INFO:Importing libraries
2023-10-22 22:25:42,222:INFO:Copying training dataset
2023-10-22 22:25:42,225:INFO:Defining folds
2023-10-22 22:25:42,226:INFO:Declaring metric variables
2023-10-22 22:25:42,229:INFO:Importing untrained model
2023-10-22 22:25:42,232:INFO:Random Forest Regressor Imported successfully
2023-10-22 22:25:42,236:INFO:Starting cross validation
2023-10-22 22:25:42,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:42,811:INFO:Calculating mean and std
2023-10-22 22:25:42,813:INFO:Creating metrics dataframe
2023-10-22 22:25:42,815:INFO:Uploading results into container
2023-10-22 22:25:42,816:INFO:Uploading model into container now
2023-10-22 22:25:42,816:INFO:_master_model_container: 13
2023-10-22 22:25:42,816:INFO:_display_container: 2
2023-10-22 22:25:42,816:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-10-22 22:25:42,816:INFO:create_model() successfully completed......................................
2023-10-22 22:25:42,916:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:42,916:INFO:Creating metrics dataframe
2023-10-22 22:25:42,925:INFO:Initializing Extra Trees Regressor
2023-10-22 22:25:42,925:INFO:Total runtime is 0.12546048561731973 minutes
2023-10-22 22:25:42,928:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:42,928:INFO:Initializing create_model()
2023-10-22 22:25:42,928:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:42,928:INFO:Checking exceptions
2023-10-22 22:25:42,928:INFO:Importing libraries
2023-10-22 22:25:42,928:INFO:Copying training dataset
2023-10-22 22:25:42,932:INFO:Defining folds
2023-10-22 22:25:42,933:INFO:Declaring metric variables
2023-10-22 22:25:42,935:INFO:Importing untrained model
2023-10-22 22:25:42,937:INFO:Extra Trees Regressor Imported successfully
2023-10-22 22:25:42,941:INFO:Starting cross validation
2023-10-22 22:25:42,942:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:43,406:INFO:Calculating mean and std
2023-10-22 22:25:43,407:INFO:Creating metrics dataframe
2023-10-22 22:25:43,409:INFO:Uploading results into container
2023-10-22 22:25:43,410:INFO:Uploading model into container now
2023-10-22 22:25:43,410:INFO:_master_model_container: 14
2023-10-22 22:25:43,410:INFO:_display_container: 2
2023-10-22 22:25:43,410:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-10-22 22:25:43,410:INFO:create_model() successfully completed......................................
2023-10-22 22:25:43,508:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:43,508:INFO:Creating metrics dataframe
2023-10-22 22:25:43,518:INFO:Initializing AdaBoost Regressor
2023-10-22 22:25:43,518:INFO:Total runtime is 0.13535352945327758 minutes
2023-10-22 22:25:43,521:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:43,521:INFO:Initializing create_model()
2023-10-22 22:25:43,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:43,521:INFO:Checking exceptions
2023-10-22 22:25:43,521:INFO:Importing libraries
2023-10-22 22:25:43,521:INFO:Copying training dataset
2023-10-22 22:25:43,525:INFO:Defining folds
2023-10-22 22:25:43,526:INFO:Declaring metric variables
2023-10-22 22:25:43,529:INFO:Importing untrained model
2023-10-22 22:25:43,532:INFO:AdaBoost Regressor Imported successfully
2023-10-22 22:25:43,536:INFO:Starting cross validation
2023-10-22 22:25:43,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:43,708:INFO:Calculating mean and std
2023-10-22 22:25:43,709:INFO:Creating metrics dataframe
2023-10-22 22:25:43,711:INFO:Uploading results into container
2023-10-22 22:25:43,712:INFO:Uploading model into container now
2023-10-22 22:25:43,712:INFO:_master_model_container: 15
2023-10-22 22:25:43,712:INFO:_display_container: 2
2023-10-22 22:25:43,712:INFO:AdaBoostRegressor(random_state=42)
2023-10-22 22:25:43,712:INFO:create_model() successfully completed......................................
2023-10-22 22:25:43,812:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:43,812:INFO:Creating metrics dataframe
2023-10-22 22:25:43,823:INFO:Initializing Gradient Boosting Regressor
2023-10-22 22:25:43,823:INFO:Total runtime is 0.140435520807902 minutes
2023-10-22 22:25:43,826:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:43,827:INFO:Initializing create_model()
2023-10-22 22:25:43,827:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:43,827:INFO:Checking exceptions
2023-10-22 22:25:43,827:INFO:Importing libraries
2023-10-22 22:25:43,827:INFO:Copying training dataset
2023-10-22 22:25:43,830:INFO:Defining folds
2023-10-22 22:25:43,830:INFO:Declaring metric variables
2023-10-22 22:25:43,832:INFO:Importing untrained model
2023-10-22 22:25:43,834:INFO:Gradient Boosting Regressor Imported successfully
2023-10-22 22:25:43,840:INFO:Starting cross validation
2023-10-22 22:25:43,841:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:44,059:INFO:Calculating mean and std
2023-10-22 22:25:44,060:INFO:Creating metrics dataframe
2023-10-22 22:25:44,063:INFO:Uploading results into container
2023-10-22 22:25:44,064:INFO:Uploading model into container now
2023-10-22 22:25:44,064:INFO:_master_model_container: 16
2023-10-22 22:25:44,064:INFO:_display_container: 2
2023-10-22 22:25:44,064:INFO:GradientBoostingRegressor(random_state=42)
2023-10-22 22:25:44,064:INFO:create_model() successfully completed......................................
2023-10-22 22:25:44,164:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:44,164:INFO:Creating metrics dataframe
2023-10-22 22:25:44,173:INFO:Initializing Extreme Gradient Boosting
2023-10-22 22:25:44,174:INFO:Total runtime is 0.14627190430959064 minutes
2023-10-22 22:25:44,176:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:44,177:INFO:Initializing create_model()
2023-10-22 22:25:44,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:44,177:INFO:Checking exceptions
2023-10-22 22:25:44,177:INFO:Importing libraries
2023-10-22 22:25:44,177:INFO:Copying training dataset
2023-10-22 22:25:44,181:INFO:Defining folds
2023-10-22 22:25:44,181:INFO:Declaring metric variables
2023-10-22 22:25:44,185:INFO:Importing untrained model
2023-10-22 22:25:44,187:INFO:Extreme Gradient Boosting Imported successfully
2023-10-22 22:25:44,192:INFO:Starting cross validation
2023-10-22 22:25:44,193:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:25:44,593:INFO:Calculating mean and std
2023-10-22 22:25:44,594:INFO:Creating metrics dataframe
2023-10-22 22:25:44,596:INFO:Uploading results into container
2023-10-22 22:25:44,597:INFO:Uploading model into container now
2023-10-22 22:25:44,597:INFO:_master_model_container: 17
2023-10-22 22:25:44,597:INFO:_display_container: 2
2023-10-22 22:25:44,598:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2023-10-22 22:25:44,598:INFO:create_model() successfully completed......................................
2023-10-22 22:25:44,692:INFO:SubProcess create_model() end ==================================
2023-10-22 22:25:44,693:INFO:Creating metrics dataframe
2023-10-22 22:25:44,702:INFO:Initializing Light Gradient Boosting Machine
2023-10-22 22:25:44,702:INFO:Total runtime is 0.15507697661717731 minutes
2023-10-22 22:25:44,706:INFO:SubProcess create_model() called ==================================
2023-10-22 22:25:44,706:INFO:Initializing create_model()
2023-10-22 22:25:44,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746f265f0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:25:44,706:INFO:Checking exceptions
2023-10-22 22:25:44,706:INFO:Importing libraries
2023-10-22 22:25:44,706:INFO:Copying training dataset
2023-10-22 22:25:44,710:INFO:Defining folds
2023-10-22 22:25:44,710:INFO:Declaring metric variables
2023-10-22 22:25:44,712:INFO:Importing untrained model
2023-10-22 22:25:44,714:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-22 22:25:44,718:INFO:Starting cross validation
2023-10-22 22:25:44,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:03,506:INFO:Initializing compare_models()
2023-10-22 22:45:03,508:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-22 22:45:03,508:INFO:Checking exceptions
2023-10-22 22:45:03,510:INFO:Preparing display monitor
2023-10-22 22:45:03,535:INFO:Initializing Linear Regression
2023-10-22 22:45:03,535:INFO:Total runtime is 3.8027763366699217e-06 minutes
2023-10-22 22:45:03,538:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:03,539:INFO:Initializing create_model()
2023-10-22 22:45:03,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:03,539:INFO:Checking exceptions
2023-10-22 22:45:03,539:INFO:Importing libraries
2023-10-22 22:45:03,539:INFO:Copying training dataset
2023-10-22 22:45:03,542:INFO:Defining folds
2023-10-22 22:45:03,542:INFO:Declaring metric variables
2023-10-22 22:45:03,544:INFO:Importing untrained model
2023-10-22 22:45:03,547:INFO:Linear Regression Imported successfully
2023-10-22 22:45:03,552:INFO:Starting cross validation
2023-10-22 22:45:03,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:05,600:INFO:Calculating mean and std
2023-10-22 22:45:05,604:INFO:Creating metrics dataframe
2023-10-22 22:45:05,612:INFO:Uploading results into container
2023-10-22 22:45:05,614:INFO:Uploading model into container now
2023-10-22 22:45:05,615:INFO:_master_model_container: 18
2023-10-22 22:45:05,615:INFO:_display_container: 2
2023-10-22 22:45:05,616:INFO:LinearRegression(n_jobs=-1)
2023-10-22 22:45:05,616:INFO:create_model() successfully completed......................................
2023-10-22 22:45:05,792:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:05,792:INFO:Creating metrics dataframe
2023-10-22 22:45:05,799:INFO:Initializing Lasso Regression
2023-10-22 22:45:05,799:INFO:Total runtime is 0.03773802121480306 minutes
2023-10-22 22:45:05,801:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:05,802:INFO:Initializing create_model()
2023-10-22 22:45:05,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:05,802:INFO:Checking exceptions
2023-10-22 22:45:05,802:INFO:Importing libraries
2023-10-22 22:45:05,802:INFO:Copying training dataset
2023-10-22 22:45:05,805:INFO:Defining folds
2023-10-22 22:45:05,805:INFO:Declaring metric variables
2023-10-22 22:45:05,807:INFO:Importing untrained model
2023-10-22 22:45:05,811:INFO:Lasso Regression Imported successfully
2023-10-22 22:45:05,817:INFO:Starting cross validation
2023-10-22 22:45:05,818:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:07,938:INFO:Calculating mean and std
2023-10-22 22:45:07,942:INFO:Creating metrics dataframe
2023-10-22 22:45:07,947:INFO:Uploading results into container
2023-10-22 22:45:07,948:INFO:Uploading model into container now
2023-10-22 22:45:07,949:INFO:_master_model_container: 19
2023-10-22 22:45:07,950:INFO:_display_container: 2
2023-10-22 22:45:07,950:INFO:Lasso(random_state=42)
2023-10-22 22:45:07,950:INFO:create_model() successfully completed......................................
2023-10-22 22:45:08,116:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:08,116:INFO:Creating metrics dataframe
2023-10-22 22:45:08,125:INFO:Initializing Ridge Regression
2023-10-22 22:45:08,125:INFO:Total runtime is 0.07650444507598878 minutes
2023-10-22 22:45:08,128:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:08,129:INFO:Initializing create_model()
2023-10-22 22:45:08,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:08,129:INFO:Checking exceptions
2023-10-22 22:45:08,129:INFO:Importing libraries
2023-10-22 22:45:08,129:INFO:Copying training dataset
2023-10-22 22:45:08,132:INFO:Defining folds
2023-10-22 22:45:08,133:INFO:Declaring metric variables
2023-10-22 22:45:08,135:INFO:Importing untrained model
2023-10-22 22:45:08,139:INFO:Ridge Regression Imported successfully
2023-10-22 22:45:08,145:INFO:Starting cross validation
2023-10-22 22:45:08,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:09,398:INFO:Calculating mean and std
2023-10-22 22:45:09,399:INFO:Creating metrics dataframe
2023-10-22 22:45:09,402:INFO:Uploading results into container
2023-10-22 22:45:09,404:INFO:Uploading model into container now
2023-10-22 22:45:09,404:INFO:_master_model_container: 20
2023-10-22 22:45:09,404:INFO:_display_container: 2
2023-10-22 22:45:09,404:INFO:Ridge(random_state=42)
2023-10-22 22:45:09,404:INFO:create_model() successfully completed......................................
2023-10-22 22:45:09,554:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:09,554:INFO:Creating metrics dataframe
2023-10-22 22:45:09,562:INFO:Initializing Elastic Net
2023-10-22 22:45:09,562:INFO:Total runtime is 0.10045998096466065 minutes
2023-10-22 22:45:09,565:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:09,565:INFO:Initializing create_model()
2023-10-22 22:45:09,565:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:09,565:INFO:Checking exceptions
2023-10-22 22:45:09,565:INFO:Importing libraries
2023-10-22 22:45:09,565:INFO:Copying training dataset
2023-10-22 22:45:09,570:INFO:Defining folds
2023-10-22 22:45:09,570:INFO:Declaring metric variables
2023-10-22 22:45:09,577:INFO:Importing untrained model
2023-10-22 22:45:09,580:INFO:Elastic Net Imported successfully
2023-10-22 22:45:09,587:INFO:Starting cross validation
2023-10-22 22:45:09,588:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:09,700:INFO:Calculating mean and std
2023-10-22 22:45:09,701:INFO:Creating metrics dataframe
2023-10-22 22:45:09,703:INFO:Uploading results into container
2023-10-22 22:45:09,704:INFO:Uploading model into container now
2023-10-22 22:45:09,704:INFO:_master_model_container: 21
2023-10-22 22:45:09,704:INFO:_display_container: 2
2023-10-22 22:45:09,704:INFO:ElasticNet(random_state=42)
2023-10-22 22:45:09,704:INFO:create_model() successfully completed......................................
2023-10-22 22:45:09,836:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:09,837:INFO:Creating metrics dataframe
2023-10-22 22:45:09,846:INFO:Initializing Least Angle Regression
2023-10-22 22:45:09,846:INFO:Total runtime is 0.10518919626871745 minutes
2023-10-22 22:45:09,848:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:09,849:INFO:Initializing create_model()
2023-10-22 22:45:09,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:09,849:INFO:Checking exceptions
2023-10-22 22:45:09,849:INFO:Importing libraries
2023-10-22 22:45:09,849:INFO:Copying training dataset
2023-10-22 22:45:09,852:INFO:Defining folds
2023-10-22 22:45:09,852:INFO:Declaring metric variables
2023-10-22 22:45:09,855:INFO:Importing untrained model
2023-10-22 22:45:09,858:INFO:Least Angle Regression Imported successfully
2023-10-22 22:45:09,862:INFO:Starting cross validation
2023-10-22 22:45:09,863:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:09,900:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:09,901:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:09,910:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.537e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:45:09,910:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.698e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:45:09,911:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.937e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:45:09,911:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.691e+01, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:45:09,911:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.411e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:45:09,914:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:09,916:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:09,917:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:09,917:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:09,926:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:09,928:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:09,929:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.517e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:45:09,930:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.566e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:45:09,930:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.847e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:45:09,930:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.982e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:45:09,930:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.150e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:45:09,931:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:09,937:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:09,966:INFO:Calculating mean and std
2023-10-22 22:45:09,967:INFO:Creating metrics dataframe
2023-10-22 22:45:09,970:INFO:Uploading results into container
2023-10-22 22:45:09,971:INFO:Uploading model into container now
2023-10-22 22:45:09,971:INFO:_master_model_container: 22
2023-10-22 22:45:09,972:INFO:_display_container: 2
2023-10-22 22:45:09,973:INFO:Lars(random_state=42)
2023-10-22 22:45:09,973:INFO:create_model() successfully completed......................................
2023-10-22 22:45:10,102:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:10,102:INFO:Creating metrics dataframe
2023-10-22 22:45:10,110:INFO:Initializing Lasso Least Angle Regression
2023-10-22 22:45:10,110:INFO:Total runtime is 0.10959332784016927 minutes
2023-10-22 22:45:10,113:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:10,113:INFO:Initializing create_model()
2023-10-22 22:45:10,113:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:10,113:INFO:Checking exceptions
2023-10-22 22:45:10,113:INFO:Importing libraries
2023-10-22 22:45:10,113:INFO:Copying training dataset
2023-10-22 22:45:10,117:INFO:Defining folds
2023-10-22 22:45:10,117:INFO:Declaring metric variables
2023-10-22 22:45:10,120:INFO:Importing untrained model
2023-10-22 22:45:10,124:INFO:Lasso Least Angle Regression Imported successfully
2023-10-22 22:45:10,131:INFO:Starting cross validation
2023-10-22 22:45:10,131:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:10,168:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:45:10,171:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:45:10,178:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:45:10,181:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:45:10,183:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:45:10,184:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:45:10,194:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:45:10,197:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:45:10,198:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:45:10,199:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:45:10,220:INFO:Calculating mean and std
2023-10-22 22:45:10,222:INFO:Creating metrics dataframe
2023-10-22 22:45:10,224:INFO:Uploading results into container
2023-10-22 22:45:10,225:INFO:Uploading model into container now
2023-10-22 22:45:10,225:INFO:_master_model_container: 23
2023-10-22 22:45:10,225:INFO:_display_container: 2
2023-10-22 22:45:10,225:INFO:LassoLars(random_state=42)
2023-10-22 22:45:10,225:INFO:create_model() successfully completed......................................
2023-10-22 22:45:10,337:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:10,337:INFO:Creating metrics dataframe
2023-10-22 22:45:10,347:INFO:Initializing Orthogonal Matching Pursuit
2023-10-22 22:45:10,347:INFO:Total runtime is 0.11353342533111573 minutes
2023-10-22 22:45:10,350:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:10,350:INFO:Initializing create_model()
2023-10-22 22:45:10,350:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:10,350:INFO:Checking exceptions
2023-10-22 22:45:10,350:INFO:Importing libraries
2023-10-22 22:45:10,350:INFO:Copying training dataset
2023-10-22 22:45:10,353:INFO:Defining folds
2023-10-22 22:45:10,354:INFO:Declaring metric variables
2023-10-22 22:45:10,357:INFO:Importing untrained model
2023-10-22 22:45:10,359:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-22 22:45:10,363:INFO:Starting cross validation
2023-10-22 22:45:10,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:10,397:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:10,397:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:10,400:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:10,409:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:10,420:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:10,425:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:10,432:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:10,439:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:10,456:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:10,463:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:45:10,485:INFO:Calculating mean and std
2023-10-22 22:45:10,486:INFO:Creating metrics dataframe
2023-10-22 22:45:10,488:INFO:Uploading results into container
2023-10-22 22:45:10,489:INFO:Uploading model into container now
2023-10-22 22:45:10,489:INFO:_master_model_container: 24
2023-10-22 22:45:10,489:INFO:_display_container: 2
2023-10-22 22:45:10,490:INFO:OrthogonalMatchingPursuit()
2023-10-22 22:45:10,490:INFO:create_model() successfully completed......................................
2023-10-22 22:45:10,600:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:10,601:INFO:Creating metrics dataframe
2023-10-22 22:45:10,610:INFO:Initializing Bayesian Ridge
2023-10-22 22:45:10,610:INFO:Total runtime is 0.1179150382677714 minutes
2023-10-22 22:45:10,612:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:10,612:INFO:Initializing create_model()
2023-10-22 22:45:10,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:10,612:INFO:Checking exceptions
2023-10-22 22:45:10,612:INFO:Importing libraries
2023-10-22 22:45:10,612:INFO:Copying training dataset
2023-10-22 22:45:10,615:INFO:Defining folds
2023-10-22 22:45:10,615:INFO:Declaring metric variables
2023-10-22 22:45:10,618:INFO:Importing untrained model
2023-10-22 22:45:10,620:INFO:Bayesian Ridge Imported successfully
2023-10-22 22:45:10,628:INFO:Starting cross validation
2023-10-22 22:45:10,629:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:10,736:INFO:Calculating mean and std
2023-10-22 22:45:10,737:INFO:Creating metrics dataframe
2023-10-22 22:45:10,739:INFO:Uploading results into container
2023-10-22 22:45:10,740:INFO:Uploading model into container now
2023-10-22 22:45:10,740:INFO:_master_model_container: 25
2023-10-22 22:45:10,740:INFO:_display_container: 2
2023-10-22 22:45:10,740:INFO:BayesianRidge()
2023-10-22 22:45:10,740:INFO:create_model() successfully completed......................................
2023-10-22 22:45:10,852:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:10,852:INFO:Creating metrics dataframe
2023-10-22 22:45:10,866:INFO:Initializing Passive Aggressive Regressor
2023-10-22 22:45:10,866:INFO:Total runtime is 0.12219043970108032 minutes
2023-10-22 22:45:10,870:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:10,870:INFO:Initializing create_model()
2023-10-22 22:45:10,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:10,870:INFO:Checking exceptions
2023-10-22 22:45:10,870:INFO:Importing libraries
2023-10-22 22:45:10,870:INFO:Copying training dataset
2023-10-22 22:45:10,881:INFO:Defining folds
2023-10-22 22:45:10,882:INFO:Declaring metric variables
2023-10-22 22:45:10,884:INFO:Importing untrained model
2023-10-22 22:45:10,892:INFO:Passive Aggressive Regressor Imported successfully
2023-10-22 22:45:10,902:INFO:Starting cross validation
2023-10-22 22:45:10,903:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:11,001:INFO:Calculating mean and std
2023-10-22 22:45:11,002:INFO:Creating metrics dataframe
2023-10-22 22:45:11,005:INFO:Uploading results into container
2023-10-22 22:45:11,005:INFO:Uploading model into container now
2023-10-22 22:45:11,006:INFO:_master_model_container: 26
2023-10-22 22:45:11,006:INFO:_display_container: 2
2023-10-22 22:45:11,006:INFO:PassiveAggressiveRegressor(random_state=42)
2023-10-22 22:45:11,006:INFO:create_model() successfully completed......................................
2023-10-22 22:45:11,118:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:11,119:INFO:Creating metrics dataframe
2023-10-22 22:45:11,126:INFO:Initializing Huber Regressor
2023-10-22 22:45:11,126:INFO:Total runtime is 0.12651800314585368 minutes
2023-10-22 22:45:11,128:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:11,128:INFO:Initializing create_model()
2023-10-22 22:45:11,128:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:11,128:INFO:Checking exceptions
2023-10-22 22:45:11,128:INFO:Importing libraries
2023-10-22 22:45:11,128:INFO:Copying training dataset
2023-10-22 22:45:11,131:INFO:Defining folds
2023-10-22 22:45:11,131:INFO:Declaring metric variables
2023-10-22 22:45:11,133:INFO:Importing untrained model
2023-10-22 22:45:11,136:INFO:Huber Regressor Imported successfully
2023-10-22 22:45:11,143:INFO:Starting cross validation
2023-10-22 22:45:11,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:11,189:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:45:11,218:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:45:11,219:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:45:11,231:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:45:11,243:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:45:11,243:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:45:11,244:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:45:11,244:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:45:11,257:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:45:11,262:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:45:11,277:INFO:Calculating mean and std
2023-10-22 22:45:11,278:INFO:Creating metrics dataframe
2023-10-22 22:45:11,280:INFO:Uploading results into container
2023-10-22 22:45:11,280:INFO:Uploading model into container now
2023-10-22 22:45:11,281:INFO:_master_model_container: 27
2023-10-22 22:45:11,281:INFO:_display_container: 2
2023-10-22 22:45:11,281:INFO:HuberRegressor()
2023-10-22 22:45:11,281:INFO:create_model() successfully completed......................................
2023-10-22 22:45:11,393:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:11,393:INFO:Creating metrics dataframe
2023-10-22 22:45:11,400:INFO:Initializing K Neighbors Regressor
2023-10-22 22:45:11,400:INFO:Total runtime is 0.131081489721934 minutes
2023-10-22 22:45:11,402:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:11,402:INFO:Initializing create_model()
2023-10-22 22:45:11,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:11,402:INFO:Checking exceptions
2023-10-22 22:45:11,402:INFO:Importing libraries
2023-10-22 22:45:11,402:INFO:Copying training dataset
2023-10-22 22:45:11,406:INFO:Defining folds
2023-10-22 22:45:11,406:INFO:Declaring metric variables
2023-10-22 22:45:11,408:INFO:Importing untrained model
2023-10-22 22:45:11,410:INFO:K Neighbors Regressor Imported successfully
2023-10-22 22:45:11,415:INFO:Starting cross validation
2023-10-22 22:45:11,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:11,531:INFO:Calculating mean and std
2023-10-22 22:45:11,532:INFO:Creating metrics dataframe
2023-10-22 22:45:11,535:INFO:Uploading results into container
2023-10-22 22:45:11,536:INFO:Uploading model into container now
2023-10-22 22:45:11,536:INFO:_master_model_container: 28
2023-10-22 22:45:11,536:INFO:_display_container: 2
2023-10-22 22:45:11,536:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-22 22:45:11,537:INFO:create_model() successfully completed......................................
2023-10-22 22:45:11,651:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:11,651:INFO:Creating metrics dataframe
2023-10-22 22:45:11,657:INFO:Initializing Decision Tree Regressor
2023-10-22 22:45:11,658:INFO:Total runtime is 0.13538109461466472 minutes
2023-10-22 22:45:11,660:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:11,660:INFO:Initializing create_model()
2023-10-22 22:45:11,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:11,660:INFO:Checking exceptions
2023-10-22 22:45:11,660:INFO:Importing libraries
2023-10-22 22:45:11,660:INFO:Copying training dataset
2023-10-22 22:45:11,663:INFO:Defining folds
2023-10-22 22:45:11,663:INFO:Declaring metric variables
2023-10-22 22:45:11,666:INFO:Importing untrained model
2023-10-22 22:45:11,668:INFO:Decision Tree Regressor Imported successfully
2023-10-22 22:45:11,672:INFO:Starting cross validation
2023-10-22 22:45:11,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:11,790:INFO:Calculating mean and std
2023-10-22 22:45:11,792:INFO:Creating metrics dataframe
2023-10-22 22:45:11,794:INFO:Uploading results into container
2023-10-22 22:45:11,794:INFO:Uploading model into container now
2023-10-22 22:45:11,795:INFO:_master_model_container: 29
2023-10-22 22:45:11,795:INFO:_display_container: 2
2023-10-22 22:45:11,795:INFO:DecisionTreeRegressor(random_state=42)
2023-10-22 22:45:11,795:INFO:create_model() successfully completed......................................
2023-10-22 22:45:11,906:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:11,906:INFO:Creating metrics dataframe
2023-10-22 22:45:11,913:INFO:Initializing Random Forest Regressor
2023-10-22 22:45:11,913:INFO:Total runtime is 0.13963896830876668 minutes
2023-10-22 22:45:11,915:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:11,916:INFO:Initializing create_model()
2023-10-22 22:45:11,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:11,916:INFO:Checking exceptions
2023-10-22 22:45:11,916:INFO:Importing libraries
2023-10-22 22:45:11,916:INFO:Copying training dataset
2023-10-22 22:45:11,919:INFO:Defining folds
2023-10-22 22:45:11,919:INFO:Declaring metric variables
2023-10-22 22:45:11,921:INFO:Importing untrained model
2023-10-22 22:45:11,924:INFO:Random Forest Regressor Imported successfully
2023-10-22 22:45:11,930:INFO:Starting cross validation
2023-10-22 22:45:11,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:12,534:INFO:Calculating mean and std
2023-10-22 22:45:12,536:INFO:Creating metrics dataframe
2023-10-22 22:45:12,539:INFO:Uploading results into container
2023-10-22 22:45:12,540:INFO:Uploading model into container now
2023-10-22 22:45:12,540:INFO:_master_model_container: 30
2023-10-22 22:45:12,540:INFO:_display_container: 2
2023-10-22 22:45:12,540:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-10-22 22:45:12,540:INFO:create_model() successfully completed......................................
2023-10-22 22:45:12,674:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:12,675:INFO:Creating metrics dataframe
2023-10-22 22:45:12,684:INFO:Initializing Extra Trees Regressor
2023-10-22 22:45:12,684:INFO:Total runtime is 0.1524820566177368 minutes
2023-10-22 22:45:12,686:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:12,686:INFO:Initializing create_model()
2023-10-22 22:45:12,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:12,686:INFO:Checking exceptions
2023-10-22 22:45:12,686:INFO:Importing libraries
2023-10-22 22:45:12,686:INFO:Copying training dataset
2023-10-22 22:45:12,689:INFO:Defining folds
2023-10-22 22:45:12,690:INFO:Declaring metric variables
2023-10-22 22:45:12,692:INFO:Importing untrained model
2023-10-22 22:45:12,694:INFO:Extra Trees Regressor Imported successfully
2023-10-22 22:45:12,697:INFO:Starting cross validation
2023-10-22 22:45:12,698:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:13,182:INFO:Calculating mean and std
2023-10-22 22:45:13,183:INFO:Creating metrics dataframe
2023-10-22 22:45:13,186:INFO:Uploading results into container
2023-10-22 22:45:13,186:INFO:Uploading model into container now
2023-10-22 22:45:13,187:INFO:_master_model_container: 31
2023-10-22 22:45:13,187:INFO:_display_container: 2
2023-10-22 22:45:13,187:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-10-22 22:45:13,187:INFO:create_model() successfully completed......................................
2023-10-22 22:45:13,297:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:13,298:INFO:Creating metrics dataframe
2023-10-22 22:45:13,306:INFO:Initializing AdaBoost Regressor
2023-10-22 22:45:13,306:INFO:Total runtime is 0.16285982926686604 minutes
2023-10-22 22:45:13,308:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:13,309:INFO:Initializing create_model()
2023-10-22 22:45:13,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:13,309:INFO:Checking exceptions
2023-10-22 22:45:13,309:INFO:Importing libraries
2023-10-22 22:45:13,309:INFO:Copying training dataset
2023-10-22 22:45:13,311:INFO:Defining folds
2023-10-22 22:45:13,312:INFO:Declaring metric variables
2023-10-22 22:45:13,314:INFO:Importing untrained model
2023-10-22 22:45:13,317:INFO:AdaBoost Regressor Imported successfully
2023-10-22 22:45:13,322:INFO:Starting cross validation
2023-10-22 22:45:13,323:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:13,523:INFO:Calculating mean and std
2023-10-22 22:45:13,525:INFO:Creating metrics dataframe
2023-10-22 22:45:13,527:INFO:Uploading results into container
2023-10-22 22:45:13,527:INFO:Uploading model into container now
2023-10-22 22:45:13,528:INFO:_master_model_container: 32
2023-10-22 22:45:13,528:INFO:_display_container: 2
2023-10-22 22:45:13,528:INFO:AdaBoostRegressor(random_state=42)
2023-10-22 22:45:13,528:INFO:create_model() successfully completed......................................
2023-10-22 22:45:13,638:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:13,638:INFO:Creating metrics dataframe
2023-10-22 22:45:13,648:INFO:Initializing Gradient Boosting Regressor
2023-10-22 22:45:13,648:INFO:Total runtime is 0.16855424642562866 minutes
2023-10-22 22:45:13,651:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:13,651:INFO:Initializing create_model()
2023-10-22 22:45:13,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:13,651:INFO:Checking exceptions
2023-10-22 22:45:13,651:INFO:Importing libraries
2023-10-22 22:45:13,651:INFO:Copying training dataset
2023-10-22 22:45:13,655:INFO:Defining folds
2023-10-22 22:45:13,655:INFO:Declaring metric variables
2023-10-22 22:45:13,657:INFO:Importing untrained model
2023-10-22 22:45:13,659:INFO:Gradient Boosting Regressor Imported successfully
2023-10-22 22:45:13,664:INFO:Starting cross validation
2023-10-22 22:45:13,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:13,886:INFO:Calculating mean and std
2023-10-22 22:45:13,887:INFO:Creating metrics dataframe
2023-10-22 22:45:13,889:INFO:Uploading results into container
2023-10-22 22:45:13,890:INFO:Uploading model into container now
2023-10-22 22:45:13,890:INFO:_master_model_container: 33
2023-10-22 22:45:13,890:INFO:_display_container: 2
2023-10-22 22:45:13,890:INFO:GradientBoostingRegressor(random_state=42)
2023-10-22 22:45:13,890:INFO:create_model() successfully completed......................................
2023-10-22 22:45:13,998:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:13,998:INFO:Creating metrics dataframe
2023-10-22 22:45:14,008:INFO:Initializing Extreme Gradient Boosting
2023-10-22 22:45:14,008:INFO:Total runtime is 0.17455395062764487 minutes
2023-10-22 22:45:14,010:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:14,010:INFO:Initializing create_model()
2023-10-22 22:45:14,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:14,010:INFO:Checking exceptions
2023-10-22 22:45:14,010:INFO:Importing libraries
2023-10-22 22:45:14,010:INFO:Copying training dataset
2023-10-22 22:45:14,013:INFO:Defining folds
2023-10-22 22:45:14,016:INFO:Declaring metric variables
2023-10-22 22:45:14,018:INFO:Importing untrained model
2023-10-22 22:45:14,021:INFO:Extreme Gradient Boosting Imported successfully
2023-10-22 22:45:14,025:INFO:Starting cross validation
2023-10-22 22:45:14,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:45:14,532:INFO:Calculating mean and std
2023-10-22 22:45:14,533:INFO:Creating metrics dataframe
2023-10-22 22:45:14,545:INFO:Uploading results into container
2023-10-22 22:45:14,546:INFO:Uploading model into container now
2023-10-22 22:45:14,546:INFO:_master_model_container: 34
2023-10-22 22:45:14,546:INFO:_display_container: 2
2023-10-22 22:45:14,547:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2023-10-22 22:45:14,547:INFO:create_model() successfully completed......................................
2023-10-22 22:45:14,660:INFO:SubProcess create_model() end ==================================
2023-10-22 22:45:14,660:INFO:Creating metrics dataframe
2023-10-22 22:45:14,668:INFO:Initializing Light Gradient Boosting Machine
2023-10-22 22:45:14,668:INFO:Total runtime is 0.1855513691902161 minutes
2023-10-22 22:45:14,670:INFO:SubProcess create_model() called ==================================
2023-10-22 22:45:14,670:INFO:Initializing create_model()
2023-10-22 22:45:14,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f9746fdc550>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:45:14,670:INFO:Checking exceptions
2023-10-22 22:45:14,670:INFO:Importing libraries
2023-10-22 22:45:14,670:INFO:Copying training dataset
2023-10-22 22:45:14,674:INFO:Defining folds
2023-10-22 22:45:14,674:INFO:Declaring metric variables
2023-10-22 22:45:14,677:INFO:Importing untrained model
2023-10-22 22:45:14,679:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-22 22:45:14,683:INFO:Starting cross validation
2023-10-22 22:45:14,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:35,504:INFO:Initializing compare_models()
2023-10-22 22:49:35,504:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, 'include': None, 'exclude': ['lar'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['lar'])
2023-10-22 22:49:35,505:INFO:Checking exceptions
2023-10-22 22:49:35,508:INFO:Preparing display monitor
2023-10-22 22:49:35,536:INFO:Initializing Linear Regression
2023-10-22 22:49:35,536:INFO:Total runtime is 1.6689300537109375e-06 minutes
2023-10-22 22:49:35,539:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:35,539:INFO:Initializing create_model()
2023-10-22 22:49:35,539:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:35,539:INFO:Checking exceptions
2023-10-22 22:49:35,539:INFO:Importing libraries
2023-10-22 22:49:35,539:INFO:Copying training dataset
2023-10-22 22:49:35,542:INFO:Defining folds
2023-10-22 22:49:35,542:INFO:Declaring metric variables
2023-10-22 22:49:35,545:INFO:Importing untrained model
2023-10-22 22:49:35,548:INFO:Linear Regression Imported successfully
2023-10-22 22:49:35,552:INFO:Starting cross validation
2023-10-22 22:49:35,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:37,269:INFO:Calculating mean and std
2023-10-22 22:49:37,273:INFO:Creating metrics dataframe
2023-10-22 22:49:37,278:INFO:Uploading results into container
2023-10-22 22:49:37,279:INFO:Uploading model into container now
2023-10-22 22:49:37,280:INFO:_master_model_container: 35
2023-10-22 22:49:37,280:INFO:_display_container: 2
2023-10-22 22:49:37,281:INFO:LinearRegression(n_jobs=-1)
2023-10-22 22:49:37,281:INFO:create_model() successfully completed......................................
2023-10-22 22:49:37,430:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:37,430:INFO:Creating metrics dataframe
2023-10-22 22:49:37,436:INFO:Initializing Lasso Regression
2023-10-22 22:49:37,436:INFO:Total runtime is 0.03167325258255005 minutes
2023-10-22 22:49:37,438:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:37,439:INFO:Initializing create_model()
2023-10-22 22:49:37,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:37,439:INFO:Checking exceptions
2023-10-22 22:49:37,439:INFO:Importing libraries
2023-10-22 22:49:37,439:INFO:Copying training dataset
2023-10-22 22:49:37,442:INFO:Defining folds
2023-10-22 22:49:37,442:INFO:Declaring metric variables
2023-10-22 22:49:37,444:INFO:Importing untrained model
2023-10-22 22:49:37,447:INFO:Lasso Regression Imported successfully
2023-10-22 22:49:37,451:INFO:Starting cross validation
2023-10-22 22:49:37,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:38,952:INFO:Calculating mean and std
2023-10-22 22:49:38,955:INFO:Creating metrics dataframe
2023-10-22 22:49:38,960:INFO:Uploading results into container
2023-10-22 22:49:38,960:INFO:Uploading model into container now
2023-10-22 22:49:38,961:INFO:_master_model_container: 36
2023-10-22 22:49:38,961:INFO:_display_container: 2
2023-10-22 22:49:38,962:INFO:Lasso(random_state=42)
2023-10-22 22:49:38,962:INFO:create_model() successfully completed......................................
2023-10-22 22:49:39,102:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:39,102:INFO:Creating metrics dataframe
2023-10-22 22:49:39,108:INFO:Initializing Ridge Regression
2023-10-22 22:49:39,108:INFO:Total runtime is 0.059542608261108396 minutes
2023-10-22 22:49:39,111:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:39,111:INFO:Initializing create_model()
2023-10-22 22:49:39,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:39,111:INFO:Checking exceptions
2023-10-22 22:49:39,111:INFO:Importing libraries
2023-10-22 22:49:39,111:INFO:Copying training dataset
2023-10-22 22:49:39,116:INFO:Defining folds
2023-10-22 22:49:39,116:INFO:Declaring metric variables
2023-10-22 22:49:39,119:INFO:Importing untrained model
2023-10-22 22:49:39,122:INFO:Ridge Regression Imported successfully
2023-10-22 22:49:39,126:INFO:Starting cross validation
2023-10-22 22:49:39,127:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:40,231:INFO:Calculating mean and std
2023-10-22 22:49:40,233:INFO:Creating metrics dataframe
2023-10-22 22:49:40,237:INFO:Uploading results into container
2023-10-22 22:49:40,237:INFO:Uploading model into container now
2023-10-22 22:49:40,238:INFO:_master_model_container: 37
2023-10-22 22:49:40,238:INFO:_display_container: 2
2023-10-22 22:49:40,238:INFO:Ridge(random_state=42)
2023-10-22 22:49:40,238:INFO:create_model() successfully completed......................................
2023-10-22 22:49:40,372:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:40,373:INFO:Creating metrics dataframe
2023-10-22 22:49:40,380:INFO:Initializing Elastic Net
2023-10-22 22:49:40,380:INFO:Total runtime is 0.0807310700416565 minutes
2023-10-22 22:49:40,382:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:40,382:INFO:Initializing create_model()
2023-10-22 22:49:40,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:40,382:INFO:Checking exceptions
2023-10-22 22:49:40,382:INFO:Importing libraries
2023-10-22 22:49:40,382:INFO:Copying training dataset
2023-10-22 22:49:40,387:INFO:Defining folds
2023-10-22 22:49:40,387:INFO:Declaring metric variables
2023-10-22 22:49:40,390:INFO:Importing untrained model
2023-10-22 22:49:40,392:INFO:Elastic Net Imported successfully
2023-10-22 22:49:40,400:INFO:Starting cross validation
2023-10-22 22:49:40,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:40,500:INFO:Calculating mean and std
2023-10-22 22:49:40,502:INFO:Creating metrics dataframe
2023-10-22 22:49:40,504:INFO:Uploading results into container
2023-10-22 22:49:40,504:INFO:Uploading model into container now
2023-10-22 22:49:40,505:INFO:_master_model_container: 38
2023-10-22 22:49:40,505:INFO:_display_container: 2
2023-10-22 22:49:40,505:INFO:ElasticNet(random_state=42)
2023-10-22 22:49:40,505:INFO:create_model() successfully completed......................................
2023-10-22 22:49:40,622:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:40,622:INFO:Creating metrics dataframe
2023-10-22 22:49:40,628:INFO:Initializing Lasso Least Angle Regression
2023-10-22 22:49:40,628:INFO:Total runtime is 0.08487642208735148 minutes
2023-10-22 22:49:40,630:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:40,630:INFO:Initializing create_model()
2023-10-22 22:49:40,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:40,631:INFO:Checking exceptions
2023-10-22 22:49:40,631:INFO:Importing libraries
2023-10-22 22:49:40,631:INFO:Copying training dataset
2023-10-22 22:49:40,634:INFO:Defining folds
2023-10-22 22:49:40,634:INFO:Declaring metric variables
2023-10-22 22:49:40,636:INFO:Importing untrained model
2023-10-22 22:49:40,639:INFO:Lasso Least Angle Regression Imported successfully
2023-10-22 22:49:40,644:INFO:Starting cross validation
2023-10-22 22:49:40,645:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:40,681:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:49:40,692:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:49:40,714:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:49:40,715:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:49:40,725:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:49:40,727:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:49:40,729:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:49:40,729:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:49:40,730:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:49:40,741:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:49:40,760:INFO:Calculating mean and std
2023-10-22 22:49:40,761:INFO:Creating metrics dataframe
2023-10-22 22:49:40,764:INFO:Uploading results into container
2023-10-22 22:49:40,764:INFO:Uploading model into container now
2023-10-22 22:49:40,764:INFO:_master_model_container: 39
2023-10-22 22:49:40,764:INFO:_display_container: 2
2023-10-22 22:49:40,765:INFO:LassoLars(random_state=42)
2023-10-22 22:49:40,765:INFO:create_model() successfully completed......................................
2023-10-22 22:49:40,883:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:40,883:INFO:Creating metrics dataframe
2023-10-22 22:49:40,890:INFO:Initializing Orthogonal Matching Pursuit
2023-10-22 22:49:40,891:INFO:Total runtime is 0.08925669590632121 minutes
2023-10-22 22:49:40,893:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:40,893:INFO:Initializing create_model()
2023-10-22 22:49:40,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:40,894:INFO:Checking exceptions
2023-10-22 22:49:40,894:INFO:Importing libraries
2023-10-22 22:49:40,894:INFO:Copying training dataset
2023-10-22 22:49:40,897:INFO:Defining folds
2023-10-22 22:49:40,897:INFO:Declaring metric variables
2023-10-22 22:49:40,899:INFO:Importing untrained model
2023-10-22 22:49:40,903:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-22 22:49:40,910:INFO:Starting cross validation
2023-10-22 22:49:40,911:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:40,968:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:49:40,968:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:49:40,982:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:49:40,989:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:49:40,992:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:49:40,998:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:49:40,998:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:49:40,991:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:49:40,999:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:49:40,999:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:49:41,034:INFO:Calculating mean and std
2023-10-22 22:49:41,035:INFO:Creating metrics dataframe
2023-10-22 22:49:41,038:INFO:Uploading results into container
2023-10-22 22:49:41,039:INFO:Uploading model into container now
2023-10-22 22:49:41,039:INFO:_master_model_container: 40
2023-10-22 22:49:41,039:INFO:_display_container: 2
2023-10-22 22:49:41,040:INFO:OrthogonalMatchingPursuit()
2023-10-22 22:49:41,040:INFO:create_model() successfully completed......................................
2023-10-22 22:49:41,176:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:41,176:INFO:Creating metrics dataframe
2023-10-22 22:49:41,183:INFO:Initializing Bayesian Ridge
2023-10-22 22:49:41,183:INFO:Total runtime is 0.0941130797068278 minutes
2023-10-22 22:49:41,185:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:41,185:INFO:Initializing create_model()
2023-10-22 22:49:41,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:41,185:INFO:Checking exceptions
2023-10-22 22:49:41,185:INFO:Importing libraries
2023-10-22 22:49:41,185:INFO:Copying training dataset
2023-10-22 22:49:41,189:INFO:Defining folds
2023-10-22 22:49:41,190:INFO:Declaring metric variables
2023-10-22 22:49:41,194:INFO:Importing untrained model
2023-10-22 22:49:41,196:INFO:Bayesian Ridge Imported successfully
2023-10-22 22:49:41,201:INFO:Starting cross validation
2023-10-22 22:49:41,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:41,307:INFO:Calculating mean and std
2023-10-22 22:49:41,308:INFO:Creating metrics dataframe
2023-10-22 22:49:41,310:INFO:Uploading results into container
2023-10-22 22:49:41,311:INFO:Uploading model into container now
2023-10-22 22:49:41,311:INFO:_master_model_container: 41
2023-10-22 22:49:41,311:INFO:_display_container: 2
2023-10-22 22:49:41,311:INFO:BayesianRidge()
2023-10-22 22:49:41,311:INFO:create_model() successfully completed......................................
2023-10-22 22:49:41,458:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:41,458:INFO:Creating metrics dataframe
2023-10-22 22:49:41,465:INFO:Initializing Passive Aggressive Regressor
2023-10-22 22:49:41,466:INFO:Total runtime is 0.09882948795954387 minutes
2023-10-22 22:49:41,469:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:41,469:INFO:Initializing create_model()
2023-10-22 22:49:41,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:41,469:INFO:Checking exceptions
2023-10-22 22:49:41,469:INFO:Importing libraries
2023-10-22 22:49:41,469:INFO:Copying training dataset
2023-10-22 22:49:41,474:INFO:Defining folds
2023-10-22 22:49:41,474:INFO:Declaring metric variables
2023-10-22 22:49:41,478:INFO:Importing untrained model
2023-10-22 22:49:41,481:INFO:Passive Aggressive Regressor Imported successfully
2023-10-22 22:49:41,487:INFO:Starting cross validation
2023-10-22 22:49:41,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:41,596:INFO:Calculating mean and std
2023-10-22 22:49:41,597:INFO:Creating metrics dataframe
2023-10-22 22:49:41,600:INFO:Uploading results into container
2023-10-22 22:49:41,600:INFO:Uploading model into container now
2023-10-22 22:49:41,600:INFO:_master_model_container: 42
2023-10-22 22:49:41,601:INFO:_display_container: 2
2023-10-22 22:49:41,601:INFO:PassiveAggressiveRegressor(random_state=42)
2023-10-22 22:49:41,601:INFO:create_model() successfully completed......................................
2023-10-22 22:49:41,750:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:41,751:INFO:Creating metrics dataframe
2023-10-22 22:49:41,760:INFO:Initializing Huber Regressor
2023-10-22 22:49:41,761:INFO:Total runtime is 0.10374821821848552 minutes
2023-10-22 22:49:41,764:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:41,765:INFO:Initializing create_model()
2023-10-22 22:49:41,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:41,765:INFO:Checking exceptions
2023-10-22 22:49:41,765:INFO:Importing libraries
2023-10-22 22:49:41,765:INFO:Copying training dataset
2023-10-22 22:49:41,769:INFO:Defining folds
2023-10-22 22:49:41,770:INFO:Declaring metric variables
2023-10-22 22:49:41,772:INFO:Importing untrained model
2023-10-22 22:49:41,775:INFO:Huber Regressor Imported successfully
2023-10-22 22:49:41,779:INFO:Starting cross validation
2023-10-22 22:49:41,780:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:41,839:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:49:41,846:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:49:41,852:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:49:41,857:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:49:41,858:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:49:41,860:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:49:41,870:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:49:41,877:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:49:41,879:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:49:41,883:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:49:41,901:INFO:Calculating mean and std
2023-10-22 22:49:41,902:INFO:Creating metrics dataframe
2023-10-22 22:49:41,905:INFO:Uploading results into container
2023-10-22 22:49:41,905:INFO:Uploading model into container now
2023-10-22 22:49:41,906:INFO:_master_model_container: 43
2023-10-22 22:49:41,906:INFO:_display_container: 2
2023-10-22 22:49:41,906:INFO:HuberRegressor()
2023-10-22 22:49:41,906:INFO:create_model() successfully completed......................................
2023-10-22 22:49:42,043:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:42,043:INFO:Creating metrics dataframe
2023-10-22 22:49:42,051:INFO:Initializing K Neighbors Regressor
2023-10-22 22:49:42,051:INFO:Total runtime is 0.10858819087346396 minutes
2023-10-22 22:49:42,054:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:42,054:INFO:Initializing create_model()
2023-10-22 22:49:42,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:42,054:INFO:Checking exceptions
2023-10-22 22:49:42,054:INFO:Importing libraries
2023-10-22 22:49:42,054:INFO:Copying training dataset
2023-10-22 22:49:42,058:INFO:Defining folds
2023-10-22 22:49:42,059:INFO:Declaring metric variables
2023-10-22 22:49:42,061:INFO:Importing untrained model
2023-10-22 22:49:42,063:INFO:K Neighbors Regressor Imported successfully
2023-10-22 22:49:42,067:INFO:Starting cross validation
2023-10-22 22:49:42,068:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:42,183:INFO:Calculating mean and std
2023-10-22 22:49:42,184:INFO:Creating metrics dataframe
2023-10-22 22:49:42,187:INFO:Uploading results into container
2023-10-22 22:49:42,187:INFO:Uploading model into container now
2023-10-22 22:49:42,187:INFO:_master_model_container: 44
2023-10-22 22:49:42,187:INFO:_display_container: 2
2023-10-22 22:49:42,188:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-22 22:49:42,188:INFO:create_model() successfully completed......................................
2023-10-22 22:49:42,321:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:42,322:INFO:Creating metrics dataframe
2023-10-22 22:49:42,330:INFO:Initializing Decision Tree Regressor
2023-10-22 22:49:42,330:INFO:Total runtime is 0.11323840618133546 minutes
2023-10-22 22:49:42,333:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:42,333:INFO:Initializing create_model()
2023-10-22 22:49:42,333:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:42,333:INFO:Checking exceptions
2023-10-22 22:49:42,333:INFO:Importing libraries
2023-10-22 22:49:42,333:INFO:Copying training dataset
2023-10-22 22:49:42,339:INFO:Defining folds
2023-10-22 22:49:42,339:INFO:Declaring metric variables
2023-10-22 22:49:42,342:INFO:Importing untrained model
2023-10-22 22:49:42,344:INFO:Decision Tree Regressor Imported successfully
2023-10-22 22:49:42,348:INFO:Starting cross validation
2023-10-22 22:49:42,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:42,440:INFO:Calculating mean and std
2023-10-22 22:49:42,441:INFO:Creating metrics dataframe
2023-10-22 22:49:42,444:INFO:Uploading results into container
2023-10-22 22:49:42,444:INFO:Uploading model into container now
2023-10-22 22:49:42,444:INFO:_master_model_container: 45
2023-10-22 22:49:42,444:INFO:_display_container: 2
2023-10-22 22:49:42,445:INFO:DecisionTreeRegressor(random_state=42)
2023-10-22 22:49:42,445:INFO:create_model() successfully completed......................................
2023-10-22 22:49:42,579:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:42,580:INFO:Creating metrics dataframe
2023-10-22 22:49:42,591:INFO:Initializing Random Forest Regressor
2023-10-22 22:49:42,592:INFO:Total runtime is 0.1175963878631592 minutes
2023-10-22 22:49:42,594:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:42,594:INFO:Initializing create_model()
2023-10-22 22:49:42,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:42,594:INFO:Checking exceptions
2023-10-22 22:49:42,594:INFO:Importing libraries
2023-10-22 22:49:42,595:INFO:Copying training dataset
2023-10-22 22:49:42,597:INFO:Defining folds
2023-10-22 22:49:42,598:INFO:Declaring metric variables
2023-10-22 22:49:42,600:INFO:Importing untrained model
2023-10-22 22:49:42,603:INFO:Random Forest Regressor Imported successfully
2023-10-22 22:49:42,607:INFO:Starting cross validation
2023-10-22 22:49:42,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:43,276:INFO:Calculating mean and std
2023-10-22 22:49:43,277:INFO:Creating metrics dataframe
2023-10-22 22:49:43,280:INFO:Uploading results into container
2023-10-22 22:49:43,280:INFO:Uploading model into container now
2023-10-22 22:49:43,280:INFO:_master_model_container: 46
2023-10-22 22:49:43,280:INFO:_display_container: 2
2023-10-22 22:49:43,281:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-10-22 22:49:43,281:INFO:create_model() successfully completed......................................
2023-10-22 22:49:43,413:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:43,413:INFO:Creating metrics dataframe
2023-10-22 22:49:43,425:INFO:Initializing Extra Trees Regressor
2023-10-22 22:49:43,425:INFO:Total runtime is 0.13148369391759238 minutes
2023-10-22 22:49:43,427:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:43,427:INFO:Initializing create_model()
2023-10-22 22:49:43,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:43,428:INFO:Checking exceptions
2023-10-22 22:49:43,428:INFO:Importing libraries
2023-10-22 22:49:43,428:INFO:Copying training dataset
2023-10-22 22:49:43,431:INFO:Defining folds
2023-10-22 22:49:43,431:INFO:Declaring metric variables
2023-10-22 22:49:43,434:INFO:Importing untrained model
2023-10-22 22:49:43,437:INFO:Extra Trees Regressor Imported successfully
2023-10-22 22:49:43,441:INFO:Starting cross validation
2023-10-22 22:49:43,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:43,934:INFO:Calculating mean and std
2023-10-22 22:49:43,936:INFO:Creating metrics dataframe
2023-10-22 22:49:43,939:INFO:Uploading results into container
2023-10-22 22:49:43,939:INFO:Uploading model into container now
2023-10-22 22:49:43,939:INFO:_master_model_container: 47
2023-10-22 22:49:43,939:INFO:_display_container: 2
2023-10-22 22:49:43,940:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-10-22 22:49:43,940:INFO:create_model() successfully completed......................................
2023-10-22 22:49:44,067:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:44,067:INFO:Creating metrics dataframe
2023-10-22 22:49:44,075:INFO:Initializing AdaBoost Regressor
2023-10-22 22:49:44,075:INFO:Total runtime is 0.14232356150945027 minutes
2023-10-22 22:49:44,077:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:44,078:INFO:Initializing create_model()
2023-10-22 22:49:44,078:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:44,078:INFO:Checking exceptions
2023-10-22 22:49:44,078:INFO:Importing libraries
2023-10-22 22:49:44,078:INFO:Copying training dataset
2023-10-22 22:49:44,082:INFO:Defining folds
2023-10-22 22:49:44,082:INFO:Declaring metric variables
2023-10-22 22:49:44,086:INFO:Importing untrained model
2023-10-22 22:49:44,089:INFO:AdaBoost Regressor Imported successfully
2023-10-22 22:49:44,093:INFO:Starting cross validation
2023-10-22 22:49:44,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:44,280:INFO:Calculating mean and std
2023-10-22 22:49:44,282:INFO:Creating metrics dataframe
2023-10-22 22:49:44,285:INFO:Uploading results into container
2023-10-22 22:49:44,286:INFO:Uploading model into container now
2023-10-22 22:49:44,286:INFO:_master_model_container: 48
2023-10-22 22:49:44,286:INFO:_display_container: 2
2023-10-22 22:49:44,287:INFO:AdaBoostRegressor(random_state=42)
2023-10-22 22:49:44,287:INFO:create_model() successfully completed......................................
2023-10-22 22:49:44,414:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:44,414:INFO:Creating metrics dataframe
2023-10-22 22:49:44,423:INFO:Initializing Gradient Boosting Regressor
2023-10-22 22:49:44,423:INFO:Total runtime is 0.14811956882476807 minutes
2023-10-22 22:49:44,425:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:44,425:INFO:Initializing create_model()
2023-10-22 22:49:44,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:44,426:INFO:Checking exceptions
2023-10-22 22:49:44,426:INFO:Importing libraries
2023-10-22 22:49:44,426:INFO:Copying training dataset
2023-10-22 22:49:44,429:INFO:Defining folds
2023-10-22 22:49:44,429:INFO:Declaring metric variables
2023-10-22 22:49:44,431:INFO:Importing untrained model
2023-10-22 22:49:44,435:INFO:Gradient Boosting Regressor Imported successfully
2023-10-22 22:49:44,441:INFO:Starting cross validation
2023-10-22 22:49:44,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:44,665:INFO:Calculating mean and std
2023-10-22 22:49:44,667:INFO:Creating metrics dataframe
2023-10-22 22:49:44,670:INFO:Uploading results into container
2023-10-22 22:49:44,670:INFO:Uploading model into container now
2023-10-22 22:49:44,671:INFO:_master_model_container: 49
2023-10-22 22:49:44,671:INFO:_display_container: 2
2023-10-22 22:49:44,671:INFO:GradientBoostingRegressor(random_state=42)
2023-10-22 22:49:44,671:INFO:create_model() successfully completed......................................
2023-10-22 22:49:44,808:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:44,808:INFO:Creating metrics dataframe
2023-10-22 22:49:44,816:INFO:Initializing Extreme Gradient Boosting
2023-10-22 22:49:44,816:INFO:Total runtime is 0.15466635624567668 minutes
2023-10-22 22:49:44,819:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:44,819:INFO:Initializing create_model()
2023-10-22 22:49:44,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:44,819:INFO:Checking exceptions
2023-10-22 22:49:44,819:INFO:Importing libraries
2023-10-22 22:49:44,819:INFO:Copying training dataset
2023-10-22 22:49:44,823:INFO:Defining folds
2023-10-22 22:49:44,824:INFO:Declaring metric variables
2023-10-22 22:49:44,827:INFO:Importing untrained model
2023-10-22 22:49:44,830:INFO:Extreme Gradient Boosting Imported successfully
2023-10-22 22:49:44,837:INFO:Starting cross validation
2023-10-22 22:49:44,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:49:45,344:INFO:Calculating mean and std
2023-10-22 22:49:45,345:INFO:Creating metrics dataframe
2023-10-22 22:49:45,347:INFO:Uploading results into container
2023-10-22 22:49:45,348:INFO:Uploading model into container now
2023-10-22 22:49:45,348:INFO:_master_model_container: 50
2023-10-22 22:49:45,348:INFO:_display_container: 2
2023-10-22 22:49:45,349:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2023-10-22 22:49:45,349:INFO:create_model() successfully completed......................................
2023-10-22 22:49:45,473:INFO:SubProcess create_model() end ==================================
2023-10-22 22:49:45,473:INFO:Creating metrics dataframe
2023-10-22 22:49:45,482:INFO:Initializing Light Gradient Boosting Machine
2023-10-22 22:49:45,482:INFO:Total runtime is 0.16576829353968303 minutes
2023-10-22 22:49:45,485:INFO:SubProcess create_model() called ==================================
2023-10-22 22:49:45,486:INFO:Initializing create_model()
2023-10-22 22:49:45,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0eacc70>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:49:45,486:INFO:Checking exceptions
2023-10-22 22:49:45,486:INFO:Importing libraries
2023-10-22 22:49:45,486:INFO:Copying training dataset
2023-10-22 22:49:45,490:INFO:Defining folds
2023-10-22 22:49:45,490:INFO:Declaring metric variables
2023-10-22 22:49:45,493:INFO:Importing untrained model
2023-10-22 22:49:45,496:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-22 22:49:45,501:INFO:Starting cross validation
2023-10-22 22:49:45,502:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:37,027:INFO:Initializing compare_models()
2023-10-22 22:53:37,027:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-10-22 22:53:37,028:INFO:Checking exceptions
2023-10-22 22:53:37,031:INFO:Preparing display monitor
2023-10-22 22:53:37,058:INFO:Initializing Linear Regression
2023-10-22 22:53:37,058:INFO:Total runtime is 5.535284678141276e-06 minutes
2023-10-22 22:53:37,061:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:37,061:INFO:Initializing create_model()
2023-10-22 22:53:37,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:37,062:INFO:Checking exceptions
2023-10-22 22:53:37,062:INFO:Importing libraries
2023-10-22 22:53:37,062:INFO:Copying training dataset
2023-10-22 22:53:37,066:INFO:Defining folds
2023-10-22 22:53:37,066:INFO:Declaring metric variables
2023-10-22 22:53:37,070:INFO:Importing untrained model
2023-10-22 22:53:37,074:INFO:Linear Regression Imported successfully
2023-10-22 22:53:37,079:INFO:Starting cross validation
2023-10-22 22:53:37,080:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:39,167:INFO:Calculating mean and std
2023-10-22 22:53:39,171:INFO:Creating metrics dataframe
2023-10-22 22:53:39,183:INFO:Uploading results into container
2023-10-22 22:53:39,185:INFO:Uploading model into container now
2023-10-22 22:53:39,186:INFO:_master_model_container: 51
2023-10-22 22:53:39,187:INFO:_display_container: 2
2023-10-22 22:53:39,187:INFO:LinearRegression(n_jobs=-1)
2023-10-22 22:53:39,187:INFO:create_model() successfully completed......................................
2023-10-22 22:53:39,365:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:39,365:INFO:Creating metrics dataframe
2023-10-22 22:53:39,372:INFO:Initializing Lasso Regression
2023-10-22 22:53:39,372:INFO:Total runtime is 0.03857074578603109 minutes
2023-10-22 22:53:39,375:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:39,376:INFO:Initializing create_model()
2023-10-22 22:53:39,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:39,377:INFO:Checking exceptions
2023-10-22 22:53:39,377:INFO:Importing libraries
2023-10-22 22:53:39,377:INFO:Copying training dataset
2023-10-22 22:53:39,380:INFO:Defining folds
2023-10-22 22:53:39,380:INFO:Declaring metric variables
2023-10-22 22:53:39,384:INFO:Importing untrained model
2023-10-22 22:53:39,391:INFO:Lasso Regression Imported successfully
2023-10-22 22:53:39,398:INFO:Starting cross validation
2023-10-22 22:53:39,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:41,279:INFO:Calculating mean and std
2023-10-22 22:53:41,282:INFO:Creating metrics dataframe
2023-10-22 22:53:41,288:INFO:Uploading results into container
2023-10-22 22:53:41,289:INFO:Uploading model into container now
2023-10-22 22:53:41,290:INFO:_master_model_container: 52
2023-10-22 22:53:41,290:INFO:_display_container: 2
2023-10-22 22:53:41,291:INFO:Lasso(random_state=42)
2023-10-22 22:53:41,291:INFO:create_model() successfully completed......................................
2023-10-22 22:53:41,454:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:41,454:INFO:Creating metrics dataframe
2023-10-22 22:53:41,462:INFO:Initializing Ridge Regression
2023-10-22 22:53:41,462:INFO:Total runtime is 0.07340557972590128 minutes
2023-10-22 22:53:41,465:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:41,465:INFO:Initializing create_model()
2023-10-22 22:53:41,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:41,465:INFO:Checking exceptions
2023-10-22 22:53:41,465:INFO:Importing libraries
2023-10-22 22:53:41,465:INFO:Copying training dataset
2023-10-22 22:53:41,470:INFO:Defining folds
2023-10-22 22:53:41,471:INFO:Declaring metric variables
2023-10-22 22:53:41,474:INFO:Importing untrained model
2023-10-22 22:53:41,477:INFO:Ridge Regression Imported successfully
2023-10-22 22:53:41,482:INFO:Starting cross validation
2023-10-22 22:53:41,484:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:42,666:INFO:Calculating mean and std
2023-10-22 22:53:42,678:INFO:Creating metrics dataframe
2023-10-22 22:53:42,693:INFO:Uploading results into container
2023-10-22 22:53:42,693:INFO:Uploading model into container now
2023-10-22 22:53:42,694:INFO:_master_model_container: 53
2023-10-22 22:53:42,694:INFO:_display_container: 2
2023-10-22 22:53:42,695:INFO:Ridge(random_state=42)
2023-10-22 22:53:42,695:INFO:create_model() successfully completed......................................
2023-10-22 22:53:42,837:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:42,837:INFO:Creating metrics dataframe
2023-10-22 22:53:42,844:INFO:Initializing Elastic Net
2023-10-22 22:53:42,844:INFO:Total runtime is 0.09643783171971639 minutes
2023-10-22 22:53:42,846:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:42,846:INFO:Initializing create_model()
2023-10-22 22:53:42,846:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:42,846:INFO:Checking exceptions
2023-10-22 22:53:42,846:INFO:Importing libraries
2023-10-22 22:53:42,846:INFO:Copying training dataset
2023-10-22 22:53:42,850:INFO:Defining folds
2023-10-22 22:53:42,850:INFO:Declaring metric variables
2023-10-22 22:53:42,853:INFO:Importing untrained model
2023-10-22 22:53:42,857:INFO:Elastic Net Imported successfully
2023-10-22 22:53:42,861:INFO:Starting cross validation
2023-10-22 22:53:42,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:42,986:INFO:Calculating mean and std
2023-10-22 22:53:42,987:INFO:Creating metrics dataframe
2023-10-22 22:53:42,989:INFO:Uploading results into container
2023-10-22 22:53:42,990:INFO:Uploading model into container now
2023-10-22 22:53:42,990:INFO:_master_model_container: 54
2023-10-22 22:53:42,990:INFO:_display_container: 2
2023-10-22 22:53:42,990:INFO:ElasticNet(random_state=42)
2023-10-22 22:53:42,990:INFO:create_model() successfully completed......................................
2023-10-22 22:53:43,117:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:43,117:INFO:Creating metrics dataframe
2023-10-22 22:53:43,126:INFO:Initializing Least Angle Regression
2023-10-22 22:53:43,126:INFO:Total runtime is 0.10113840103149413 minutes
2023-10-22 22:53:43,128:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:43,128:INFO:Initializing create_model()
2023-10-22 22:53:43,128:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:43,129:INFO:Checking exceptions
2023-10-22 22:53:43,129:INFO:Importing libraries
2023-10-22 22:53:43,129:INFO:Copying training dataset
2023-10-22 22:53:43,134:INFO:Defining folds
2023-10-22 22:53:43,134:INFO:Declaring metric variables
2023-10-22 22:53:43,137:INFO:Importing untrained model
2023-10-22 22:53:43,142:INFO:Least Angle Regression Imported successfully
2023-10-22 22:53:43,148:INFO:Starting cross validation
2023-10-22 22:53:43,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:43,192:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,194:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,196:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,198:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=6.537e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:53:43,198:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.698e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:53:43,198:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.937e+02, with an active set of 17 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:53:43,198:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.691e+01, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:53:43,198:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.411e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.186e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:53:43,208:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,225:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,225:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,228:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.517e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:53:43,228:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=3.566e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:53:43,228:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,229:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.847e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:53:43,229:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.982e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:53:43,229:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.150e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-10-22 22:53:43,239:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,246:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,252:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,277:INFO:Calculating mean and std
2023-10-22 22:53:43,278:INFO:Creating metrics dataframe
2023-10-22 22:53:43,281:INFO:Uploading results into container
2023-10-22 22:53:43,282:INFO:Uploading model into container now
2023-10-22 22:53:43,282:INFO:_master_model_container: 55
2023-10-22 22:53:43,282:INFO:_display_container: 2
2023-10-22 22:53:43,282:INFO:Lars(random_state=42)
2023-10-22 22:53:43,282:INFO:create_model() successfully completed......................................
2023-10-22 22:53:43,413:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:43,413:INFO:Creating metrics dataframe
2023-10-22 22:53:43,422:INFO:Initializing Lasso Least Angle Regression
2023-10-22 22:53:43,422:INFO:Total runtime is 0.10606799523035684 minutes
2023-10-22 22:53:43,424:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:43,425:INFO:Initializing create_model()
2023-10-22 22:53:43,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:43,425:INFO:Checking exceptions
2023-10-22 22:53:43,425:INFO:Importing libraries
2023-10-22 22:53:43,425:INFO:Copying training dataset
2023-10-22 22:53:43,428:INFO:Defining folds
2023-10-22 22:53:43,428:INFO:Declaring metric variables
2023-10-22 22:53:43,431:INFO:Importing untrained model
2023-10-22 22:53:43,433:INFO:Lasso Least Angle Regression Imported successfully
2023-10-22 22:53:43,439:INFO:Starting cross validation
2023-10-22 22:53:43,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:43,472:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:53:43,475:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:53:43,485:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:53:43,486:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:53:43,497:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:53:43,499:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:53:43,508:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:53:43,510:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:53:43,520:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:53:43,526:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 22:53:43,543:INFO:Calculating mean and std
2023-10-22 22:53:43,545:INFO:Creating metrics dataframe
2023-10-22 22:53:43,547:INFO:Uploading results into container
2023-10-22 22:53:43,548:INFO:Uploading model into container now
2023-10-22 22:53:43,548:INFO:_master_model_container: 56
2023-10-22 22:53:43,548:INFO:_display_container: 2
2023-10-22 22:53:43,548:INFO:LassoLars(random_state=42)
2023-10-22 22:53:43,548:INFO:create_model() successfully completed......................................
2023-10-22 22:53:43,682:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:43,682:INFO:Creating metrics dataframe
2023-10-22 22:53:43,692:INFO:Initializing Orthogonal Matching Pursuit
2023-10-22 22:53:43,692:INFO:Total runtime is 0.11056865056355793 minutes
2023-10-22 22:53:43,694:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:43,694:INFO:Initializing create_model()
2023-10-22 22:53:43,695:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:43,695:INFO:Checking exceptions
2023-10-22 22:53:43,695:INFO:Importing libraries
2023-10-22 22:53:43,695:INFO:Copying training dataset
2023-10-22 22:53:43,698:INFO:Defining folds
2023-10-22 22:53:43,698:INFO:Declaring metric variables
2023-10-22 22:53:43,701:INFO:Importing untrained model
2023-10-22 22:53:43,704:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-22 22:53:43,708:INFO:Starting cross validation
2023-10-22 22:53:43,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:43,761:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,766:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,767:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,768:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,769:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,771:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,777:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,781:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,782:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,785:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 22:53:43,814:INFO:Calculating mean and std
2023-10-22 22:53:43,816:INFO:Creating metrics dataframe
2023-10-22 22:53:43,819:INFO:Uploading results into container
2023-10-22 22:53:43,819:INFO:Uploading model into container now
2023-10-22 22:53:43,820:INFO:_master_model_container: 57
2023-10-22 22:53:43,820:INFO:_display_container: 2
2023-10-22 22:53:43,820:INFO:OrthogonalMatchingPursuit()
2023-10-22 22:53:43,820:INFO:create_model() successfully completed......................................
2023-10-22 22:53:43,942:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:43,942:INFO:Creating metrics dataframe
2023-10-22 22:53:43,952:INFO:Initializing Bayesian Ridge
2023-10-22 22:53:43,952:INFO:Total runtime is 0.11490377982457477 minutes
2023-10-22 22:53:43,954:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:43,955:INFO:Initializing create_model()
2023-10-22 22:53:43,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:43,955:INFO:Checking exceptions
2023-10-22 22:53:43,955:INFO:Importing libraries
2023-10-22 22:53:43,955:INFO:Copying training dataset
2023-10-22 22:53:43,958:INFO:Defining folds
2023-10-22 22:53:43,958:INFO:Declaring metric variables
2023-10-22 22:53:43,960:INFO:Importing untrained model
2023-10-22 22:53:43,965:INFO:Bayesian Ridge Imported successfully
2023-10-22 22:53:43,969:INFO:Starting cross validation
2023-10-22 22:53:43,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:44,101:INFO:Calculating mean and std
2023-10-22 22:53:44,103:INFO:Creating metrics dataframe
2023-10-22 22:53:44,106:INFO:Uploading results into container
2023-10-22 22:53:44,107:INFO:Uploading model into container now
2023-10-22 22:53:44,107:INFO:_master_model_container: 58
2023-10-22 22:53:44,107:INFO:_display_container: 2
2023-10-22 22:53:44,107:INFO:BayesianRidge()
2023-10-22 22:53:44,107:INFO:create_model() successfully completed......................................
2023-10-22 22:53:44,227:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:44,227:INFO:Creating metrics dataframe
2023-10-22 22:53:44,235:INFO:Initializing Passive Aggressive Regressor
2023-10-22 22:53:44,235:INFO:Total runtime is 0.11961937745412189 minutes
2023-10-22 22:53:44,237:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:44,238:INFO:Initializing create_model()
2023-10-22 22:53:44,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:44,238:INFO:Checking exceptions
2023-10-22 22:53:44,238:INFO:Importing libraries
2023-10-22 22:53:44,238:INFO:Copying training dataset
2023-10-22 22:53:44,240:INFO:Defining folds
2023-10-22 22:53:44,240:INFO:Declaring metric variables
2023-10-22 22:53:44,242:INFO:Importing untrained model
2023-10-22 22:53:44,245:INFO:Passive Aggressive Regressor Imported successfully
2023-10-22 22:53:44,250:INFO:Starting cross validation
2023-10-22 22:53:44,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:44,324:INFO:Calculating mean and std
2023-10-22 22:53:44,324:INFO:Creating metrics dataframe
2023-10-22 22:53:44,326:INFO:Uploading results into container
2023-10-22 22:53:44,326:INFO:Uploading model into container now
2023-10-22 22:53:44,327:INFO:_master_model_container: 59
2023-10-22 22:53:44,327:INFO:_display_container: 2
2023-10-22 22:53:44,327:INFO:PassiveAggressiveRegressor(random_state=42)
2023-10-22 22:53:44,327:INFO:create_model() successfully completed......................................
2023-10-22 22:53:44,460:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:44,460:INFO:Creating metrics dataframe
2023-10-22 22:53:44,473:INFO:Initializing Huber Regressor
2023-10-22 22:53:44,473:INFO:Total runtime is 0.12359054485956826 minutes
2023-10-22 22:53:44,475:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:44,475:INFO:Initializing create_model()
2023-10-22 22:53:44,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:44,475:INFO:Checking exceptions
2023-10-22 22:53:44,476:INFO:Importing libraries
2023-10-22 22:53:44,476:INFO:Copying training dataset
2023-10-22 22:53:44,484:INFO:Defining folds
2023-10-22 22:53:44,485:INFO:Declaring metric variables
2023-10-22 22:53:44,488:INFO:Importing untrained model
2023-10-22 22:53:44,491:INFO:Huber Regressor Imported successfully
2023-10-22 22:53:44,494:INFO:Starting cross validation
2023-10-22 22:53:44,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:44,587:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:53:44,590:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:53:44,594:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:53:44,603:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:53:44,603:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:53:44,614:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:53:44,630:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:53:44,630:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:53:44,632:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:53:44,641:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 22:53:44,657:INFO:Calculating mean and std
2023-10-22 22:53:44,658:INFO:Creating metrics dataframe
2023-10-22 22:53:44,661:INFO:Uploading results into container
2023-10-22 22:53:44,661:INFO:Uploading model into container now
2023-10-22 22:53:44,661:INFO:_master_model_container: 60
2023-10-22 22:53:44,661:INFO:_display_container: 2
2023-10-22 22:53:44,662:INFO:HuberRegressor()
2023-10-22 22:53:44,662:INFO:create_model() successfully completed......................................
2023-10-22 22:53:44,793:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:44,793:INFO:Creating metrics dataframe
2023-10-22 22:53:44,801:INFO:Initializing K Neighbors Regressor
2023-10-22 22:53:44,801:INFO:Total runtime is 0.12905511061350503 minutes
2023-10-22 22:53:44,803:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:44,804:INFO:Initializing create_model()
2023-10-22 22:53:44,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:44,804:INFO:Checking exceptions
2023-10-22 22:53:44,804:INFO:Importing libraries
2023-10-22 22:53:44,804:INFO:Copying training dataset
2023-10-22 22:53:44,807:INFO:Defining folds
2023-10-22 22:53:44,807:INFO:Declaring metric variables
2023-10-22 22:53:44,809:INFO:Importing untrained model
2023-10-22 22:53:44,811:INFO:K Neighbors Regressor Imported successfully
2023-10-22 22:53:44,816:INFO:Starting cross validation
2023-10-22 22:53:44,816:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:44,923:INFO:Calculating mean and std
2023-10-22 22:53:44,924:INFO:Creating metrics dataframe
2023-10-22 22:53:44,926:INFO:Uploading results into container
2023-10-22 22:53:44,927:INFO:Uploading model into container now
2023-10-22 22:53:44,927:INFO:_master_model_container: 61
2023-10-22 22:53:44,927:INFO:_display_container: 2
2023-10-22 22:53:44,927:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-22 22:53:44,927:INFO:create_model() successfully completed......................................
2023-10-22 22:53:45,050:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:45,050:INFO:Creating metrics dataframe
2023-10-22 22:53:45,059:INFO:Initializing Decision Tree Regressor
2023-10-22 22:53:45,059:INFO:Total runtime is 0.13335779507954915 minutes
2023-10-22 22:53:45,062:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:45,063:INFO:Initializing create_model()
2023-10-22 22:53:45,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:45,063:INFO:Checking exceptions
2023-10-22 22:53:45,063:INFO:Importing libraries
2023-10-22 22:53:45,063:INFO:Copying training dataset
2023-10-22 22:53:45,066:INFO:Defining folds
2023-10-22 22:53:45,066:INFO:Declaring metric variables
2023-10-22 22:53:45,068:INFO:Importing untrained model
2023-10-22 22:53:45,071:INFO:Decision Tree Regressor Imported successfully
2023-10-22 22:53:45,078:INFO:Starting cross validation
2023-10-22 22:53:45,079:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:45,204:INFO:Calculating mean and std
2023-10-22 22:53:45,205:INFO:Creating metrics dataframe
2023-10-22 22:53:45,208:INFO:Uploading results into container
2023-10-22 22:53:45,208:INFO:Uploading model into container now
2023-10-22 22:53:45,209:INFO:_master_model_container: 62
2023-10-22 22:53:45,209:INFO:_display_container: 2
2023-10-22 22:53:45,209:INFO:DecisionTreeRegressor(random_state=42)
2023-10-22 22:53:45,209:INFO:create_model() successfully completed......................................
2023-10-22 22:53:45,335:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:45,335:INFO:Creating metrics dataframe
2023-10-22 22:53:45,342:INFO:Initializing Random Forest Regressor
2023-10-22 22:53:45,342:INFO:Total runtime is 0.1380785346031189 minutes
2023-10-22 22:53:45,345:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:45,345:INFO:Initializing create_model()
2023-10-22 22:53:45,345:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:45,345:INFO:Checking exceptions
2023-10-22 22:53:45,345:INFO:Importing libraries
2023-10-22 22:53:45,345:INFO:Copying training dataset
2023-10-22 22:53:45,348:INFO:Defining folds
2023-10-22 22:53:45,348:INFO:Declaring metric variables
2023-10-22 22:53:45,350:INFO:Importing untrained model
2023-10-22 22:53:45,352:INFO:Random Forest Regressor Imported successfully
2023-10-22 22:53:45,356:INFO:Starting cross validation
2023-10-22 22:53:45,357:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:45,973:INFO:Calculating mean and std
2023-10-22 22:53:45,974:INFO:Creating metrics dataframe
2023-10-22 22:53:45,976:INFO:Uploading results into container
2023-10-22 22:53:45,977:INFO:Uploading model into container now
2023-10-22 22:53:45,977:INFO:_master_model_container: 63
2023-10-22 22:53:45,977:INFO:_display_container: 2
2023-10-22 22:53:45,977:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-10-22 22:53:45,977:INFO:create_model() successfully completed......................................
2023-10-22 22:53:46,106:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:46,107:INFO:Creating metrics dataframe
2023-10-22 22:53:46,119:INFO:Initializing Extra Trees Regressor
2023-10-22 22:53:46,119:INFO:Total runtime is 0.151028569539388 minutes
2023-10-22 22:53:46,122:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:46,122:INFO:Initializing create_model()
2023-10-22 22:53:46,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:46,122:INFO:Checking exceptions
2023-10-22 22:53:46,122:INFO:Importing libraries
2023-10-22 22:53:46,122:INFO:Copying training dataset
2023-10-22 22:53:46,127:INFO:Defining folds
2023-10-22 22:53:46,127:INFO:Declaring metric variables
2023-10-22 22:53:46,130:INFO:Importing untrained model
2023-10-22 22:53:46,132:INFO:Extra Trees Regressor Imported successfully
2023-10-22 22:53:46,136:INFO:Starting cross validation
2023-10-22 22:53:46,137:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:46,633:INFO:Calculating mean and std
2023-10-22 22:53:46,634:INFO:Creating metrics dataframe
2023-10-22 22:53:46,637:INFO:Uploading results into container
2023-10-22 22:53:46,637:INFO:Uploading model into container now
2023-10-22 22:53:46,637:INFO:_master_model_container: 64
2023-10-22 22:53:46,637:INFO:_display_container: 2
2023-10-22 22:53:46,638:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-10-22 22:53:46,638:INFO:create_model() successfully completed......................................
2023-10-22 22:53:46,768:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:46,768:INFO:Creating metrics dataframe
2023-10-22 22:53:46,776:INFO:Initializing AdaBoost Regressor
2023-10-22 22:53:46,776:INFO:Total runtime is 0.16196959018707274 minutes
2023-10-22 22:53:46,780:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:46,781:INFO:Initializing create_model()
2023-10-22 22:53:46,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:46,781:INFO:Checking exceptions
2023-10-22 22:53:46,781:INFO:Importing libraries
2023-10-22 22:53:46,781:INFO:Copying training dataset
2023-10-22 22:53:46,784:INFO:Defining folds
2023-10-22 22:53:46,784:INFO:Declaring metric variables
2023-10-22 22:53:46,787:INFO:Importing untrained model
2023-10-22 22:53:46,789:INFO:AdaBoost Regressor Imported successfully
2023-10-22 22:53:46,794:INFO:Starting cross validation
2023-10-22 22:53:46,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:47,006:INFO:Calculating mean and std
2023-10-22 22:53:47,007:INFO:Creating metrics dataframe
2023-10-22 22:53:47,010:INFO:Uploading results into container
2023-10-22 22:53:47,010:INFO:Uploading model into container now
2023-10-22 22:53:47,011:INFO:_master_model_container: 65
2023-10-22 22:53:47,011:INFO:_display_container: 2
2023-10-22 22:53:47,011:INFO:AdaBoostRegressor(random_state=42)
2023-10-22 22:53:47,011:INFO:create_model() successfully completed......................................
2023-10-22 22:53:47,148:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:47,148:INFO:Creating metrics dataframe
2023-10-22 22:53:47,157:INFO:Initializing Gradient Boosting Regressor
2023-10-22 22:53:47,157:INFO:Total runtime is 0.1683203856150309 minutes
2023-10-22 22:53:47,159:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:47,160:INFO:Initializing create_model()
2023-10-22 22:53:47,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:47,160:INFO:Checking exceptions
2023-10-22 22:53:47,160:INFO:Importing libraries
2023-10-22 22:53:47,160:INFO:Copying training dataset
2023-10-22 22:53:47,166:INFO:Defining folds
2023-10-22 22:53:47,166:INFO:Declaring metric variables
2023-10-22 22:53:47,168:INFO:Importing untrained model
2023-10-22 22:53:47,170:INFO:Gradient Boosting Regressor Imported successfully
2023-10-22 22:53:47,175:INFO:Starting cross validation
2023-10-22 22:53:47,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:47,411:INFO:Calculating mean and std
2023-10-22 22:53:47,412:INFO:Creating metrics dataframe
2023-10-22 22:53:47,414:INFO:Uploading results into container
2023-10-22 22:53:47,415:INFO:Uploading model into container now
2023-10-22 22:53:47,415:INFO:_master_model_container: 66
2023-10-22 22:53:47,415:INFO:_display_container: 2
2023-10-22 22:53:47,415:INFO:GradientBoostingRegressor(random_state=42)
2023-10-22 22:53:47,415:INFO:create_model() successfully completed......................................
2023-10-22 22:53:47,544:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:47,545:INFO:Creating metrics dataframe
2023-10-22 22:53:47,554:INFO:Initializing Extreme Gradient Boosting
2023-10-22 22:53:47,554:INFO:Total runtime is 0.17493515412012733 minutes
2023-10-22 22:53:47,558:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:47,559:INFO:Initializing create_model()
2023-10-22 22:53:47,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:47,559:INFO:Checking exceptions
2023-10-22 22:53:47,559:INFO:Importing libraries
2023-10-22 22:53:47,559:INFO:Copying training dataset
2023-10-22 22:53:47,563:INFO:Defining folds
2023-10-22 22:53:47,563:INFO:Declaring metric variables
2023-10-22 22:53:47,565:INFO:Importing untrained model
2023-10-22 22:53:47,569:INFO:Extreme Gradient Boosting Imported successfully
2023-10-22 22:53:47,575:INFO:Starting cross validation
2023-10-22 22:53:47,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 22:53:48,079:INFO:Calculating mean and std
2023-10-22 22:53:48,081:INFO:Creating metrics dataframe
2023-10-22 22:53:48,084:INFO:Uploading results into container
2023-10-22 22:53:48,084:INFO:Uploading model into container now
2023-10-22 22:53:48,084:INFO:_master_model_container: 67
2023-10-22 22:53:48,084:INFO:_display_container: 2
2023-10-22 22:53:48,085:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2023-10-22 22:53:48,085:INFO:create_model() successfully completed......................................
2023-10-22 22:53:48,224:INFO:SubProcess create_model() end ==================================
2023-10-22 22:53:48,225:INFO:Creating metrics dataframe
2023-10-22 22:53:48,235:INFO:Initializing Light Gradient Boosting Machine
2023-10-22 22:53:48,235:INFO:Total runtime is 0.1862967809041341 minutes
2023-10-22 22:53:48,238:INFO:SubProcess create_model() called ==================================
2023-10-22 22:53:48,239:INFO:Initializing create_model()
2023-10-22 22:53:48,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980c6cbfd0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 22:53:48,239:INFO:Checking exceptions
2023-10-22 22:53:48,239:INFO:Importing libraries
2023-10-22 22:53:48,239:INFO:Copying training dataset
2023-10-22 22:53:48,244:INFO:Defining folds
2023-10-22 22:53:48,244:INFO:Declaring metric variables
2023-10-22 22:53:48,248:INFO:Importing untrained model
2023-10-22 22:53:48,252:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-22 22:53:48,258:INFO:Starting cross validation
2023-10-22 22:53:48,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:07,768:INFO:Initializing compare_models()
2023-10-22 23:01:07,768:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, 'include': None, 'exclude': ['lar'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['lar'])
2023-10-22 23:01:07,768:INFO:Checking exceptions
2023-10-22 23:01:07,772:INFO:Preparing display monitor
2023-10-22 23:01:07,798:INFO:Initializing Linear Regression
2023-10-22 23:01:07,798:INFO:Total runtime is 6.449222564697266e-06 minutes
2023-10-22 23:01:07,800:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:07,801:INFO:Initializing create_model()
2023-10-22 23:01:07,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:07,802:INFO:Checking exceptions
2023-10-22 23:01:07,802:INFO:Importing libraries
2023-10-22 23:01:07,802:INFO:Copying training dataset
2023-10-22 23:01:07,804:INFO:Defining folds
2023-10-22 23:01:07,805:INFO:Declaring metric variables
2023-10-22 23:01:07,807:INFO:Importing untrained model
2023-10-22 23:01:07,811:INFO:Linear Regression Imported successfully
2023-10-22 23:01:07,816:INFO:Starting cross validation
2023-10-22 23:01:07,817:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:09,389:INFO:Calculating mean and std
2023-10-22 23:01:09,391:INFO:Creating metrics dataframe
2023-10-22 23:01:09,396:INFO:Uploading results into container
2023-10-22 23:01:09,396:INFO:Uploading model into container now
2023-10-22 23:01:09,397:INFO:_master_model_container: 68
2023-10-22 23:01:09,397:INFO:_display_container: 2
2023-10-22 23:01:09,397:INFO:LinearRegression(n_jobs=-1)
2023-10-22 23:01:09,397:INFO:create_model() successfully completed......................................
2023-10-22 23:01:09,533:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:09,533:INFO:Creating metrics dataframe
2023-10-22 23:01:09,540:INFO:Initializing Lasso Regression
2023-10-22 23:01:09,540:INFO:Total runtime is 0.02903180519739787 minutes
2023-10-22 23:01:09,542:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:09,542:INFO:Initializing create_model()
2023-10-22 23:01:09,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:09,542:INFO:Checking exceptions
2023-10-22 23:01:09,542:INFO:Importing libraries
2023-10-22 23:01:09,542:INFO:Copying training dataset
2023-10-22 23:01:09,545:INFO:Defining folds
2023-10-22 23:01:09,546:INFO:Declaring metric variables
2023-10-22 23:01:09,549:INFO:Importing untrained model
2023-10-22 23:01:09,552:INFO:Lasso Regression Imported successfully
2023-10-22 23:01:09,557:INFO:Starting cross validation
2023-10-22 23:01:09,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:10,997:INFO:Calculating mean and std
2023-10-22 23:01:10,998:INFO:Creating metrics dataframe
2023-10-22 23:01:11,002:INFO:Uploading results into container
2023-10-22 23:01:11,003:INFO:Uploading model into container now
2023-10-22 23:01:11,003:INFO:_master_model_container: 69
2023-10-22 23:01:11,003:INFO:_display_container: 2
2023-10-22 23:01:11,003:INFO:Lasso(random_state=42)
2023-10-22 23:01:11,003:INFO:create_model() successfully completed......................................
2023-10-22 23:01:11,137:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:11,137:INFO:Creating metrics dataframe
2023-10-22 23:01:11,144:INFO:Initializing Ridge Regression
2023-10-22 23:01:11,144:INFO:Total runtime is 0.055763745307922365 minutes
2023-10-22 23:01:11,146:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:11,147:INFO:Initializing create_model()
2023-10-22 23:01:11,147:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:11,147:INFO:Checking exceptions
2023-10-22 23:01:11,147:INFO:Importing libraries
2023-10-22 23:01:11,147:INFO:Copying training dataset
2023-10-22 23:01:11,150:INFO:Defining folds
2023-10-22 23:01:11,151:INFO:Declaring metric variables
2023-10-22 23:01:11,153:INFO:Importing untrained model
2023-10-22 23:01:11,155:INFO:Ridge Regression Imported successfully
2023-10-22 23:01:11,159:INFO:Starting cross validation
2023-10-22 23:01:11,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:12,223:INFO:Calculating mean and std
2023-10-22 23:01:12,225:INFO:Creating metrics dataframe
2023-10-22 23:01:12,228:INFO:Uploading results into container
2023-10-22 23:01:12,229:INFO:Uploading model into container now
2023-10-22 23:01:12,230:INFO:_master_model_container: 70
2023-10-22 23:01:12,230:INFO:_display_container: 2
2023-10-22 23:01:12,230:INFO:Ridge(random_state=42)
2023-10-22 23:01:12,230:INFO:create_model() successfully completed......................................
2023-10-22 23:01:12,376:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:12,376:INFO:Creating metrics dataframe
2023-10-22 23:01:12,382:INFO:Initializing Elastic Net
2023-10-22 23:01:12,382:INFO:Total runtime is 0.07640747626622518 minutes
2023-10-22 23:01:12,385:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:12,385:INFO:Initializing create_model()
2023-10-22 23:01:12,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:12,386:INFO:Checking exceptions
2023-10-22 23:01:12,386:INFO:Importing libraries
2023-10-22 23:01:12,386:INFO:Copying training dataset
2023-10-22 23:01:12,390:INFO:Defining folds
2023-10-22 23:01:12,390:INFO:Declaring metric variables
2023-10-22 23:01:12,393:INFO:Importing untrained model
2023-10-22 23:01:12,396:INFO:Elastic Net Imported successfully
2023-10-22 23:01:12,404:INFO:Starting cross validation
2023-10-22 23:01:12,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:12,526:INFO:Calculating mean and std
2023-10-22 23:01:12,527:INFO:Creating metrics dataframe
2023-10-22 23:01:12,531:INFO:Uploading results into container
2023-10-22 23:01:12,531:INFO:Uploading model into container now
2023-10-22 23:01:12,532:INFO:_master_model_container: 71
2023-10-22 23:01:12,532:INFO:_display_container: 2
2023-10-22 23:01:12,532:INFO:ElasticNet(random_state=42)
2023-10-22 23:01:12,532:INFO:create_model() successfully completed......................................
2023-10-22 23:01:12,660:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:12,660:INFO:Creating metrics dataframe
2023-10-22 23:01:12,668:INFO:Initializing Lasso Least Angle Regression
2023-10-22 23:01:12,668:INFO:Total runtime is 0.0811706026395162 minutes
2023-10-22 23:01:12,670:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:12,670:INFO:Initializing create_model()
2023-10-22 23:01:12,671:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:12,671:INFO:Checking exceptions
2023-10-22 23:01:12,671:INFO:Importing libraries
2023-10-22 23:01:12,671:INFO:Copying training dataset
2023-10-22 23:01:12,674:INFO:Defining folds
2023-10-22 23:01:12,674:INFO:Declaring metric variables
2023-10-22 23:01:12,676:INFO:Importing untrained model
2023-10-22 23:01:12,679:INFO:Lasso Least Angle Regression Imported successfully
2023-10-22 23:01:12,684:INFO:Starting cross validation
2023-10-22 23:01:12,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:12,724:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:01:12,729:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:01:12,733:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:01:12,739:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:01:12,741:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:01:12,744:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:01:12,749:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:01:12,749:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:01:12,753:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:01:12,766:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:01:12,786:INFO:Calculating mean and std
2023-10-22 23:01:12,788:INFO:Creating metrics dataframe
2023-10-22 23:01:12,790:INFO:Uploading results into container
2023-10-22 23:01:12,791:INFO:Uploading model into container now
2023-10-22 23:01:12,791:INFO:_master_model_container: 72
2023-10-22 23:01:12,791:INFO:_display_container: 2
2023-10-22 23:01:12,791:INFO:LassoLars(random_state=42)
2023-10-22 23:01:12,791:INFO:create_model() successfully completed......................................
2023-10-22 23:01:12,930:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:12,930:INFO:Creating metrics dataframe
2023-10-22 23:01:12,939:INFO:Initializing Orthogonal Matching Pursuit
2023-10-22 23:01:12,939:INFO:Total runtime is 0.08568153778711955 minutes
2023-10-22 23:01:12,941:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:12,941:INFO:Initializing create_model()
2023-10-22 23:01:12,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:12,941:INFO:Checking exceptions
2023-10-22 23:01:12,941:INFO:Importing libraries
2023-10-22 23:01:12,941:INFO:Copying training dataset
2023-10-22 23:01:12,944:INFO:Defining folds
2023-10-22 23:01:12,945:INFO:Declaring metric variables
2023-10-22 23:01:12,948:INFO:Importing untrained model
2023-10-22 23:01:12,951:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-22 23:01:12,956:INFO:Starting cross validation
2023-10-22 23:01:12,957:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:12,992:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:01:12,992:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:01:12,999:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:01:13,010:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:01:13,014:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:01:13,015:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:01:13,016:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:01:13,016:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:01:13,020:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:01:13,023:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:01:13,041:INFO:Calculating mean and std
2023-10-22 23:01:13,041:INFO:Creating metrics dataframe
2023-10-22 23:01:13,044:INFO:Uploading results into container
2023-10-22 23:01:13,044:INFO:Uploading model into container now
2023-10-22 23:01:13,044:INFO:_master_model_container: 73
2023-10-22 23:01:13,044:INFO:_display_container: 2
2023-10-22 23:01:13,044:INFO:OrthogonalMatchingPursuit()
2023-10-22 23:01:13,044:INFO:create_model() successfully completed......................................
2023-10-22 23:01:13,172:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:13,173:INFO:Creating metrics dataframe
2023-10-22 23:01:13,179:INFO:Initializing Bayesian Ridge
2023-10-22 23:01:13,180:INFO:Total runtime is 0.08969393173853557 minutes
2023-10-22 23:01:13,182:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:13,182:INFO:Initializing create_model()
2023-10-22 23:01:13,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:13,182:INFO:Checking exceptions
2023-10-22 23:01:13,182:INFO:Importing libraries
2023-10-22 23:01:13,182:INFO:Copying training dataset
2023-10-22 23:01:13,184:INFO:Defining folds
2023-10-22 23:01:13,185:INFO:Declaring metric variables
2023-10-22 23:01:13,187:INFO:Importing untrained model
2023-10-22 23:01:13,189:INFO:Bayesian Ridge Imported successfully
2023-10-22 23:01:13,193:INFO:Starting cross validation
2023-10-22 23:01:13,194:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:13,293:INFO:Calculating mean and std
2023-10-22 23:01:13,295:INFO:Creating metrics dataframe
2023-10-22 23:01:13,297:INFO:Uploading results into container
2023-10-22 23:01:13,297:INFO:Uploading model into container now
2023-10-22 23:01:13,298:INFO:_master_model_container: 74
2023-10-22 23:01:13,298:INFO:_display_container: 2
2023-10-22 23:01:13,298:INFO:BayesianRidge()
2023-10-22 23:01:13,298:INFO:create_model() successfully completed......................................
2023-10-22 23:01:13,419:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:13,419:INFO:Creating metrics dataframe
2023-10-22 23:01:13,427:INFO:Initializing Passive Aggressive Regressor
2023-10-22 23:01:13,427:INFO:Total runtime is 0.0938201387723287 minutes
2023-10-22 23:01:13,430:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:13,430:INFO:Initializing create_model()
2023-10-22 23:01:13,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:13,430:INFO:Checking exceptions
2023-10-22 23:01:13,430:INFO:Importing libraries
2023-10-22 23:01:13,430:INFO:Copying training dataset
2023-10-22 23:01:13,434:INFO:Defining folds
2023-10-22 23:01:13,434:INFO:Declaring metric variables
2023-10-22 23:01:13,436:INFO:Importing untrained model
2023-10-22 23:01:13,439:INFO:Passive Aggressive Regressor Imported successfully
2023-10-22 23:01:13,443:INFO:Starting cross validation
2023-10-22 23:01:13,444:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:13,566:INFO:Calculating mean and std
2023-10-22 23:01:13,568:INFO:Creating metrics dataframe
2023-10-22 23:01:13,570:INFO:Uploading results into container
2023-10-22 23:01:13,571:INFO:Uploading model into container now
2023-10-22 23:01:13,571:INFO:_master_model_container: 75
2023-10-22 23:01:13,571:INFO:_display_container: 2
2023-10-22 23:01:13,571:INFO:PassiveAggressiveRegressor(random_state=42)
2023-10-22 23:01:13,571:INFO:create_model() successfully completed......................................
2023-10-22 23:01:13,692:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:13,692:INFO:Creating metrics dataframe
2023-10-22 23:01:13,698:INFO:Initializing Huber Regressor
2023-10-22 23:01:13,699:INFO:Total runtime is 0.09834484259287517 minutes
2023-10-22 23:01:13,701:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:13,702:INFO:Initializing create_model()
2023-10-22 23:01:13,702:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:13,702:INFO:Checking exceptions
2023-10-22 23:01:13,702:INFO:Importing libraries
2023-10-22 23:01:13,702:INFO:Copying training dataset
2023-10-22 23:01:13,704:INFO:Defining folds
2023-10-22 23:01:13,704:INFO:Declaring metric variables
2023-10-22 23:01:13,707:INFO:Importing untrained model
2023-10-22 23:01:13,709:INFO:Huber Regressor Imported successfully
2023-10-22 23:01:13,714:INFO:Starting cross validation
2023-10-22 23:01:13,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:13,772:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:01:13,773:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:01:13,778:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:01:13,779:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:01:13,779:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:01:13,787:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:01:13,788:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:01:13,794:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:01:13,796:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:01:13,800:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:01:13,814:INFO:Calculating mean and std
2023-10-22 23:01:13,815:INFO:Creating metrics dataframe
2023-10-22 23:01:13,818:INFO:Uploading results into container
2023-10-22 23:01:13,818:INFO:Uploading model into container now
2023-10-22 23:01:13,819:INFO:_master_model_container: 76
2023-10-22 23:01:13,819:INFO:_display_container: 2
2023-10-22 23:01:13,819:INFO:HuberRegressor()
2023-10-22 23:01:13,819:INFO:create_model() successfully completed......................................
2023-10-22 23:01:13,935:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:13,935:INFO:Creating metrics dataframe
2023-10-22 23:01:13,941:INFO:Initializing K Neighbors Regressor
2023-10-22 23:01:13,941:INFO:Total runtime is 0.10238289435704549 minutes
2023-10-22 23:01:13,943:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:13,943:INFO:Initializing create_model()
2023-10-22 23:01:13,943:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:13,943:INFO:Checking exceptions
2023-10-22 23:01:13,943:INFO:Importing libraries
2023-10-22 23:01:13,943:INFO:Copying training dataset
2023-10-22 23:01:13,947:INFO:Defining folds
2023-10-22 23:01:13,947:INFO:Declaring metric variables
2023-10-22 23:01:13,950:INFO:Importing untrained model
2023-10-22 23:01:13,952:INFO:K Neighbors Regressor Imported successfully
2023-10-22 23:01:13,956:INFO:Starting cross validation
2023-10-22 23:01:13,957:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:14,057:INFO:Calculating mean and std
2023-10-22 23:01:14,058:INFO:Creating metrics dataframe
2023-10-22 23:01:14,060:INFO:Uploading results into container
2023-10-22 23:01:14,060:INFO:Uploading model into container now
2023-10-22 23:01:14,061:INFO:_master_model_container: 77
2023-10-22 23:01:14,061:INFO:_display_container: 2
2023-10-22 23:01:14,061:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-22 23:01:14,061:INFO:create_model() successfully completed......................................
2023-10-22 23:01:14,173:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:14,173:INFO:Creating metrics dataframe
2023-10-22 23:01:14,181:INFO:Initializing Decision Tree Regressor
2023-10-22 23:01:14,182:INFO:Total runtime is 0.10639539559682211 minutes
2023-10-22 23:01:14,184:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:14,184:INFO:Initializing create_model()
2023-10-22 23:01:14,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:14,184:INFO:Checking exceptions
2023-10-22 23:01:14,184:INFO:Importing libraries
2023-10-22 23:01:14,184:INFO:Copying training dataset
2023-10-22 23:01:14,187:INFO:Defining folds
2023-10-22 23:01:14,187:INFO:Declaring metric variables
2023-10-22 23:01:14,189:INFO:Importing untrained model
2023-10-22 23:01:14,191:INFO:Decision Tree Regressor Imported successfully
2023-10-22 23:01:14,195:INFO:Starting cross validation
2023-10-22 23:01:14,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:14,303:INFO:Calculating mean and std
2023-10-22 23:01:14,305:INFO:Creating metrics dataframe
2023-10-22 23:01:14,307:INFO:Uploading results into container
2023-10-22 23:01:14,308:INFO:Uploading model into container now
2023-10-22 23:01:14,308:INFO:_master_model_container: 78
2023-10-22 23:01:14,308:INFO:_display_container: 2
2023-10-22 23:01:14,308:INFO:DecisionTreeRegressor(random_state=42)
2023-10-22 23:01:14,308:INFO:create_model() successfully completed......................................
2023-10-22 23:01:14,428:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:14,428:INFO:Creating metrics dataframe
2023-10-22 23:01:14,438:INFO:Initializing Random Forest Regressor
2023-10-22 23:01:14,438:INFO:Total runtime is 0.11066788037618001 minutes
2023-10-22 23:01:14,440:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:14,441:INFO:Initializing create_model()
2023-10-22 23:01:14,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:14,441:INFO:Checking exceptions
2023-10-22 23:01:14,441:INFO:Importing libraries
2023-10-22 23:01:14,441:INFO:Copying training dataset
2023-10-22 23:01:14,444:INFO:Defining folds
2023-10-22 23:01:14,444:INFO:Declaring metric variables
2023-10-22 23:01:14,446:INFO:Importing untrained model
2023-10-22 23:01:14,448:INFO:Random Forest Regressor Imported successfully
2023-10-22 23:01:14,453:INFO:Starting cross validation
2023-10-22 23:01:14,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:15,025:INFO:Calculating mean and std
2023-10-22 23:01:15,026:INFO:Creating metrics dataframe
2023-10-22 23:01:15,029:INFO:Uploading results into container
2023-10-22 23:01:15,030:INFO:Uploading model into container now
2023-10-22 23:01:15,030:INFO:_master_model_container: 79
2023-10-22 23:01:15,030:INFO:_display_container: 2
2023-10-22 23:01:15,030:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-10-22 23:01:15,030:INFO:create_model() successfully completed......................................
2023-10-22 23:01:15,159:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:15,159:INFO:Creating metrics dataframe
2023-10-22 23:01:15,168:INFO:Initializing Extra Trees Regressor
2023-10-22 23:01:15,168:INFO:Total runtime is 0.12283809979756673 minutes
2023-10-22 23:01:15,170:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:15,171:INFO:Initializing create_model()
2023-10-22 23:01:15,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:15,171:INFO:Checking exceptions
2023-10-22 23:01:15,171:INFO:Importing libraries
2023-10-22 23:01:15,171:INFO:Copying training dataset
2023-10-22 23:01:15,174:INFO:Defining folds
2023-10-22 23:01:15,174:INFO:Declaring metric variables
2023-10-22 23:01:15,177:INFO:Importing untrained model
2023-10-22 23:01:15,182:INFO:Extra Trees Regressor Imported successfully
2023-10-22 23:01:15,188:INFO:Starting cross validation
2023-10-22 23:01:15,189:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:15,601:INFO:Calculating mean and std
2023-10-22 23:01:15,602:INFO:Creating metrics dataframe
2023-10-22 23:01:15,605:INFO:Uploading results into container
2023-10-22 23:01:15,605:INFO:Uploading model into container now
2023-10-22 23:01:15,606:INFO:_master_model_container: 80
2023-10-22 23:01:15,606:INFO:_display_container: 2
2023-10-22 23:01:15,606:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-10-22 23:01:15,606:INFO:create_model() successfully completed......................................
2023-10-22 23:01:15,734:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:15,734:INFO:Creating metrics dataframe
2023-10-22 23:01:15,743:INFO:Initializing AdaBoost Regressor
2023-10-22 23:01:15,743:INFO:Total runtime is 0.13242427110671998 minutes
2023-10-22 23:01:15,747:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:15,747:INFO:Initializing create_model()
2023-10-22 23:01:15,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:15,747:INFO:Checking exceptions
2023-10-22 23:01:15,747:INFO:Importing libraries
2023-10-22 23:01:15,747:INFO:Copying training dataset
2023-10-22 23:01:15,751:INFO:Defining folds
2023-10-22 23:01:15,751:INFO:Declaring metric variables
2023-10-22 23:01:15,753:INFO:Importing untrained model
2023-10-22 23:01:15,757:INFO:AdaBoost Regressor Imported successfully
2023-10-22 23:01:15,762:INFO:Starting cross validation
2023-10-22 23:01:15,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:15,958:INFO:Calculating mean and std
2023-10-22 23:01:15,960:INFO:Creating metrics dataframe
2023-10-22 23:01:15,962:INFO:Uploading results into container
2023-10-22 23:01:15,963:INFO:Uploading model into container now
2023-10-22 23:01:15,963:INFO:_master_model_container: 81
2023-10-22 23:01:15,963:INFO:_display_container: 2
2023-10-22 23:01:15,963:INFO:AdaBoostRegressor(random_state=42)
2023-10-22 23:01:15,963:INFO:create_model() successfully completed......................................
2023-10-22 23:01:16,098:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:16,098:INFO:Creating metrics dataframe
2023-10-22 23:01:16,106:INFO:Initializing Gradient Boosting Regressor
2023-10-22 23:01:16,106:INFO:Total runtime is 0.1384671727816264 minutes
2023-10-22 23:01:16,108:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:16,109:INFO:Initializing create_model()
2023-10-22 23:01:16,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:16,109:INFO:Checking exceptions
2023-10-22 23:01:16,109:INFO:Importing libraries
2023-10-22 23:01:16,109:INFO:Copying training dataset
2023-10-22 23:01:16,113:INFO:Defining folds
2023-10-22 23:01:16,114:INFO:Declaring metric variables
2023-10-22 23:01:16,116:INFO:Importing untrained model
2023-10-22 23:01:16,120:INFO:Gradient Boosting Regressor Imported successfully
2023-10-22 23:01:16,127:INFO:Starting cross validation
2023-10-22 23:01:16,127:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:16,336:INFO:Calculating mean and std
2023-10-22 23:01:16,337:INFO:Creating metrics dataframe
2023-10-22 23:01:16,340:INFO:Uploading results into container
2023-10-22 23:01:16,340:INFO:Uploading model into container now
2023-10-22 23:01:16,341:INFO:_master_model_container: 82
2023-10-22 23:01:16,341:INFO:_display_container: 2
2023-10-22 23:01:16,341:INFO:GradientBoostingRegressor(random_state=42)
2023-10-22 23:01:16,341:INFO:create_model() successfully completed......................................
2023-10-22 23:01:16,478:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:16,478:INFO:Creating metrics dataframe
2023-10-22 23:01:16,485:INFO:Initializing Extreme Gradient Boosting
2023-10-22 23:01:16,485:INFO:Total runtime is 0.14478442668914795 minutes
2023-10-22 23:01:16,487:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:16,487:INFO:Initializing create_model()
2023-10-22 23:01:16,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:16,487:INFO:Checking exceptions
2023-10-22 23:01:16,487:INFO:Importing libraries
2023-10-22 23:01:16,487:INFO:Copying training dataset
2023-10-22 23:01:16,492:INFO:Defining folds
2023-10-22 23:01:16,492:INFO:Declaring metric variables
2023-10-22 23:01:16,496:INFO:Importing untrained model
2023-10-22 23:01:16,498:INFO:Extreme Gradient Boosting Imported successfully
2023-10-22 23:01:16,502:INFO:Starting cross validation
2023-10-22 23:01:16,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:01:16,945:INFO:Calculating mean and std
2023-10-22 23:01:16,946:INFO:Creating metrics dataframe
2023-10-22 23:01:16,949:INFO:Uploading results into container
2023-10-22 23:01:16,949:INFO:Uploading model into container now
2023-10-22 23:01:16,949:INFO:_master_model_container: 83
2023-10-22 23:01:16,949:INFO:_display_container: 2
2023-10-22 23:01:16,950:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2023-10-22 23:01:16,950:INFO:create_model() successfully completed......................................
2023-10-22 23:01:17,085:INFO:SubProcess create_model() end ==================================
2023-10-22 23:01:17,085:INFO:Creating metrics dataframe
2023-10-22 23:01:17,095:INFO:Initializing Light Gradient Boosting Machine
2023-10-22 23:01:17,095:INFO:Total runtime is 0.1549460490544637 minutes
2023-10-22 23:01:17,097:INFO:SubProcess create_model() called ==================================
2023-10-22 23:01:17,097:INFO:Initializing create_model()
2023-10-22 23:01:17,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f980d185ed0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:01:17,097:INFO:Checking exceptions
2023-10-22 23:01:17,097:INFO:Importing libraries
2023-10-22 23:01:17,097:INFO:Copying training dataset
2023-10-22 23:01:17,101:INFO:Defining folds
2023-10-22 23:01:17,102:INFO:Declaring metric variables
2023-10-22 23:01:17,105:INFO:Importing untrained model
2023-10-22 23:01:17,108:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-22 23:01:17,113:INFO:Starting cross validation
2023-10-22 23:01:17,114:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:16,037:INFO:Initializing compare_models()
2023-10-22 23:02:16,039:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, 'include': None, 'exclude': ['lar', 'par'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['lar', 'par'])
2023-10-22 23:02:16,039:INFO:Checking exceptions
2023-10-22 23:02:16,040:INFO:Preparing display monitor
2023-10-22 23:02:16,065:INFO:Initializing Linear Regression
2023-10-22 23:02:16,065:INFO:Total runtime is 6.298224131266276e-06 minutes
2023-10-22 23:02:16,068:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:16,068:INFO:Initializing create_model()
2023-10-22 23:02:16,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:16,068:INFO:Checking exceptions
2023-10-22 23:02:16,068:INFO:Importing libraries
2023-10-22 23:02:16,068:INFO:Copying training dataset
2023-10-22 23:02:16,071:INFO:Defining folds
2023-10-22 23:02:16,071:INFO:Declaring metric variables
2023-10-22 23:02:16,074:INFO:Importing untrained model
2023-10-22 23:02:16,076:INFO:Linear Regression Imported successfully
2023-10-22 23:02:16,080:INFO:Starting cross validation
2023-10-22 23:02:16,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:17,829:INFO:Calculating mean and std
2023-10-22 23:02:17,831:INFO:Creating metrics dataframe
2023-10-22 23:02:17,836:INFO:Uploading results into container
2023-10-22 23:02:17,837:INFO:Uploading model into container now
2023-10-22 23:02:17,838:INFO:_master_model_container: 84
2023-10-22 23:02:17,838:INFO:_display_container: 2
2023-10-22 23:02:17,839:INFO:LinearRegression(n_jobs=-1)
2023-10-22 23:02:17,839:INFO:create_model() successfully completed......................................
2023-10-22 23:02:18,016:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:18,016:INFO:Creating metrics dataframe
2023-10-22 23:02:18,023:INFO:Initializing Lasso Regression
2023-10-22 23:02:18,023:INFO:Total runtime is 0.03262987931569417 minutes
2023-10-22 23:02:18,025:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:18,025:INFO:Initializing create_model()
2023-10-22 23:02:18,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:18,026:INFO:Checking exceptions
2023-10-22 23:02:18,026:INFO:Importing libraries
2023-10-22 23:02:18,026:INFO:Copying training dataset
2023-10-22 23:02:18,030:INFO:Defining folds
2023-10-22 23:02:18,030:INFO:Declaring metric variables
2023-10-22 23:02:18,032:INFO:Importing untrained model
2023-10-22 23:02:18,035:INFO:Lasso Regression Imported successfully
2023-10-22 23:02:18,039:INFO:Starting cross validation
2023-10-22 23:02:18,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:20,031:INFO:Calculating mean and std
2023-10-22 23:02:20,035:INFO:Creating metrics dataframe
2023-10-22 23:02:20,043:INFO:Uploading results into container
2023-10-22 23:02:20,044:INFO:Uploading model into container now
2023-10-22 23:02:20,045:INFO:_master_model_container: 85
2023-10-22 23:02:20,045:INFO:_display_container: 2
2023-10-22 23:02:20,046:INFO:Lasso(random_state=42)
2023-10-22 23:02:20,046:INFO:create_model() successfully completed......................................
2023-10-22 23:02:20,232:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:20,232:INFO:Creating metrics dataframe
2023-10-22 23:02:20,242:INFO:Initializing Ridge Regression
2023-10-22 23:02:20,243:INFO:Total runtime is 0.06963095664978028 minutes
2023-10-22 23:02:20,246:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:20,246:INFO:Initializing create_model()
2023-10-22 23:02:20,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:20,246:INFO:Checking exceptions
2023-10-22 23:02:20,246:INFO:Importing libraries
2023-10-22 23:02:20,246:INFO:Copying training dataset
2023-10-22 23:02:20,249:INFO:Defining folds
2023-10-22 23:02:20,250:INFO:Declaring metric variables
2023-10-22 23:02:20,253:INFO:Importing untrained model
2023-10-22 23:02:20,256:INFO:Ridge Regression Imported successfully
2023-10-22 23:02:20,260:INFO:Starting cross validation
2023-10-22 23:02:20,261:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:21,467:INFO:Calculating mean and std
2023-10-22 23:02:21,469:INFO:Creating metrics dataframe
2023-10-22 23:02:21,475:INFO:Uploading results into container
2023-10-22 23:02:21,476:INFO:Uploading model into container now
2023-10-22 23:02:21,476:INFO:_master_model_container: 86
2023-10-22 23:02:21,476:INFO:_display_container: 2
2023-10-22 23:02:21,476:INFO:Ridge(random_state=42)
2023-10-22 23:02:21,476:INFO:create_model() successfully completed......................................
2023-10-22 23:02:21,611:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:21,611:INFO:Creating metrics dataframe
2023-10-22 23:02:21,617:INFO:Initializing Elastic Net
2023-10-22 23:02:21,618:INFO:Total runtime is 0.0925589958826701 minutes
2023-10-22 23:02:21,621:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:21,622:INFO:Initializing create_model()
2023-10-22 23:02:21,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:21,622:INFO:Checking exceptions
2023-10-22 23:02:21,622:INFO:Importing libraries
2023-10-22 23:02:21,622:INFO:Copying training dataset
2023-10-22 23:02:21,625:INFO:Defining folds
2023-10-22 23:02:21,625:INFO:Declaring metric variables
2023-10-22 23:02:21,628:INFO:Importing untrained model
2023-10-22 23:02:21,630:INFO:Elastic Net Imported successfully
2023-10-22 23:02:21,636:INFO:Starting cross validation
2023-10-22 23:02:21,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:21,752:INFO:Calculating mean and std
2023-10-22 23:02:21,753:INFO:Creating metrics dataframe
2023-10-22 23:02:21,756:INFO:Uploading results into container
2023-10-22 23:02:21,756:INFO:Uploading model into container now
2023-10-22 23:02:21,756:INFO:_master_model_container: 87
2023-10-22 23:02:21,756:INFO:_display_container: 2
2023-10-22 23:02:21,757:INFO:ElasticNet(random_state=42)
2023-10-22 23:02:21,757:INFO:create_model() successfully completed......................................
2023-10-22 23:02:21,882:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:21,882:INFO:Creating metrics dataframe
2023-10-22 23:02:21,889:INFO:Initializing Lasso Least Angle Regression
2023-10-22 23:02:21,889:INFO:Total runtime is 0.09706654946009319 minutes
2023-10-22 23:02:21,891:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:21,892:INFO:Initializing create_model()
2023-10-22 23:02:21,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:21,892:INFO:Checking exceptions
2023-10-22 23:02:21,892:INFO:Importing libraries
2023-10-22 23:02:21,892:INFO:Copying training dataset
2023-10-22 23:02:21,895:INFO:Defining folds
2023-10-22 23:02:21,895:INFO:Declaring metric variables
2023-10-22 23:02:21,897:INFO:Importing untrained model
2023-10-22 23:02:21,900:INFO:Lasso Least Angle Regression Imported successfully
2023-10-22 23:02:21,906:INFO:Starting cross validation
2023-10-22 23:02:21,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:21,955:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:21,957:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:21,964:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:21,967:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:21,973:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:21,975:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:21,976:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:21,979:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:21,982:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:21,983:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:22,010:INFO:Calculating mean and std
2023-10-22 23:02:22,011:INFO:Creating metrics dataframe
2023-10-22 23:02:22,014:INFO:Uploading results into container
2023-10-22 23:02:22,014:INFO:Uploading model into container now
2023-10-22 23:02:22,015:INFO:_master_model_container: 88
2023-10-22 23:02:22,015:INFO:_display_container: 2
2023-10-22 23:02:22,015:INFO:LassoLars(random_state=42)
2023-10-22 23:02:22,015:INFO:create_model() successfully completed......................................
2023-10-22 23:02:22,144:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:22,144:INFO:Creating metrics dataframe
2023-10-22 23:02:22,151:INFO:Initializing Orthogonal Matching Pursuit
2023-10-22 23:02:22,151:INFO:Total runtime is 0.10143945614496867 minutes
2023-10-22 23:02:22,153:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:22,154:INFO:Initializing create_model()
2023-10-22 23:02:22,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:22,154:INFO:Checking exceptions
2023-10-22 23:02:22,154:INFO:Importing libraries
2023-10-22 23:02:22,154:INFO:Copying training dataset
2023-10-22 23:02:22,157:INFO:Defining folds
2023-10-22 23:02:22,157:INFO:Declaring metric variables
2023-10-22 23:02:22,159:INFO:Importing untrained model
2023-10-22 23:02:22,162:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-22 23:02:22,166:INFO:Starting cross validation
2023-10-22 23:02:22,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:22,205:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:22,208:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:22,208:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:22,208:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:22,213:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:22,222:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:22,223:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:22,229:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:22,230:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:22,233:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:22,249:INFO:Calculating mean and std
2023-10-22 23:02:22,249:INFO:Creating metrics dataframe
2023-10-22 23:02:22,252:INFO:Uploading results into container
2023-10-22 23:02:22,252:INFO:Uploading model into container now
2023-10-22 23:02:22,252:INFO:_master_model_container: 89
2023-10-22 23:02:22,252:INFO:_display_container: 2
2023-10-22 23:02:22,253:INFO:OrthogonalMatchingPursuit()
2023-10-22 23:02:22,253:INFO:create_model() successfully completed......................................
2023-10-22 23:02:22,374:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:22,374:INFO:Creating metrics dataframe
2023-10-22 23:02:22,381:INFO:Initializing Bayesian Ridge
2023-10-22 23:02:22,381:INFO:Total runtime is 0.10526498556137086 minutes
2023-10-22 23:02:22,383:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:22,384:INFO:Initializing create_model()
2023-10-22 23:02:22,384:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:22,384:INFO:Checking exceptions
2023-10-22 23:02:22,384:INFO:Importing libraries
2023-10-22 23:02:22,384:INFO:Copying training dataset
2023-10-22 23:02:22,387:INFO:Defining folds
2023-10-22 23:02:22,388:INFO:Declaring metric variables
2023-10-22 23:02:22,390:INFO:Importing untrained model
2023-10-22 23:02:22,392:INFO:Bayesian Ridge Imported successfully
2023-10-22 23:02:22,398:INFO:Starting cross validation
2023-10-22 23:02:22,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:22,509:INFO:Calculating mean and std
2023-10-22 23:02:22,510:INFO:Creating metrics dataframe
2023-10-22 23:02:22,513:INFO:Uploading results into container
2023-10-22 23:02:22,514:INFO:Uploading model into container now
2023-10-22 23:02:22,514:INFO:_master_model_container: 90
2023-10-22 23:02:22,514:INFO:_display_container: 2
2023-10-22 23:02:22,514:INFO:BayesianRidge()
2023-10-22 23:02:22,514:INFO:create_model() successfully completed......................................
2023-10-22 23:02:22,643:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:22,643:INFO:Creating metrics dataframe
2023-10-22 23:02:22,650:INFO:Initializing Huber Regressor
2023-10-22 23:02:22,651:INFO:Total runtime is 0.10976541837056479 minutes
2023-10-22 23:02:22,655:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:22,655:INFO:Initializing create_model()
2023-10-22 23:02:22,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:22,655:INFO:Checking exceptions
2023-10-22 23:02:22,655:INFO:Importing libraries
2023-10-22 23:02:22,655:INFO:Copying training dataset
2023-10-22 23:02:22,660:INFO:Defining folds
2023-10-22 23:02:22,660:INFO:Declaring metric variables
2023-10-22 23:02:22,662:INFO:Importing untrained model
2023-10-22 23:02:22,665:INFO:Huber Regressor Imported successfully
2023-10-22 23:02:22,670:INFO:Starting cross validation
2023-10-22 23:02:22,671:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:22,721:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:22,726:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:22,746:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:22,752:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:22,755:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:22,755:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:22,760:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:22,761:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:22,768:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:22,778:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:22,797:INFO:Calculating mean and std
2023-10-22 23:02:22,799:INFO:Creating metrics dataframe
2023-10-22 23:02:22,801:INFO:Uploading results into container
2023-10-22 23:02:22,802:INFO:Uploading model into container now
2023-10-22 23:02:22,802:INFO:_master_model_container: 91
2023-10-22 23:02:22,802:INFO:_display_container: 2
2023-10-22 23:02:22,802:INFO:HuberRegressor()
2023-10-22 23:02:22,802:INFO:create_model() successfully completed......................................
2023-10-22 23:02:22,934:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:22,934:INFO:Creating metrics dataframe
2023-10-22 23:02:22,941:INFO:Initializing K Neighbors Regressor
2023-10-22 23:02:22,941:INFO:Total runtime is 0.11460549831390382 minutes
2023-10-22 23:02:22,944:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:22,944:INFO:Initializing create_model()
2023-10-22 23:02:22,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:22,944:INFO:Checking exceptions
2023-10-22 23:02:22,944:INFO:Importing libraries
2023-10-22 23:02:22,944:INFO:Copying training dataset
2023-10-22 23:02:22,948:INFO:Defining folds
2023-10-22 23:02:22,948:INFO:Declaring metric variables
2023-10-22 23:02:22,951:INFO:Importing untrained model
2023-10-22 23:02:22,953:INFO:K Neighbors Regressor Imported successfully
2023-10-22 23:02:22,958:INFO:Starting cross validation
2023-10-22 23:02:22,959:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:23,101:INFO:Calculating mean and std
2023-10-22 23:02:23,102:INFO:Creating metrics dataframe
2023-10-22 23:02:23,105:INFO:Uploading results into container
2023-10-22 23:02:23,106:INFO:Uploading model into container now
2023-10-22 23:02:23,106:INFO:_master_model_container: 92
2023-10-22 23:02:23,106:INFO:_display_container: 2
2023-10-22 23:02:23,106:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-22 23:02:23,106:INFO:create_model() successfully completed......................................
2023-10-22 23:02:23,235:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:23,235:INFO:Creating metrics dataframe
2023-10-22 23:02:23,241:INFO:Initializing Decision Tree Regressor
2023-10-22 23:02:23,241:INFO:Total runtime is 0.11961156129837038 minutes
2023-10-22 23:02:23,244:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:23,244:INFO:Initializing create_model()
2023-10-22 23:02:23,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:23,244:INFO:Checking exceptions
2023-10-22 23:02:23,244:INFO:Importing libraries
2023-10-22 23:02:23,244:INFO:Copying training dataset
2023-10-22 23:02:23,248:INFO:Defining folds
2023-10-22 23:02:23,248:INFO:Declaring metric variables
2023-10-22 23:02:23,250:INFO:Importing untrained model
2023-10-22 23:02:23,253:INFO:Decision Tree Regressor Imported successfully
2023-10-22 23:02:23,258:INFO:Starting cross validation
2023-10-22 23:02:23,258:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:23,358:INFO:Calculating mean and std
2023-10-22 23:02:23,359:INFO:Creating metrics dataframe
2023-10-22 23:02:23,361:INFO:Uploading results into container
2023-10-22 23:02:23,362:INFO:Uploading model into container now
2023-10-22 23:02:23,362:INFO:_master_model_container: 93
2023-10-22 23:02:23,362:INFO:_display_container: 2
2023-10-22 23:02:23,362:INFO:DecisionTreeRegressor(random_state=42)
2023-10-22 23:02:23,362:INFO:create_model() successfully completed......................................
2023-10-22 23:02:23,479:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:23,480:INFO:Creating metrics dataframe
2023-10-22 23:02:23,489:INFO:Initializing Random Forest Regressor
2023-10-22 23:02:23,489:INFO:Total runtime is 0.123733921845754 minutes
2023-10-22 23:02:23,491:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:23,492:INFO:Initializing create_model()
2023-10-22 23:02:23,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:23,492:INFO:Checking exceptions
2023-10-22 23:02:23,492:INFO:Importing libraries
2023-10-22 23:02:23,492:INFO:Copying training dataset
2023-10-22 23:02:23,494:INFO:Defining folds
2023-10-22 23:02:23,495:INFO:Declaring metric variables
2023-10-22 23:02:23,498:INFO:Importing untrained model
2023-10-22 23:02:23,500:INFO:Random Forest Regressor Imported successfully
2023-10-22 23:02:23,505:INFO:Starting cross validation
2023-10-22 23:02:23,505:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:24,080:INFO:Calculating mean and std
2023-10-22 23:02:24,081:INFO:Creating metrics dataframe
2023-10-22 23:02:24,084:INFO:Uploading results into container
2023-10-22 23:02:24,084:INFO:Uploading model into container now
2023-10-22 23:02:24,084:INFO:_master_model_container: 94
2023-10-22 23:02:24,084:INFO:_display_container: 2
2023-10-22 23:02:24,085:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-10-22 23:02:24,085:INFO:create_model() successfully completed......................................
2023-10-22 23:02:24,205:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:24,205:INFO:Creating metrics dataframe
2023-10-22 23:02:24,215:INFO:Initializing Extra Trees Regressor
2023-10-22 23:02:24,215:INFO:Total runtime is 0.1358344316482544 minutes
2023-10-22 23:02:24,218:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:24,218:INFO:Initializing create_model()
2023-10-22 23:02:24,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:24,218:INFO:Checking exceptions
2023-10-22 23:02:24,218:INFO:Importing libraries
2023-10-22 23:02:24,218:INFO:Copying training dataset
2023-10-22 23:02:24,221:INFO:Defining folds
2023-10-22 23:02:24,221:INFO:Declaring metric variables
2023-10-22 23:02:24,224:INFO:Importing untrained model
2023-10-22 23:02:24,226:INFO:Extra Trees Regressor Imported successfully
2023-10-22 23:02:24,232:INFO:Starting cross validation
2023-10-22 23:02:24,233:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:24,724:INFO:Calculating mean and std
2023-10-22 23:02:24,725:INFO:Creating metrics dataframe
2023-10-22 23:02:24,727:INFO:Uploading results into container
2023-10-22 23:02:24,728:INFO:Uploading model into container now
2023-10-22 23:02:24,728:INFO:_master_model_container: 95
2023-10-22 23:02:24,728:INFO:_display_container: 2
2023-10-22 23:02:24,728:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-10-22 23:02:24,728:INFO:create_model() successfully completed......................................
2023-10-22 23:02:24,859:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:24,859:INFO:Creating metrics dataframe
2023-10-22 23:02:24,868:INFO:Initializing AdaBoost Regressor
2023-10-22 23:02:24,868:INFO:Total runtime is 0.14672364393870035 minutes
2023-10-22 23:02:24,870:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:24,871:INFO:Initializing create_model()
2023-10-22 23:02:24,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:24,871:INFO:Checking exceptions
2023-10-22 23:02:24,871:INFO:Importing libraries
2023-10-22 23:02:24,871:INFO:Copying training dataset
2023-10-22 23:02:24,874:INFO:Defining folds
2023-10-22 23:02:24,874:INFO:Declaring metric variables
2023-10-22 23:02:24,876:INFO:Importing untrained model
2023-10-22 23:02:24,879:INFO:AdaBoost Regressor Imported successfully
2023-10-22 23:02:24,883:INFO:Starting cross validation
2023-10-22 23:02:24,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:25,049:INFO:Calculating mean and std
2023-10-22 23:02:25,050:INFO:Creating metrics dataframe
2023-10-22 23:02:25,052:INFO:Uploading results into container
2023-10-22 23:02:25,053:INFO:Uploading model into container now
2023-10-22 23:02:25,053:INFO:_master_model_container: 96
2023-10-22 23:02:25,053:INFO:_display_container: 2
2023-10-22 23:02:25,053:INFO:AdaBoostRegressor(random_state=42)
2023-10-22 23:02:25,053:INFO:create_model() successfully completed......................................
2023-10-22 23:02:25,168:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:25,169:INFO:Creating metrics dataframe
2023-10-22 23:02:25,177:INFO:Initializing Gradient Boosting Regressor
2023-10-22 23:02:25,177:INFO:Total runtime is 0.1518768032391866 minutes
2023-10-22 23:02:25,180:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:25,180:INFO:Initializing create_model()
2023-10-22 23:02:25,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:25,180:INFO:Checking exceptions
2023-10-22 23:02:25,180:INFO:Importing libraries
2023-10-22 23:02:25,180:INFO:Copying training dataset
2023-10-22 23:02:25,185:INFO:Defining folds
2023-10-22 23:02:25,185:INFO:Declaring metric variables
2023-10-22 23:02:25,188:INFO:Importing untrained model
2023-10-22 23:02:25,190:INFO:Gradient Boosting Regressor Imported successfully
2023-10-22 23:02:25,195:INFO:Starting cross validation
2023-10-22 23:02:25,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:25,432:INFO:Calculating mean and std
2023-10-22 23:02:25,434:INFO:Creating metrics dataframe
2023-10-22 23:02:25,436:INFO:Uploading results into container
2023-10-22 23:02:25,436:INFO:Uploading model into container now
2023-10-22 23:02:25,437:INFO:_master_model_container: 97
2023-10-22 23:02:25,437:INFO:_display_container: 2
2023-10-22 23:02:25,437:INFO:GradientBoostingRegressor(random_state=42)
2023-10-22 23:02:25,437:INFO:create_model() successfully completed......................................
2023-10-22 23:02:25,552:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:25,552:INFO:Creating metrics dataframe
2023-10-22 23:02:25,562:INFO:Initializing Extreme Gradient Boosting
2023-10-22 23:02:25,563:INFO:Total runtime is 0.1583053429921468 minutes
2023-10-22 23:02:25,566:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:25,566:INFO:Initializing create_model()
2023-10-22 23:02:25,567:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:25,567:INFO:Checking exceptions
2023-10-22 23:02:25,567:INFO:Importing libraries
2023-10-22 23:02:25,567:INFO:Copying training dataset
2023-10-22 23:02:25,570:INFO:Defining folds
2023-10-22 23:02:25,570:INFO:Declaring metric variables
2023-10-22 23:02:25,572:INFO:Importing untrained model
2023-10-22 23:02:25,575:INFO:Extreme Gradient Boosting Imported successfully
2023-10-22 23:02:25,579:INFO:Starting cross validation
2023-10-22 23:02:25,582:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:26,014:INFO:Calculating mean and std
2023-10-22 23:02:26,015:INFO:Creating metrics dataframe
2023-10-22 23:02:26,018:INFO:Uploading results into container
2023-10-22 23:02:26,018:INFO:Uploading model into container now
2023-10-22 23:02:26,018:INFO:_master_model_container: 98
2023-10-22 23:02:26,018:INFO:_display_container: 2
2023-10-22 23:02:26,019:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2023-10-22 23:02:26,019:INFO:create_model() successfully completed......................................
2023-10-22 23:02:26,145:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:26,145:INFO:Creating metrics dataframe
2023-10-22 23:02:26,152:INFO:Initializing Light Gradient Boosting Machine
2023-10-22 23:02:26,152:INFO:Total runtime is 0.16812744537989296 minutes
2023-10-22 23:02:26,155:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:26,155:INFO:Initializing create_model()
2023-10-22 23:02:26,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c09d9a20>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:26,155:INFO:Checking exceptions
2023-10-22 23:02:26,155:INFO:Importing libraries
2023-10-22 23:02:26,155:INFO:Copying training dataset
2023-10-22 23:02:26,159:INFO:Defining folds
2023-10-22 23:02:26,159:INFO:Declaring metric variables
2023-10-22 23:02:26,162:INFO:Importing untrained model
2023-10-22 23:02:26,166:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-22 23:02:26,171:INFO:Starting cross validation
2023-10-22 23:02:26,172:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:50,780:INFO:Initializing compare_models()
2023-10-22 23:02:50,780:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, 'include': None, 'exclude': ['lar', 'par', 'dt'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['lar', 'par', 'dt'])
2023-10-22 23:02:50,781:INFO:Checking exceptions
2023-10-22 23:02:50,783:INFO:Preparing display monitor
2023-10-22 23:02:50,810:INFO:Initializing Linear Regression
2023-10-22 23:02:50,810:INFO:Total runtime is 1.811981201171875e-06 minutes
2023-10-22 23:02:50,814:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:50,814:INFO:Initializing create_model()
2023-10-22 23:02:50,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:50,814:INFO:Checking exceptions
2023-10-22 23:02:50,814:INFO:Importing libraries
2023-10-22 23:02:50,814:INFO:Copying training dataset
2023-10-22 23:02:50,818:INFO:Defining folds
2023-10-22 23:02:50,818:INFO:Declaring metric variables
2023-10-22 23:02:50,821:INFO:Importing untrained model
2023-10-22 23:02:50,823:INFO:Linear Regression Imported successfully
2023-10-22 23:02:50,827:INFO:Starting cross validation
2023-10-22 23:02:50,828:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:52,786:INFO:Calculating mean and std
2023-10-22 23:02:52,788:INFO:Creating metrics dataframe
2023-10-22 23:02:52,793:INFO:Uploading results into container
2023-10-22 23:02:52,794:INFO:Uploading model into container now
2023-10-22 23:02:52,794:INFO:_master_model_container: 99
2023-10-22 23:02:52,794:INFO:_display_container: 2
2023-10-22 23:02:52,795:INFO:LinearRegression(n_jobs=-1)
2023-10-22 23:02:52,795:INFO:create_model() successfully completed......................................
2023-10-22 23:02:52,943:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:52,943:INFO:Creating metrics dataframe
2023-10-22 23:02:52,950:INFO:Initializing Lasso Regression
2023-10-22 23:02:52,950:INFO:Total runtime is 0.03567057053248088 minutes
2023-10-22 23:02:52,953:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:52,953:INFO:Initializing create_model()
2023-10-22 23:02:52,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:52,954:INFO:Checking exceptions
2023-10-22 23:02:52,954:INFO:Importing libraries
2023-10-22 23:02:52,954:INFO:Copying training dataset
2023-10-22 23:02:52,957:INFO:Defining folds
2023-10-22 23:02:52,957:INFO:Declaring metric variables
2023-10-22 23:02:52,959:INFO:Importing untrained model
2023-10-22 23:02:52,963:INFO:Lasso Regression Imported successfully
2023-10-22 23:02:52,969:INFO:Starting cross validation
2023-10-22 23:02:52,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:54,635:INFO:Calculating mean and std
2023-10-22 23:02:54,637:INFO:Creating metrics dataframe
2023-10-22 23:02:54,642:INFO:Uploading results into container
2023-10-22 23:02:54,642:INFO:Uploading model into container now
2023-10-22 23:02:54,643:INFO:_master_model_container: 100
2023-10-22 23:02:54,643:INFO:_display_container: 2
2023-10-22 23:02:54,643:INFO:Lasso(random_state=42)
2023-10-22 23:02:54,643:INFO:create_model() successfully completed......................................
2023-10-22 23:02:54,795:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:54,795:INFO:Creating metrics dataframe
2023-10-22 23:02:54,803:INFO:Initializing Ridge Regression
2023-10-22 23:02:54,803:INFO:Total runtime is 0.06655356089274089 minutes
2023-10-22 23:02:54,806:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:54,807:INFO:Initializing create_model()
2023-10-22 23:02:54,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:54,807:INFO:Checking exceptions
2023-10-22 23:02:54,807:INFO:Importing libraries
2023-10-22 23:02:54,807:INFO:Copying training dataset
2023-10-22 23:02:54,812:INFO:Defining folds
2023-10-22 23:02:54,812:INFO:Declaring metric variables
2023-10-22 23:02:54,815:INFO:Importing untrained model
2023-10-22 23:02:54,819:INFO:Ridge Regression Imported successfully
2023-10-22 23:02:54,825:INFO:Starting cross validation
2023-10-22 23:02:54,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:56,015:INFO:Calculating mean and std
2023-10-22 23:02:56,017:INFO:Creating metrics dataframe
2023-10-22 23:02:56,021:INFO:Uploading results into container
2023-10-22 23:02:56,021:INFO:Uploading model into container now
2023-10-22 23:02:56,021:INFO:_master_model_container: 101
2023-10-22 23:02:56,022:INFO:_display_container: 2
2023-10-22 23:02:56,022:INFO:Ridge(random_state=42)
2023-10-22 23:02:56,022:INFO:create_model() successfully completed......................................
2023-10-22 23:02:56,149:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:56,149:INFO:Creating metrics dataframe
2023-10-22 23:02:56,157:INFO:Initializing Elastic Net
2023-10-22 23:02:56,157:INFO:Total runtime is 0.0891095519065857 minutes
2023-10-22 23:02:56,160:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:56,160:INFO:Initializing create_model()
2023-10-22 23:02:56,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:56,160:INFO:Checking exceptions
2023-10-22 23:02:56,160:INFO:Importing libraries
2023-10-22 23:02:56,160:INFO:Copying training dataset
2023-10-22 23:02:56,163:INFO:Defining folds
2023-10-22 23:02:56,163:INFO:Declaring metric variables
2023-10-22 23:02:56,166:INFO:Importing untrained model
2023-10-22 23:02:56,169:INFO:Elastic Net Imported successfully
2023-10-22 23:02:56,173:INFO:Starting cross validation
2023-10-22 23:02:56,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:56,290:INFO:Calculating mean and std
2023-10-22 23:02:56,291:INFO:Creating metrics dataframe
2023-10-22 23:02:56,295:INFO:Uploading results into container
2023-10-22 23:02:56,296:INFO:Uploading model into container now
2023-10-22 23:02:56,296:INFO:_master_model_container: 102
2023-10-22 23:02:56,296:INFO:_display_container: 2
2023-10-22 23:02:56,296:INFO:ElasticNet(random_state=42)
2023-10-22 23:02:56,296:INFO:create_model() successfully completed......................................
2023-10-22 23:02:56,430:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:56,430:INFO:Creating metrics dataframe
2023-10-22 23:02:56,436:INFO:Initializing Lasso Least Angle Regression
2023-10-22 23:02:56,436:INFO:Total runtime is 0.09376690785090129 minutes
2023-10-22 23:02:56,438:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:56,439:INFO:Initializing create_model()
2023-10-22 23:02:56,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:56,439:INFO:Checking exceptions
2023-10-22 23:02:56,439:INFO:Importing libraries
2023-10-22 23:02:56,439:INFO:Copying training dataset
2023-10-22 23:02:56,442:INFO:Defining folds
2023-10-22 23:02:56,442:INFO:Declaring metric variables
2023-10-22 23:02:56,444:INFO:Importing untrained model
2023-10-22 23:02:56,447:INFO:Lasso Least Angle Regression Imported successfully
2023-10-22 23:02:56,452:INFO:Starting cross validation
2023-10-22 23:02:56,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:56,490:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:56,497:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:56,498:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:56,500:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:56,502:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:56,503:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:56,505:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:56,512:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:56,515:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:56,522:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-22 23:02:56,542:INFO:Calculating mean and std
2023-10-22 23:02:56,543:INFO:Creating metrics dataframe
2023-10-22 23:02:56,545:INFO:Uploading results into container
2023-10-22 23:02:56,546:INFO:Uploading model into container now
2023-10-22 23:02:56,546:INFO:_master_model_container: 103
2023-10-22 23:02:56,546:INFO:_display_container: 2
2023-10-22 23:02:56,546:INFO:LassoLars(random_state=42)
2023-10-22 23:02:56,546:INFO:create_model() successfully completed......................................
2023-10-22 23:02:56,665:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:56,665:INFO:Creating metrics dataframe
2023-10-22 23:02:56,671:INFO:Initializing Orthogonal Matching Pursuit
2023-10-22 23:02:56,671:INFO:Total runtime is 0.09768397808074952 minutes
2023-10-22 23:02:56,673:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:56,673:INFO:Initializing create_model()
2023-10-22 23:02:56,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:56,673:INFO:Checking exceptions
2023-10-22 23:02:56,673:INFO:Importing libraries
2023-10-22 23:02:56,673:INFO:Copying training dataset
2023-10-22 23:02:56,677:INFO:Defining folds
2023-10-22 23:02:56,677:INFO:Declaring metric variables
2023-10-22 23:02:56,680:INFO:Importing untrained model
2023-10-22 23:02:56,683:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-22 23:02:56,688:INFO:Starting cross validation
2023-10-22 23:02:56,689:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:56,729:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:56,736:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:56,748:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:56,753:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:56,754:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:56,763:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:56,764:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:56,772:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:56,769:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:56,788:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-22 23:02:56,804:INFO:Calculating mean and std
2023-10-22 23:02:56,805:INFO:Creating metrics dataframe
2023-10-22 23:02:56,807:INFO:Uploading results into container
2023-10-22 23:02:56,808:INFO:Uploading model into container now
2023-10-22 23:02:56,808:INFO:_master_model_container: 104
2023-10-22 23:02:56,808:INFO:_display_container: 2
2023-10-22 23:02:56,808:INFO:OrthogonalMatchingPursuit()
2023-10-22 23:02:56,808:INFO:create_model() successfully completed......................................
2023-10-22 23:02:56,947:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:56,948:INFO:Creating metrics dataframe
2023-10-22 23:02:56,955:INFO:Initializing Bayesian Ridge
2023-10-22 23:02:56,955:INFO:Total runtime is 0.10241703192392985 minutes
2023-10-22 23:02:56,957:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:56,957:INFO:Initializing create_model()
2023-10-22 23:02:56,958:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:56,958:INFO:Checking exceptions
2023-10-22 23:02:56,958:INFO:Importing libraries
2023-10-22 23:02:56,958:INFO:Copying training dataset
2023-10-22 23:02:56,961:INFO:Defining folds
2023-10-22 23:02:56,961:INFO:Declaring metric variables
2023-10-22 23:02:56,964:INFO:Importing untrained model
2023-10-22 23:02:56,969:INFO:Bayesian Ridge Imported successfully
2023-10-22 23:02:56,974:INFO:Starting cross validation
2023-10-22 23:02:56,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:57,076:INFO:Calculating mean and std
2023-10-22 23:02:57,077:INFO:Creating metrics dataframe
2023-10-22 23:02:57,081:INFO:Uploading results into container
2023-10-22 23:02:57,081:INFO:Uploading model into container now
2023-10-22 23:02:57,082:INFO:_master_model_container: 105
2023-10-22 23:02:57,082:INFO:_display_container: 2
2023-10-22 23:02:57,083:INFO:BayesianRidge()
2023-10-22 23:02:57,083:INFO:create_model() successfully completed......................................
2023-10-22 23:02:57,213:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:57,213:INFO:Creating metrics dataframe
2023-10-22 23:02:57,219:INFO:Initializing Huber Regressor
2023-10-22 23:02:57,220:INFO:Total runtime is 0.1068250854810079 minutes
2023-10-22 23:02:57,222:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:57,222:INFO:Initializing create_model()
2023-10-22 23:02:57,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:57,222:INFO:Checking exceptions
2023-10-22 23:02:57,222:INFO:Importing libraries
2023-10-22 23:02:57,222:INFO:Copying training dataset
2023-10-22 23:02:57,227:INFO:Defining folds
2023-10-22 23:02:57,227:INFO:Declaring metric variables
2023-10-22 23:02:57,230:INFO:Importing untrained model
2023-10-22 23:02:57,233:INFO:Huber Regressor Imported successfully
2023-10-22 23:02:57,238:INFO:Starting cross validation
2023-10-22 23:02:57,239:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:57,284:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:57,295:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:57,319:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:57,328:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:57,329:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:57,337:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:57,342:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:57,344:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:57,345:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:57,349:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-22 23:02:57,373:INFO:Calculating mean and std
2023-10-22 23:02:57,374:INFO:Creating metrics dataframe
2023-10-22 23:02:57,376:INFO:Uploading results into container
2023-10-22 23:02:57,377:INFO:Uploading model into container now
2023-10-22 23:02:57,378:INFO:_master_model_container: 106
2023-10-22 23:02:57,378:INFO:_display_container: 2
2023-10-22 23:02:57,378:INFO:HuberRegressor()
2023-10-22 23:02:57,378:INFO:create_model() successfully completed......................................
2023-10-22 23:02:57,508:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:57,509:INFO:Creating metrics dataframe
2023-10-22 23:02:57,517:INFO:Initializing K Neighbors Regressor
2023-10-22 23:02:57,517:INFO:Total runtime is 0.1117769996325175 minutes
2023-10-22 23:02:57,519:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:57,519:INFO:Initializing create_model()
2023-10-22 23:02:57,519:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:57,519:INFO:Checking exceptions
2023-10-22 23:02:57,519:INFO:Importing libraries
2023-10-22 23:02:57,519:INFO:Copying training dataset
2023-10-22 23:02:57,522:INFO:Defining folds
2023-10-22 23:02:57,522:INFO:Declaring metric variables
2023-10-22 23:02:57,524:INFO:Importing untrained model
2023-10-22 23:02:57,528:INFO:K Neighbors Regressor Imported successfully
2023-10-22 23:02:57,534:INFO:Starting cross validation
2023-10-22 23:02:57,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:57,667:INFO:Calculating mean and std
2023-10-22 23:02:57,669:INFO:Creating metrics dataframe
2023-10-22 23:02:57,671:INFO:Uploading results into container
2023-10-22 23:02:57,672:INFO:Uploading model into container now
2023-10-22 23:02:57,672:INFO:_master_model_container: 107
2023-10-22 23:02:57,672:INFO:_display_container: 2
2023-10-22 23:02:57,672:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-22 23:02:57,672:INFO:create_model() successfully completed......................................
2023-10-22 23:02:57,801:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:57,801:INFO:Creating metrics dataframe
2023-10-22 23:02:57,810:INFO:Initializing Random Forest Regressor
2023-10-22 23:02:57,810:INFO:Total runtime is 0.11666670640309652 minutes
2023-10-22 23:02:57,813:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:57,813:INFO:Initializing create_model()
2023-10-22 23:02:57,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:57,813:INFO:Checking exceptions
2023-10-22 23:02:57,813:INFO:Importing libraries
2023-10-22 23:02:57,813:INFO:Copying training dataset
2023-10-22 23:02:57,816:INFO:Defining folds
2023-10-22 23:02:57,816:INFO:Declaring metric variables
2023-10-22 23:02:57,818:INFO:Importing untrained model
2023-10-22 23:02:57,820:INFO:Random Forest Regressor Imported successfully
2023-10-22 23:02:57,825:INFO:Starting cross validation
2023-10-22 23:02:57,826:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:58,403:INFO:Calculating mean and std
2023-10-22 23:02:58,404:INFO:Creating metrics dataframe
2023-10-22 23:02:58,407:INFO:Uploading results into container
2023-10-22 23:02:58,407:INFO:Uploading model into container now
2023-10-22 23:02:58,408:INFO:_master_model_container: 108
2023-10-22 23:02:58,408:INFO:_display_container: 2
2023-10-22 23:02:58,408:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-10-22 23:02:58,408:INFO:create_model() successfully completed......................................
2023-10-22 23:02:58,548:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:58,548:INFO:Creating metrics dataframe
2023-10-22 23:02:58,557:INFO:Initializing Extra Trees Regressor
2023-10-22 23:02:58,557:INFO:Total runtime is 0.12911979357401532 minutes
2023-10-22 23:02:58,562:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:58,562:INFO:Initializing create_model()
2023-10-22 23:02:58,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:58,562:INFO:Checking exceptions
2023-10-22 23:02:58,562:INFO:Importing libraries
2023-10-22 23:02:58,562:INFO:Copying training dataset
2023-10-22 23:02:58,566:INFO:Defining folds
2023-10-22 23:02:58,566:INFO:Declaring metric variables
2023-10-22 23:02:58,568:INFO:Importing untrained model
2023-10-22 23:02:58,570:INFO:Extra Trees Regressor Imported successfully
2023-10-22 23:02:58,575:INFO:Starting cross validation
2023-10-22 23:02:58,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:59,120:INFO:Calculating mean and std
2023-10-22 23:02:59,121:INFO:Creating metrics dataframe
2023-10-22 23:02:59,123:INFO:Uploading results into container
2023-10-22 23:02:59,124:INFO:Uploading model into container now
2023-10-22 23:02:59,125:INFO:_master_model_container: 109
2023-10-22 23:02:59,125:INFO:_display_container: 2
2023-10-22 23:02:59,125:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-10-22 23:02:59,125:INFO:create_model() successfully completed......................................
2023-10-22 23:02:59,261:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:59,261:INFO:Creating metrics dataframe
2023-10-22 23:02:59,269:INFO:Initializing AdaBoost Regressor
2023-10-22 23:02:59,269:INFO:Total runtime is 0.14098443190256757 minutes
2023-10-22 23:02:59,272:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:59,272:INFO:Initializing create_model()
2023-10-22 23:02:59,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:59,272:INFO:Checking exceptions
2023-10-22 23:02:59,272:INFO:Importing libraries
2023-10-22 23:02:59,272:INFO:Copying training dataset
2023-10-22 23:02:59,278:INFO:Defining folds
2023-10-22 23:02:59,278:INFO:Declaring metric variables
2023-10-22 23:02:59,281:INFO:Importing untrained model
2023-10-22 23:02:59,283:INFO:AdaBoost Regressor Imported successfully
2023-10-22 23:02:59,287:INFO:Starting cross validation
2023-10-22 23:02:59,288:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:59,501:INFO:Calculating mean and std
2023-10-22 23:02:59,502:INFO:Creating metrics dataframe
2023-10-22 23:02:59,505:INFO:Uploading results into container
2023-10-22 23:02:59,506:INFO:Uploading model into container now
2023-10-22 23:02:59,506:INFO:_master_model_container: 110
2023-10-22 23:02:59,506:INFO:_display_container: 2
2023-10-22 23:02:59,507:INFO:AdaBoostRegressor(random_state=42)
2023-10-22 23:02:59,507:INFO:create_model() successfully completed......................................
2023-10-22 23:02:59,638:INFO:SubProcess create_model() end ==================================
2023-10-22 23:02:59,638:INFO:Creating metrics dataframe
2023-10-22 23:02:59,646:INFO:Initializing Gradient Boosting Regressor
2023-10-22 23:02:59,647:INFO:Total runtime is 0.14728186925252282 minutes
2023-10-22 23:02:59,650:INFO:SubProcess create_model() called ==================================
2023-10-22 23:02:59,651:INFO:Initializing create_model()
2023-10-22 23:02:59,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:02:59,651:INFO:Checking exceptions
2023-10-22 23:02:59,651:INFO:Importing libraries
2023-10-22 23:02:59,651:INFO:Copying training dataset
2023-10-22 23:02:59,656:INFO:Defining folds
2023-10-22 23:02:59,657:INFO:Declaring metric variables
2023-10-22 23:02:59,659:INFO:Importing untrained model
2023-10-22 23:02:59,662:INFO:Gradient Boosting Regressor Imported successfully
2023-10-22 23:02:59,666:INFO:Starting cross validation
2023-10-22 23:02:59,666:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:02:59,933:INFO:Calculating mean and std
2023-10-22 23:02:59,934:INFO:Creating metrics dataframe
2023-10-22 23:02:59,937:INFO:Uploading results into container
2023-10-22 23:02:59,937:INFO:Uploading model into container now
2023-10-22 23:02:59,938:INFO:_master_model_container: 111
2023-10-22 23:02:59,938:INFO:_display_container: 2
2023-10-22 23:02:59,938:INFO:GradientBoostingRegressor(random_state=42)
2023-10-22 23:02:59,938:INFO:create_model() successfully completed......................................
2023-10-22 23:03:00,082:INFO:SubProcess create_model() end ==================================
2023-10-22 23:03:00,082:INFO:Creating metrics dataframe
2023-10-22 23:03:00,091:INFO:Initializing Extreme Gradient Boosting
2023-10-22 23:03:00,092:INFO:Total runtime is 0.15469421148300175 minutes
2023-10-22 23:03:00,094:INFO:SubProcess create_model() called ==================================
2023-10-22 23:03:00,095:INFO:Initializing create_model()
2023-10-22 23:03:00,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:03:00,095:INFO:Checking exceptions
2023-10-22 23:03:00,095:INFO:Importing libraries
2023-10-22 23:03:00,095:INFO:Copying training dataset
2023-10-22 23:03:00,098:INFO:Defining folds
2023-10-22 23:03:00,098:INFO:Declaring metric variables
2023-10-22 23:03:00,100:INFO:Importing untrained model
2023-10-22 23:03:00,102:INFO:Extreme Gradient Boosting Imported successfully
2023-10-22 23:03:00,108:INFO:Starting cross validation
2023-10-22 23:03:00,110:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:03:00,529:INFO:Calculating mean and std
2023-10-22 23:03:00,530:INFO:Creating metrics dataframe
2023-10-22 23:03:00,533:INFO:Uploading results into container
2023-10-22 23:03:00,533:INFO:Uploading model into container now
2023-10-22 23:03:00,534:INFO:_master_model_container: 112
2023-10-22 23:03:00,534:INFO:_display_container: 2
2023-10-22 23:03:00,534:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2023-10-22 23:03:00,534:INFO:create_model() successfully completed......................................
2023-10-22 23:03:00,687:INFO:SubProcess create_model() end ==================================
2023-10-22 23:03:00,687:INFO:Creating metrics dataframe
2023-10-22 23:03:00,695:INFO:Initializing Light Gradient Boosting Machine
2023-10-22 23:03:00,695:INFO:Total runtime is 0.16475682258605961 minutes
2023-10-22 23:03:00,698:INFO:SubProcess create_model() called ==================================
2023-10-22 23:03:00,698:INFO:Initializing create_model()
2023-10-22 23:03:00,698:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f97c0eae560>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f97c0aea1d0>, model_only=True, return_train_score=False, kwargs={})
2023-10-22 23:03:00,698:INFO:Checking exceptions
2023-10-22 23:03:00,698:INFO:Importing libraries
2023-10-22 23:03:00,698:INFO:Copying training dataset
2023-10-22 23:03:00,701:INFO:Defining folds
2023-10-22 23:03:00,701:INFO:Declaring metric variables
2023-10-22 23:03:00,704:INFO:Importing untrained model
2023-10-22 23:03:00,706:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-22 23:03:00,711:INFO:Starting cross validation
2023-10-22 23:03:00,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-22 23:04:47,209:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LinearRegression was fitted without feature names
  warnings.warn(

2023-10-23 11:26:55,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 11:26:55,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 11:26:55,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 11:26:55,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-10-23 11:26:55,390:INFO:PyCaret RegressionExperiment
2023-10-23 11:26:55,391:INFO:Logging name: reg-default-name
2023-10-23 11:26:55,391:INFO:ML Usecase: MLUsecase.REGRESSION
2023-10-23 11:26:55,391:INFO:version 3.1.0
2023-10-23 11:26:55,391:INFO:Initializing setup()
2023-10-23 11:26:55,391:INFO:self.USI: 3353
2023-10-23 11:26:55,391:INFO:self._variable_keys: {'y', 'gpu_n_jobs_param', 'fold_generator', 'y_train', 'log_plots_param', 'fold_shuffle_param', 'memory', 'fold_groups_param', 'X_test', 'target_param', 'exp_id', 'idx', '_ml_usecase', 'html_param', 'logging_param', 'data', 'seed', 'n_jobs_param', 'y_test', 'USI', 'X', 'exp_name_log', '_available_plots', 'pipeline', 'transform_target_param', 'gpu_param', 'X_train'}
2023-10-23 11:26:55,391:INFO:Checking environment
2023-10-23 11:26:55,391:INFO:python_version: 3.10.6
2023-10-23 11:26:55,391:INFO:python_build: ('main', 'Mar 10 2023 10:55:28')
2023-10-23 11:26:55,391:INFO:machine: x86_64
2023-10-23 11:26:55,391:INFO:platform: Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.35
2023-10-23 11:26:55,391:INFO:Memory: svmem(total=16562769920, available=14410444800, percent=13.0, used=1873620992, free=14220738560, active=128081920, inactive=1790693376, buffers=62783488, cached=405626880, shared=2449408, slab=113590272)
2023-10-23 11:26:55,392:INFO:Physical Core: 12
2023-10-23 11:26:55,393:INFO:Logical Core: 24
2023-10-23 11:26:55,393:INFO:Checking libraries
2023-10-23 11:26:55,393:INFO:System:
2023-10-23 11:26:55,393:INFO:    python: 3.10.6 (main, Mar 10 2023, 10:55:28) [GCC 11.3.0]
2023-10-23 11:26:55,393:INFO:executable: /usr/bin/python3
2023-10-23 11:26:55,393:INFO:   machine: Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.35
2023-10-23 11:26:55,393:INFO:PyCaret required dependencies:
2023-10-23 11:26:55,661:INFO:                 pip: 22.0.2
2023-10-23 11:26:55,661:INFO:          setuptools: 59.6.0
2023-10-23 11:26:55,661:INFO:             pycaret: 3.1.0
2023-10-23 11:26:55,661:INFO:             IPython: 8.5.0
2023-10-23 11:26:55,661:INFO:          ipywidgets: 7.7.2
2023-10-23 11:26:55,661:INFO:                tqdm: 4.64.1
2023-10-23 11:26:55,661:INFO:               numpy: 1.23.4
2023-10-23 11:26:55,661:INFO:              pandas: 1.4.2
2023-10-23 11:26:55,661:INFO:              jinja2: 3.1.2
2023-10-23 11:26:55,661:INFO:               scipy: 1.10.1
2023-10-23 11:26:55,661:INFO:              joblib: 1.3.2
2023-10-23 11:26:55,661:INFO:             sklearn: 1.1.2
2023-10-23 11:26:55,661:INFO:                pyod: 1.1.0
2023-10-23 11:26:55,661:INFO:            imblearn: 0.9.1
2023-10-23 11:26:55,661:INFO:   category_encoders: 2.6.2
2023-10-23 11:26:55,661:INFO:            lightgbm: 4.1.0
2023-10-23 11:26:55,661:INFO:               numba: 0.58.1
2023-10-23 11:26:55,661:INFO:            requests: 2.28.1
2023-10-23 11:26:55,661:INFO:          matplotlib: 3.5.3
2023-10-23 11:26:55,661:INFO:          scikitplot: 0.3.7
2023-10-23 11:26:55,661:INFO:         yellowbrick: 1.5
2023-10-23 11:26:55,661:INFO:              plotly: 5.9.0
2023-10-23 11:26:55,661:INFO:    plotly-resampler: Not installed
2023-10-23 11:26:55,661:INFO:             kaleido: 0.2.1
2023-10-23 11:26:55,661:INFO:           schemdraw: 0.15
2023-10-23 11:26:55,661:INFO:         statsmodels: 0.13.2
2023-10-23 11:26:55,661:INFO:              sktime: 0.21.1
2023-10-23 11:26:55,661:INFO:               tbats: 1.1.3
2023-10-23 11:26:55,661:INFO:            pmdarima: 2.0.1
2023-10-23 11:26:55,661:INFO:              psutil: 5.9.3
2023-10-23 11:26:55,661:INFO:          markupsafe: 2.1.1
2023-10-23 11:26:55,661:INFO:             pickle5: Not installed
2023-10-23 11:26:55,661:INFO:         cloudpickle: 2.2.0
2023-10-23 11:26:55,661:INFO:         deprecation: 2.1.0
2023-10-23 11:26:55,661:INFO:              xxhash: 3.4.1
2023-10-23 11:26:55,661:INFO:           wurlitzer: 3.0.3
2023-10-23 11:26:55,661:INFO:PyCaret optional dependencies:
2023-10-23 11:26:55,679:INFO:                shap: Not installed
2023-10-23 11:26:55,679:INFO:           interpret: Not installed
2023-10-23 11:26:55,679:INFO:                umap: Not installed
2023-10-23 11:26:55,679:INFO:     ydata_profiling: Not installed
2023-10-23 11:26:55,679:INFO:  explainerdashboard: Not installed
2023-10-23 11:26:55,679:INFO:             autoviz: Not installed
2023-10-23 11:26:55,679:INFO:           fairlearn: Not installed
2023-10-23 11:26:55,679:INFO:          deepchecks: Not installed
2023-10-23 11:26:55,679:INFO:             xgboost: 1.6.2
2023-10-23 11:26:55,679:INFO:            catboost: Not installed
2023-10-23 11:26:55,679:INFO:              kmodes: Not installed
2023-10-23 11:26:55,679:INFO:             mlxtend: Not installed
2023-10-23 11:26:55,679:INFO:       statsforecast: Not installed
2023-10-23 11:26:55,679:INFO:        tune_sklearn: Not installed
2023-10-23 11:26:55,679:INFO:                 ray: Not installed
2023-10-23 11:26:55,679:INFO:            hyperopt: Not installed
2023-10-23 11:26:55,679:INFO:              optuna: Not installed
2023-10-23 11:26:55,679:INFO:               skopt: Not installed
2023-10-23 11:26:55,679:INFO:              mlflow: Not installed
2023-10-23 11:26:55,679:INFO:              gradio: Not installed
2023-10-23 11:26:55,679:INFO:             fastapi: Not installed
2023-10-23 11:26:55,679:INFO:             uvicorn: Not installed
2023-10-23 11:26:55,679:INFO:              m2cgen: Not installed
2023-10-23 11:26:55,679:INFO:           evidently: Not installed
2023-10-23 11:26:55,679:INFO:               fugue: Not installed
2023-10-23 11:26:55,679:INFO:           streamlit: 1.11.1
2023-10-23 11:26:55,679:INFO:             prophet: Not installed
2023-10-23 11:26:55,679:INFO:None
2023-10-23 11:26:55,679:INFO:Set up data.
2023-10-23 11:26:55,683:INFO:Set up folding strategy.
2023-10-23 11:26:55,683:INFO:Set up train/test split.
2023-10-23 11:26:55,686:INFO:Set up index.
2023-10-23 11:26:55,686:INFO:Assigning column types.
2023-10-23 11:26:55,688:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-23 11:26:55,688:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,690:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,692:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,722:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,745:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,745:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:55,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:55,748:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,751:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,753:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,782:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,805:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,805:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:55,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:55,806:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-10-23 11:26:55,809:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,811:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,845:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,868:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:55,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:55,871:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,874:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,905:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,927:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,927:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:55,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:55,929:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-10-23 11:26:55,934:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,974:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 11:26:55,999:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:56,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:56,007:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-10-23 11:26:56,042:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 11:26:56,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 11:26:56,065:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:56,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:56,066:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-10-23 11:26:56,102:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 11:26:56,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 11:26:56,125:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:56,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:56,161:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 11:26:56,184:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-23 11:26:56,184:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:56,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:56,186:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-23 11:26:56,218:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 11:26:56,240:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:56,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:56,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-10-23 11:26:56,313:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:56,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:56,315:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-10-23 11:26:56,380:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:56,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:56,442:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:56,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:56,445:INFO:Preparing preprocessing pipeline...
2023-10-23 11:26:56,445:INFO:Set up simple imputation.
2023-10-23 11:26:56,448:INFO:Set up encoding of categorical features.
2023-10-23 11:26:56,449:INFO:Set up column name cleaning.
2023-10-23 11:26:56,482:INFO:Finished creating preprocessing pipeline.
2023-10-23 11:26:56,487:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Sleep', 'Activity Duration',
                                             'TSS', 'Weight', 'Steps',
                                             'Cals_burnt', 'Protein',
                                             'Sensation'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Activity Type'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Activity Type'],
                                    transformer=OneHotEncoder(cols=['Activity '
                                                                    'Type'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2023-10-23 11:26:56,487:INFO:Creating final display dataframe.
2023-10-23 11:26:56,576:INFO:Setup _display_container:                     Description             Value
0                    Session id                42
1                        Target              Cals
2                   Target type        Regression
3           Original data shape        (1014, 10)
4        Transformed data shape        (1014, 21)
5   Transformed train set shape         (709, 21)
6    Transformed test set shape         (305, 21)
7              Numeric features                 8
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              3353
2023-10-23 11:26:56,671:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:56,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:56,738:INFO:Soft dependency imported: xgboost: 1.6.2
2023-10-23 11:26:56,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-23 11:26:56,740:INFO:setup() successfully completed in 1.35s...............
2023-10-23 11:27:01,625:INFO:Initializing compare_models()
2023-10-23 11:27:01,625:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, 'include': None, 'exclude': ['lar', 'par', 'dt'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=['lar', 'par', 'dt'])
2023-10-23 11:27:01,626:INFO:Checking exceptions
2023-10-23 11:27:01,628:INFO:Preparing display monitor
2023-10-23 11:27:01,652:INFO:Initializing Linear Regression
2023-10-23 11:27:01,652:INFO:Total runtime is 3.6160151163736978e-06 minutes
2023-10-23 11:27:01,655:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:01,656:INFO:Initializing create_model()
2023-10-23 11:27:01,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:01,656:INFO:Checking exceptions
2023-10-23 11:27:01,656:INFO:Importing libraries
2023-10-23 11:27:01,656:INFO:Copying training dataset
2023-10-23 11:27:01,658:INFO:Defining folds
2023-10-23 11:27:01,658:INFO:Declaring metric variables
2023-10-23 11:27:01,662:INFO:Importing untrained model
2023-10-23 11:27:01,665:INFO:Linear Regression Imported successfully
2023-10-23 11:27:01,671:INFO:Starting cross validation
2023-10-23 11:27:01,672:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:03,356:INFO:Calculating mean and std
2023-10-23 11:27:03,357:INFO:Creating metrics dataframe
2023-10-23 11:27:03,361:INFO:Uploading results into container
2023-10-23 11:27:03,362:INFO:Uploading model into container now
2023-10-23 11:27:03,362:INFO:_master_model_container: 1
2023-10-23 11:27:03,362:INFO:_display_container: 2
2023-10-23 11:27:03,362:INFO:LinearRegression(n_jobs=-1)
2023-10-23 11:27:03,362:INFO:create_model() successfully completed......................................
2023-10-23 11:27:03,445:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:03,445:INFO:Creating metrics dataframe
2023-10-23 11:27:03,452:INFO:Initializing Lasso Regression
2023-10-23 11:27:03,452:INFO:Total runtime is 0.029996705055236817 minutes
2023-10-23 11:27:03,455:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:03,456:INFO:Initializing create_model()
2023-10-23 11:27:03,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:03,456:INFO:Checking exceptions
2023-10-23 11:27:03,456:INFO:Importing libraries
2023-10-23 11:27:03,456:INFO:Copying training dataset
2023-10-23 11:27:03,460:INFO:Defining folds
2023-10-23 11:27:03,460:INFO:Declaring metric variables
2023-10-23 11:27:03,463:INFO:Importing untrained model
2023-10-23 11:27:03,465:INFO:Lasso Regression Imported successfully
2023-10-23 11:27:03,470:INFO:Starting cross validation
2023-10-23 11:27:03,471:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:05,013:INFO:Calculating mean and std
2023-10-23 11:27:05,014:INFO:Creating metrics dataframe
2023-10-23 11:27:05,017:INFO:Uploading results into container
2023-10-23 11:27:05,018:INFO:Uploading model into container now
2023-10-23 11:27:05,018:INFO:_master_model_container: 2
2023-10-23 11:27:05,018:INFO:_display_container: 2
2023-10-23 11:27:05,018:INFO:Lasso(random_state=42)
2023-10-23 11:27:05,019:INFO:create_model() successfully completed......................................
2023-10-23 11:27:05,093:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:05,093:INFO:Creating metrics dataframe
2023-10-23 11:27:05,102:INFO:Initializing Ridge Regression
2023-10-23 11:27:05,102:INFO:Total runtime is 0.05749737819035848 minutes
2023-10-23 11:27:05,106:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:05,106:INFO:Initializing create_model()
2023-10-23 11:27:05,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:05,106:INFO:Checking exceptions
2023-10-23 11:27:05,106:INFO:Importing libraries
2023-10-23 11:27:05,106:INFO:Copying training dataset
2023-10-23 11:27:05,110:INFO:Defining folds
2023-10-23 11:27:05,110:INFO:Declaring metric variables
2023-10-23 11:27:05,112:INFO:Importing untrained model
2023-10-23 11:27:05,114:INFO:Ridge Regression Imported successfully
2023-10-23 11:27:05,121:INFO:Starting cross validation
2023-10-23 11:27:05,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:05,922:INFO:Calculating mean and std
2023-10-23 11:27:05,923:INFO:Creating metrics dataframe
2023-10-23 11:27:05,925:INFO:Uploading results into container
2023-10-23 11:27:05,926:INFO:Uploading model into container now
2023-10-23 11:27:05,926:INFO:_master_model_container: 3
2023-10-23 11:27:05,926:INFO:_display_container: 2
2023-10-23 11:27:05,927:INFO:Ridge(random_state=42)
2023-10-23 11:27:05,927:INFO:create_model() successfully completed......................................
2023-10-23 11:27:06,001:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:06,001:INFO:Creating metrics dataframe
2023-10-23 11:27:06,008:INFO:Initializing Elastic Net
2023-10-23 11:27:06,008:INFO:Total runtime is 0.07259911298751831 minutes
2023-10-23 11:27:06,011:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:06,011:INFO:Initializing create_model()
2023-10-23 11:27:06,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:06,011:INFO:Checking exceptions
2023-10-23 11:27:06,011:INFO:Importing libraries
2023-10-23 11:27:06,012:INFO:Copying training dataset
2023-10-23 11:27:06,015:INFO:Defining folds
2023-10-23 11:27:06,015:INFO:Declaring metric variables
2023-10-23 11:27:06,018:INFO:Importing untrained model
2023-10-23 11:27:06,021:INFO:Elastic Net Imported successfully
2023-10-23 11:27:06,025:INFO:Starting cross validation
2023-10-23 11:27:06,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:06,132:INFO:Calculating mean and std
2023-10-23 11:27:06,133:INFO:Creating metrics dataframe
2023-10-23 11:27:06,136:INFO:Uploading results into container
2023-10-23 11:27:06,136:INFO:Uploading model into container now
2023-10-23 11:27:06,137:INFO:_master_model_container: 4
2023-10-23 11:27:06,137:INFO:_display_container: 2
2023-10-23 11:27:06,137:INFO:ElasticNet(random_state=42)
2023-10-23 11:27:06,137:INFO:create_model() successfully completed......................................
2023-10-23 11:27:06,212:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:06,212:INFO:Creating metrics dataframe
2023-10-23 11:27:06,219:INFO:Initializing Lasso Least Angle Regression
2023-10-23 11:27:06,220:INFO:Total runtime is 0.0761223316192627 minutes
2023-10-23 11:27:06,222:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:06,222:INFO:Initializing create_model()
2023-10-23 11:27:06,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:06,222:INFO:Checking exceptions
2023-10-23 11:27:06,222:INFO:Importing libraries
2023-10-23 11:27:06,222:INFO:Copying training dataset
2023-10-23 11:27:06,225:INFO:Defining folds
2023-10-23 11:27:06,225:INFO:Declaring metric variables
2023-10-23 11:27:06,227:INFO:Importing untrained model
2023-10-23 11:27:06,229:INFO:Lasso Least Angle Regression Imported successfully
2023-10-23 11:27:06,234:INFO:Starting cross validation
2023-10-23 11:27:06,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:06,266:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-23 11:27:06,275:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-23 11:27:06,288:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-23 11:27:06,309:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-23 11:27:06,309:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-23 11:27:06,312:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-23 11:27:06,317:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-23 11:27:06,321:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-23 11:27:06,326:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-23 11:27:06,334:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-10-23 11:27:06,354:INFO:Calculating mean and std
2023-10-23 11:27:06,355:INFO:Creating metrics dataframe
2023-10-23 11:27:06,357:INFO:Uploading results into container
2023-10-23 11:27:06,358:INFO:Uploading model into container now
2023-10-23 11:27:06,358:INFO:_master_model_container: 5
2023-10-23 11:27:06,358:INFO:_display_container: 2
2023-10-23 11:27:06,358:INFO:LassoLars(random_state=42)
2023-10-23 11:27:06,358:INFO:create_model() successfully completed......................................
2023-10-23 11:27:06,430:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:06,430:INFO:Creating metrics dataframe
2023-10-23 11:27:06,436:INFO:Initializing Orthogonal Matching Pursuit
2023-10-23 11:27:06,436:INFO:Total runtime is 0.07973368565241495 minutes
2023-10-23 11:27:06,438:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:06,438:INFO:Initializing create_model()
2023-10-23 11:27:06,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:06,438:INFO:Checking exceptions
2023-10-23 11:27:06,439:INFO:Importing libraries
2023-10-23 11:27:06,439:INFO:Copying training dataset
2023-10-23 11:27:06,442:INFO:Defining folds
2023-10-23 11:27:06,442:INFO:Declaring metric variables
2023-10-23 11:27:06,445:INFO:Importing untrained model
2023-10-23 11:27:06,450:INFO:Orthogonal Matching Pursuit Imported successfully
2023-10-23 11:27:06,454:INFO:Starting cross validation
2023-10-23 11:27:06,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:06,488:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-23 11:27:06,490:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-23 11:27:06,510:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-23 11:27:06,527:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-23 11:27:06,547:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-23 11:27:06,551:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-23 11:27:06,562:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-23 11:27:06,563:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-23 11:27:06,574:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-23 11:27:06,574:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-10-23 11:27:06,591:INFO:Calculating mean and std
2023-10-23 11:27:06,592:INFO:Creating metrics dataframe
2023-10-23 11:27:06,595:INFO:Uploading results into container
2023-10-23 11:27:06,596:INFO:Uploading model into container now
2023-10-23 11:27:06,596:INFO:_master_model_container: 6
2023-10-23 11:27:06,596:INFO:_display_container: 2
2023-10-23 11:27:06,596:INFO:OrthogonalMatchingPursuit()
2023-10-23 11:27:06,596:INFO:create_model() successfully completed......................................
2023-10-23 11:27:06,669:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:06,670:INFO:Creating metrics dataframe
2023-10-23 11:27:06,676:INFO:Initializing Bayesian Ridge
2023-10-23 11:27:06,686:INFO:Total runtime is 0.08389865159988404 minutes
2023-10-23 11:27:06,689:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:06,690:INFO:Initializing create_model()
2023-10-23 11:27:06,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:06,690:INFO:Checking exceptions
2023-10-23 11:27:06,690:INFO:Importing libraries
2023-10-23 11:27:06,690:INFO:Copying training dataset
2023-10-23 11:27:06,693:INFO:Defining folds
2023-10-23 11:27:06,693:INFO:Declaring metric variables
2023-10-23 11:27:06,696:INFO:Importing untrained model
2023-10-23 11:27:06,699:INFO:Bayesian Ridge Imported successfully
2023-10-23 11:27:06,706:INFO:Starting cross validation
2023-10-23 11:27:06,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:06,824:INFO:Calculating mean and std
2023-10-23 11:27:06,825:INFO:Creating metrics dataframe
2023-10-23 11:27:06,827:INFO:Uploading results into container
2023-10-23 11:27:06,828:INFO:Uploading model into container now
2023-10-23 11:27:06,828:INFO:_master_model_container: 7
2023-10-23 11:27:06,828:INFO:_display_container: 2
2023-10-23 11:27:06,828:INFO:BayesianRidge()
2023-10-23 11:27:06,828:INFO:create_model() successfully completed......................................
2023-10-23 11:27:06,902:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:06,902:INFO:Creating metrics dataframe
2023-10-23 11:27:06,910:INFO:Initializing Huber Regressor
2023-10-23 11:27:06,910:INFO:Total runtime is 0.08762638966242473 minutes
2023-10-23 11:27:06,913:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:06,913:INFO:Initializing create_model()
2023-10-23 11:27:06,913:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:06,913:INFO:Checking exceptions
2023-10-23 11:27:06,913:INFO:Importing libraries
2023-10-23 11:27:06,913:INFO:Copying training dataset
2023-10-23 11:27:06,915:INFO:Defining folds
2023-10-23 11:27:06,916:INFO:Declaring metric variables
2023-10-23 11:27:06,918:INFO:Importing untrained model
2023-10-23 11:27:06,920:INFO:Huber Regressor Imported successfully
2023-10-23 11:27:06,925:INFO:Starting cross validation
2023-10-23 11:27:06,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:07,033:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-23 11:27:07,033:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-23 11:27:07,033:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-23 11:27:07,033:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-23 11:27:07,033:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-23 11:27:07,033:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-23 11:27:07,034:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-23 11:27:07,035:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-23 11:27:07,036:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-23 11:27:07,036:WARNING:/home/alanis/.local/lib/python3.10/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-10-23 11:27:07,066:INFO:Calculating mean and std
2023-10-23 11:27:07,067:INFO:Creating metrics dataframe
2023-10-23 11:27:07,070:INFO:Uploading results into container
2023-10-23 11:27:07,070:INFO:Uploading model into container now
2023-10-23 11:27:07,070:INFO:_master_model_container: 8
2023-10-23 11:27:07,070:INFO:_display_container: 2
2023-10-23 11:27:07,070:INFO:HuberRegressor()
2023-10-23 11:27:07,071:INFO:create_model() successfully completed......................................
2023-10-23 11:27:07,141:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:07,141:INFO:Creating metrics dataframe
2023-10-23 11:27:07,150:INFO:Initializing K Neighbors Regressor
2023-10-23 11:27:07,150:INFO:Total runtime is 0.09163103898366293 minutes
2023-10-23 11:27:07,154:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:07,154:INFO:Initializing create_model()
2023-10-23 11:27:07,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:07,154:INFO:Checking exceptions
2023-10-23 11:27:07,154:INFO:Importing libraries
2023-10-23 11:27:07,154:INFO:Copying training dataset
2023-10-23 11:27:07,157:INFO:Defining folds
2023-10-23 11:27:07,157:INFO:Declaring metric variables
2023-10-23 11:27:07,160:INFO:Importing untrained model
2023-10-23 11:27:07,163:INFO:K Neighbors Regressor Imported successfully
2023-10-23 11:27:07,168:INFO:Starting cross validation
2023-10-23 11:27:07,169:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:07,288:INFO:Calculating mean and std
2023-10-23 11:27:07,289:INFO:Creating metrics dataframe
2023-10-23 11:27:07,291:INFO:Uploading results into container
2023-10-23 11:27:07,292:INFO:Uploading model into container now
2023-10-23 11:27:07,292:INFO:_master_model_container: 9
2023-10-23 11:27:07,293:INFO:_display_container: 2
2023-10-23 11:27:07,293:INFO:KNeighborsRegressor(n_jobs=-1)
2023-10-23 11:27:07,293:INFO:create_model() successfully completed......................................
2023-10-23 11:27:07,368:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:07,368:INFO:Creating metrics dataframe
2023-10-23 11:27:07,375:INFO:Initializing Random Forest Regressor
2023-10-23 11:27:07,375:INFO:Total runtime is 0.09537547826766968 minutes
2023-10-23 11:27:07,377:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:07,377:INFO:Initializing create_model()
2023-10-23 11:27:07,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:07,377:INFO:Checking exceptions
2023-10-23 11:27:07,377:INFO:Importing libraries
2023-10-23 11:27:07,377:INFO:Copying training dataset
2023-10-23 11:27:07,380:INFO:Defining folds
2023-10-23 11:27:07,380:INFO:Declaring metric variables
2023-10-23 11:27:07,384:INFO:Importing untrained model
2023-10-23 11:27:07,386:INFO:Random Forest Regressor Imported successfully
2023-10-23 11:27:07,390:INFO:Starting cross validation
2023-10-23 11:27:07,391:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:08,025:INFO:Calculating mean and std
2023-10-23 11:27:08,026:INFO:Creating metrics dataframe
2023-10-23 11:27:08,029:INFO:Uploading results into container
2023-10-23 11:27:08,029:INFO:Uploading model into container now
2023-10-23 11:27:08,030:INFO:_master_model_container: 10
2023-10-23 11:27:08,030:INFO:_display_container: 2
2023-10-23 11:27:08,030:INFO:RandomForestRegressor(n_jobs=-1, random_state=42)
2023-10-23 11:27:08,030:INFO:create_model() successfully completed......................................
2023-10-23 11:27:08,117:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:08,117:INFO:Creating metrics dataframe
2023-10-23 11:27:08,124:INFO:Initializing Extra Trees Regressor
2023-10-23 11:27:08,124:INFO:Total runtime is 0.10787076155344645 minutes
2023-10-23 11:27:08,127:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:08,127:INFO:Initializing create_model()
2023-10-23 11:27:08,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:08,127:INFO:Checking exceptions
2023-10-23 11:27:08,127:INFO:Importing libraries
2023-10-23 11:27:08,127:INFO:Copying training dataset
2023-10-23 11:27:08,130:INFO:Defining folds
2023-10-23 11:27:08,130:INFO:Declaring metric variables
2023-10-23 11:27:08,133:INFO:Importing untrained model
2023-10-23 11:27:08,135:INFO:Extra Trees Regressor Imported successfully
2023-10-23 11:27:08,140:INFO:Starting cross validation
2023-10-23 11:27:08,141:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:08,643:INFO:Calculating mean and std
2023-10-23 11:27:08,644:INFO:Creating metrics dataframe
2023-10-23 11:27:08,647:INFO:Uploading results into container
2023-10-23 11:27:08,647:INFO:Uploading model into container now
2023-10-23 11:27:08,647:INFO:_master_model_container: 11
2023-10-23 11:27:08,647:INFO:_display_container: 2
2023-10-23 11:27:08,648:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=42)
2023-10-23 11:27:08,648:INFO:create_model() successfully completed......................................
2023-10-23 11:27:08,719:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:08,720:INFO:Creating metrics dataframe
2023-10-23 11:27:08,732:INFO:Initializing AdaBoost Regressor
2023-10-23 11:27:08,732:INFO:Total runtime is 0.11799257198969523 minutes
2023-10-23 11:27:08,734:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:08,734:INFO:Initializing create_model()
2023-10-23 11:27:08,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:08,734:INFO:Checking exceptions
2023-10-23 11:27:08,734:INFO:Importing libraries
2023-10-23 11:27:08,734:INFO:Copying training dataset
2023-10-23 11:27:08,738:INFO:Defining folds
2023-10-23 11:27:08,738:INFO:Declaring metric variables
2023-10-23 11:27:08,740:INFO:Importing untrained model
2023-10-23 11:27:08,742:INFO:AdaBoost Regressor Imported successfully
2023-10-23 11:27:08,752:INFO:Starting cross validation
2023-10-23 11:27:08,753:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:08,974:INFO:Calculating mean and std
2023-10-23 11:27:08,975:INFO:Creating metrics dataframe
2023-10-23 11:27:08,978:INFO:Uploading results into container
2023-10-23 11:27:08,978:INFO:Uploading model into container now
2023-10-23 11:27:08,979:INFO:_master_model_container: 12
2023-10-23 11:27:08,979:INFO:_display_container: 2
2023-10-23 11:27:08,979:INFO:AdaBoostRegressor(random_state=42)
2023-10-23 11:27:08,979:INFO:create_model() successfully completed......................................
2023-10-23 11:27:09,059:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:09,059:INFO:Creating metrics dataframe
2023-10-23 11:27:09,067:INFO:Initializing Gradient Boosting Regressor
2023-10-23 11:27:09,067:INFO:Total runtime is 0.12357937097549439 minutes
2023-10-23 11:27:09,069:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:09,069:INFO:Initializing create_model()
2023-10-23 11:27:09,069:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:09,069:INFO:Checking exceptions
2023-10-23 11:27:09,069:INFO:Importing libraries
2023-10-23 11:27:09,070:INFO:Copying training dataset
2023-10-23 11:27:09,072:INFO:Defining folds
2023-10-23 11:27:09,072:INFO:Declaring metric variables
2023-10-23 11:27:09,074:INFO:Importing untrained model
2023-10-23 11:27:09,077:INFO:Gradient Boosting Regressor Imported successfully
2023-10-23 11:27:09,085:INFO:Starting cross validation
2023-10-23 11:27:09,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:09,295:INFO:Calculating mean and std
2023-10-23 11:27:09,295:INFO:Creating metrics dataframe
2023-10-23 11:27:09,298:INFO:Uploading results into container
2023-10-23 11:27:09,298:INFO:Uploading model into container now
2023-10-23 11:27:09,299:INFO:_master_model_container: 13
2023-10-23 11:27:09,299:INFO:_display_container: 2
2023-10-23 11:27:09,299:INFO:GradientBoostingRegressor(random_state=42)
2023-10-23 11:27:09,299:INFO:create_model() successfully completed......................................
2023-10-23 11:27:09,384:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:09,384:INFO:Creating metrics dataframe
2023-10-23 11:27:09,393:INFO:Initializing Extreme Gradient Boosting
2023-10-23 11:27:09,393:INFO:Total runtime is 0.12900993426640828 minutes
2023-10-23 11:27:09,395:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:09,396:INFO:Initializing create_model()
2023-10-23 11:27:09,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:09,396:INFO:Checking exceptions
2023-10-23 11:27:09,396:INFO:Importing libraries
2023-10-23 11:27:09,396:INFO:Copying training dataset
2023-10-23 11:27:09,399:INFO:Defining folds
2023-10-23 11:27:09,399:INFO:Declaring metric variables
2023-10-23 11:27:09,401:INFO:Importing untrained model
2023-10-23 11:27:09,404:INFO:Extreme Gradient Boosting Imported successfully
2023-10-23 11:27:09,409:INFO:Starting cross validation
2023-10-23 11:27:09,410:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-23 11:27:09,944:INFO:Calculating mean and std
2023-10-23 11:27:09,944:INFO:Creating metrics dataframe
2023-10-23 11:27:09,947:INFO:Uploading results into container
2023-10-23 11:27:09,947:INFO:Uploading model into container now
2023-10-23 11:27:09,948:INFO:_master_model_container: 14
2023-10-23 11:27:09,948:INFO:_display_container: 2
2023-10-23 11:27:09,949:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, gamma=None,
             gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,
             max_leaves=None, min_child_weight=None, missing=nan,
             monotone_constraints=None, n_estimators=100, n_jobs=-1,
             num_parallel_tree=None, predictor=None, random_state=42,
             reg_alpha=None, reg_lambda=None, ...)
2023-10-23 11:27:09,949:INFO:create_model() successfully completed......................................
2023-10-23 11:27:10,023:INFO:SubProcess create_model() end ==================================
2023-10-23 11:27:10,023:INFO:Creating metrics dataframe
2023-10-23 11:27:10,031:INFO:Initializing Light Gradient Boosting Machine
2023-10-23 11:27:10,031:INFO:Total runtime is 0.13965043226877846 minutes
2023-10-23 11:27:10,034:INFO:SubProcess create_model() called ==================================
2023-10-23 11:27:10,034:INFO:Initializing create_model()
2023-10-23 11:27:10,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d946f8eb0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3ce07ccc10>, model_only=True, return_train_score=False, kwargs={})
2023-10-23 11:27:10,034:INFO:Checking exceptions
2023-10-23 11:27:10,034:INFO:Importing libraries
2023-10-23 11:27:10,034:INFO:Copying training dataset
2023-10-23 11:27:10,036:INFO:Defining folds
2023-10-23 11:27:10,036:INFO:Declaring metric variables
2023-10-23 11:27:10,038:INFO:Importing untrained model
2023-10-23 11:27:10,041:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-23 11:27:10,045:INFO:Starting cross validation
2023-10-23 11:27:10,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
